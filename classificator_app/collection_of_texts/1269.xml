<?xml version="1.0" ?>
<doc>
	<label auto="true" type="str" verify="true"><![CDATA[Other]]></label>
	<author auto="true" type="list" verify="true">
		<item type="str"><![CDATA[snakers4]]></item>
	</author>
	<date auto="true" type="str" verify="true"><![CDATA[2022-06-06, 20:35]]></date>
	<link auto="true" type="str" verify="true"><![CDATA[https://habr.com/ru/post/669910/]]></link>
	<title auto="true" type="str" verify="true"><![CDATA[Теперь наш синтез на 20 языках]]></title>
	<categories auto="true" type="list" verify="true">
		<item type="str"><![CDATA[Машинное обучение]]></item>
		<item type="str"><![CDATA[DIY или Сделай сам]]></item>
		<item type="str"><![CDATA[Звук]]></item>
		<item type="str"><![CDATA[Natural Language Processing]]></item>
		<item type="str"><![CDATA[Голосовые интерфейсы]]></item>
	</categories>
	<key_words auto="true" type="list" verify="true">
		<item type="str"><![CDATA[tts]]></item>
		<item type="str"><![CDATA[text-to-speech]]></item>
		<item type="str"><![CDATA[синтез речи]]></item>
	</key_words>
	<text auto="true" type="str" verify="true"><![CDATA[В нашей прошлой статье мы ускорили наши модели в 10 раз, добавили новые высококачественные голоса и управление с помощью SSML, возможность генерировать аудио с разной частотой дискретизации и много других фишек.

В этот раз мы добавили:

1 высококачественный голос на русском языке (eugeny);
Синтез на 20 языках, 174 голоса;
В список языков входят 5 языков народов СНГ: калмыцкий, русский, татарский, узбекский и украинский;
В список языков входят 5 вариаций на тему романо-германских языков: английский, индийский английский, испанский, немецкий, французский;
Также в список языков входят 10 языков народов Индии;
Новую значительно улучшенную модель для простановки ударений и буквы ё со словарем в 4 миллиона слов и точностью 100% (но естественно с рядом оговорок);
Все модели наследуют все "фишки" прошлого релиза, кроме автоматической простановки ударений для языков отличных от русского;

Пока улучшение интерфейсов мы отложили на некоторое время. Ускорить модели еще в 3+ раза мы тоже смогли, но пока с потерей качества, что не позволило нам обновить их прямо в этом релизе.

Попробовать модель как обычно можно в нашем репозитории и в колабе.

Как попробовать

Для самых нетерпеливых — вот основные примеры звучания на русском языке:

Примеры звучания моделей на русском языке

Как обычно, все инструкции, все модели и языки можно найти:

В нашем публичном репозитории по ссылке. Вам нужны модели для синтеза v3;
Или можно прямо в колабе;

Вот самый минималистичный пример вызова модели:

import torch

device = torch.device('cpu')
torch.set_num_threads(4)
speaker = 'xenia'  # 'aidar', 'baya', 'kseniya', 'xenia', 'eugene', 'random'
sample_rate = 48000  # 8000, 24000, 48000

model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',
                                     model='silero_tts',
                                     language='v3_1_ru')
model.to(device)
audio = model.apply_tts(text=example_text,
                        speaker=speaker,
                        sample_rate=sample_rate)

Спикеров и принимаемые символы для каждой модели можно посмотреть в свойствах модели model.speakers и model.symbols.

Или вот такой пример, если вы хотите скачать модель к себе более явно в кеш:

Больше примеров вы можете найти по ссылкам в репозитории. С недавнего времени у моделей также появился своё pip-пакет, аналогичный по функционалу импорту через torch.hub.

Более подробное описание всех фишек, связанных с управлением голосом вы сможете найти в прошлой cтатье, тут не будем повторяться.

Новые модели и языки

Язык модели Название модели Число языков Число голосов
Английский v3_en 1 118
Английский (Индия) v3_en_indic 1 15
Испанский v3_es 1 3
Калмыцкий v3_xal 1 2
Немецкий v3_de 1 5
Русский v3_1_ru 1 5
Татарский v3_tt 1 1
Узбекский v3_uz 1 1
Украинский v3_ua 1 1
Французский v3_fr 1 6
Языки народов Индии v3_indic 10 17

Для всех моделей с более чем одним спикером доступен "случайный" спикер.

Чтобы не делать статью гигантской, просто приведу примеры звучания для каждого языка под спойлером. Попробовать модели как обычно вы можете:

В нашем публичном репозитории по ссылке. Вам нужны модели для синтеза v3;
Или можно прямо в колабе;

Примеры звучания моделей на каждом языке






















Улучшение модели простановки ударений


Но если без шуток, то задача простановки ударений оказалась сильно сложнее, чем предполагалось, но мы смогли добиться в ней впечатляющего прогресса. Если коротко, то нам удалось:

Собрать словарь ударений размером примерно в 4 миллиона слов с высоким покрытием разных корпусов;
Натренировать максимально сжатую модель, выдающую точность 100% (это не ошибка) на таком словаре общим размером менее 2.6 мегабайт (!);
Инициировать итерационный процесс улучшения и проверки словаря;
Добиться нетривиальной точности на омографах (но в текущий релиз эти модели пока не вошли) в районе 80%;

Сложность такой задачи покоится на 3 китах:

Сложность сбора и валидации большого и качественного словаря с ударениями;
Сложность "упаковки" и сжатия быстрой модели, которая со 100% точностью расставляет ударения на заданном словаре;
Сложность обработки большого количества краевых

Про каждый из этих пунктов мы отдельно расскажем.

Словарь

Нам удалось собрать словарь размером примерно в 4 миллиона слов. Эти 4 миллиона слов примерно разбиваются на следующие категории:

Примерно 100,000 частотных слов (5,000 и более вхождений), P95;
Примерно 1,000,000 слов средней частоты (100 и более вхождений), P50;
Примерно 3,000,000 "редких" слов;

Из этих 4 миллионов слов примерно 100 тысяч имели "спорное" ударение и были "кандидатами" в омографы. Из этих 100 тысяч у нас получилось выделить следующие категории:

50,000 сложных слов с 2 ударениями — мы ими пока просто пренебрегли (и оставили только основное ударение);
15,000 частотных слов — "кандидатов" в омографы;
35,000 слов — "длинный хвост";

Из 15,000 самых популярных "кандидатов" для части слов (примерно 5,000 штук) мы смогли найти наиболее популярную форму с помощью морфологических парсеров и принять ее за "эталонную". Для остальных — мы просто случайно выбрали одну из форм. Это одна из проблем словаря.

Другая проблема состоит в том, что в словаре много мусора или очень редких форм и часть слов из топовых 100,000 слов имеет просто неверное ударение.

Тут небольшая ремарка, на момент отправки статью в публикацию, мы успели проверить 20,000 самых популярных слов из словаря. Процесс автоматизированный и с многократной проверкой, но естественно не идеальный.
Мы добились того, что наша модель выдает 100% точность на нашем словаре, но в голове нужно держать этот ряд оговорок:

Часть ударений просто неверная;
Для известных нам "настоящих" омографов стоит по умолчанию более популярная форма;
Для части слов ударение было поставлено случайно из имеющихся опций;
Процесс проверки топ 100,000 самых популярных слов все еще идет (проверено 20,000 слов);

Чтобы дать примерную оценку качества нашего словаря приведем статистику покрытия на популярных интернет корпусах:

Домен Текстов Словарь … P95 Покрытие текстов, % … словаря, % … P95, %
Финансы 39,357,993 289,182 11,531 90.9 76.05 95.37
Common Crawl 300,021,148 536,319 17,236 90.07 61.7 95.99
Книги 100,013,036 903,862 29,268 91.09 61.71 95.27
Новости 25,403,505 839,365 14,559 82.53 32.09 92.49
Субтитры 44,641,621 299,061 11,764 92.82 73.14 92.97
Поэзия, литература 100,014,088 824,830 28,031 92.56 66.38 97.65
Википедия 29 401,392 768,451 21,916 85.93 54.78 96
Общая статистика 638,852,783 1,382,006 73,556 90.69 51.57 93.28

Словарь корпуса включает в себя только слова, встречающиеся более 10 раз (иначе общий словарь всех корпусов вырастет до 40 миллионов "слов").

Также для удобства пользования мы выкладываем наш словарь омографов и словарь из слов "кандидатов" в омографы, на которых мы случайно проставили ударение.

Также опережая очевидный вопрос, почему покрытие P95 не составляет 100%, мы посмотрели каких слов не хватает. В основном там:

Имена собственные;
Артефакты процессинга текста и склеенные слова (например, "такойчто" или "неизвестнокогда");
Cлова вроде "хм-м", "ааа";
И довольно редко встречаются недостающие формы существующих слов;

Со всеми вышеописанными оговорками, наше решение имеет точность в 100% на нашем словаре и занимает примерно 0.2 миллисекунды на 1 слово.

Сравнение с публичными инструментами

Ради интереса, мы также сравнили метрики на нашем словаре с другими публично доступными решениями для простановки ударений:

Инструмент Точность на всём словаре, % … на словаре P95, % … на словаре P50, %
espeak 89.58 95.86 81.37
russtress 89.47 91.98 85.63
russian_accentuation 70.3 83.86 58.86

Сжатие модели

Словарь на 4 миллиона слов весит примерно 100 мегабайт. Наша модель весит примерно 2.6 мегабайта.

Сжатие Размер, MB Сжатие, раз
Словарь 98 1.0
Словарь + gzip 23 4.3
Наша модель 2.6 37.7

То есть у нас получилось с учетом всех вспомогательных файлов и весов модели добиться сжатия словаря примерно в 40 раз. Мое личное мнение — это отличный результат.

Причем если словарь допустим увеличить до 10 миллионов слов, размер модели должен вырасти в сильно меньшей пропорции.

Краевые случаи

Для полноты картины опишем явно известные нам, решенные и еще не решенные краевые случаи.

Решенные краевые случаи:

Такие слова как как-то, кое-кто, где-нибудь, итд;
Возможность сохранения авторской пунктуации;
Возможность использования проставленного пользователем ударения и проставленной буквы ё;
Разного рода "сложные" слова через дефис (например квадратно-гнездовой);

Частично и ещё не решенные краевые случаи:

Ручная чистка и проверка 100,000 самых популярных слов в словаре;
Омографы, настоящие и "кандидаты" в омографы;
Настоящие слова с 2 ударениями (например заднеприводный);

Генерализация модели

Модель так построена, что она в первую очередь хорошо умеет запоминать слова. Но ее архитектура не мешает ей иметь ограниченную генерализацию. В общем — чем длиннее слово — тем лучше генерализация.

И естественно мы пробовали подавать ей разного рода экзотические текста, и в целом по нашим наблюдениям:

В именах, особенно коротких, часто бывает рандом;
В длинных и составных словах модель чувствует себя получше;
В выдуманных и составных русских словах ударение обычно ставится правильно;

Несколько примеров:

гл+окая к+уздра кудлан+ула б+окра +и кудр+ячит бокренк+а

Ег+о н+е призн+али в г+ороде родн+ом +и вс+е ег+о шпын+яли +и н+очью, +и дн+ём. Н+е ст+оит огорч+аться +и н+е ст+оит роб+еть, +а л+учше +эту п+есенку вм+есте проп+еть: "К+отопес! К+отопес! Ед+инственный в м+ире мал+ыш К+отопес!

П+осле П+ервой войн+ы с Мельк+ором Вал+ар воздв+игли в Ард+е дв+а Вел+иких Свет+ильника +и созд+али п+ервое корол+евство н+а +острове Алмарен.
+Этому д+олгому м+иру приш+ёл кон+ец, когд+а Мельк+ор т+айно верн+улся в +Арду +и низв+ерг Свет+ильники. Вал+ар в Ам+ане основ+али втор+ое корол+евство Валин+ор.
Йав+анна в+ырастила дв+а Др+ева Св+ета, кот+орые освещ+али Валин+ор, н+о оставл+яли Средиз+емье в+о тьм+е Мельк+ора. В б+олее п+оздних эп+охах +эти дер+евья дал+и плод+ы, кот+орые ст+али С+олнцем +и Лун+ой.

с+аша +аня паш+а м+аша зуб+арджат аннаб+ель +анна-мар+ия ангел+ина лар+иса нат+аша д+аша игн+ат иннок+ентий дил+яра караб+ас-бар+абас бурат+ино пуш+инчик ман+я юр+а +юрий +юрасик

Дальнейшие планы

Мы не планируем останавливаться на достигнутом и собираемся продолжать развивать наш синтез:

Ускорить его еще в несколько раз;
Прикрутить квантизацию и ONNX для какой-то кастрированной версии синтеза, тем самым возможно ускорив его еще в 2-4 раза;
Проверить все 100,000 слов на предмет правильности ударений;
Решить хотя бы самые частотные омографы;
Добавить возможность использовать фонемы напрямую для синтеза для произношения сложных слов и аббревиатур;
Дальше развивать фишки по управлению интонацией речи и произношением;    В нашей прошлой статье мы ускорили наши модели в 10 раз, добавили новые высококачественные голоса и управление с помощью SSML, возможность генерировать аудио с разной частотой дискретизации и много других фишек. статье  В этот раз мы добавили:  1 высококачественный голос на русском языке (eugeny);
Синтез на 20 языках, 174 голоса;
В список языков входят 5 языков народов СНГ: калмыцкий, русский, татарский, узбекский и украинский;
В список языков входят 5 вариаций на тему романо-германских языков: английский, индийский английский, испанский, немецкий, французский;
Также в список языков входят 10 языков народов Индии;
Новую значительно улучшенную модель для простановки ударений и буквы ё со словарем в 4 миллиона слов и точностью 100% (но естественно с рядом оговорок);
Все модели наследуют все "фишки" прошлого релиза, кроме автоматической простановки ударений для языков отличных от русского; 1 высококачественный голос на русском языке (eugeny); eugeny Синтез на 20 языках, 174 голоса; В список языков входят 5 языков народов СНГ: калмыцкий, русский, татарский, узбекский и украинский; В список языков входят 5 вариаций на тему романо-германских языков: английский, индийский английский, испанский, немецкий, французский; Также в список языков входят 10 языков народов Индии; Новую значительно улучшенную модель для простановки ударений и буквы ё со словарем в 4 миллиона слов и точностью 100% (но естественно с рядом оговорок); ё Все модели наследуют все "фишки" прошлого релиза, кроме автоматической простановки ударений для языков отличных от русского;  Пока улучшение интерфейсов мы отложили на некоторое время. Ускорить модели еще в 3+ раза мы тоже смогли, но пока с потерей качества, что не позволило нам обновить их прямо в этом релизе.  Попробовать модель как обычно можно в нашем репозитории и в колабе. репозитории колабе   Как попробовать  Для самых нетерпеливых — вот основные примеры звучания на русском языке:  Примеры звучания моделей на русском языке Примеры звучания моделей на русском языке     Как обычно, все инструкции, все модели и языки можно найти: Как обычно, все инструкции, все модели и языки можно найти:  В нашем публичном репозитории по ссылке. Вам нужны модели для синтеза v3;
Или можно прямо в колабе; В нашем публичном репозитории по ссылке. Вам нужны модели для синтеза v3; ссылке v3 Или можно прямо в колабе; колабе  Вот самый минималистичный пример вызова модели:  import torch

device = torch.device('cpu')
torch.set_num_threads(4)
speaker = 'xenia'  # 'aidar', 'baya', 'kseniya', 'xenia', 'eugene', 'random'
sample_rate = 48000  # 8000, 24000, 48000

model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',
                                     model='silero_tts',
                                     language='v3_1_ru')
model.to(device)
audio = model.apply_tts(text=example_text,
                        speaker=speaker,
                        sample_rate=sample_rate) import torch

device = torch.device('cpu')
torch.set_num_threads(4)
speaker = 'xenia'  # 'aidar', 'baya', 'kseniya', 'xenia', 'eugene', 'random'
sample_rate = 48000  # 8000, 24000, 48000

model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',
                                     model='silero_tts',
                                     language='v3_1_ru')
model.to(device)
audio = model.apply_tts(text=example_text,
                        speaker=speaker,
                        sample_rate=sample_rate)  Спикеров и принимаемые символы для каждой модели можно посмотреть в свойствах модели model.speakers и model.symbols. model.speakers model.symbols  Или вот такой пример, если вы хотите скачать модель к себе более явно в кеш: Или вот такой пример, если вы хотите скачать модель к себе более явно в кеш:     Больше примеров вы можете найти по ссылкам в репозитории. С недавнего времени у моделей также появился своё pip-пакет, аналогичный по функционалу импорту через torch.hub. pip torch.hub  Более подробное описание всех фишек, связанных с управлением голосом вы сможете найти в прошлой cтатье, тут не будем повторяться. cтатье  Новые модели и языки  Язык модели Название модели Число языков Число голосов
Английский v3_en 1 118
Английский (Индия) v3_en_indic 1 15
Испанский v3_es 1 3
Калмыцкий v3_xal 1 2
Немецкий v3_de 1 5
Русский v3_1_ru 1 5
Татарский v3_tt 1 1
Узбекский v3_uz 1 1
Украинский v3_ua 1 1
Французский v3_fr 1 6
Языки народов Индии v3_indic 10 17 Язык модели Название модели Число языков Число голосов
Английский v3_en 1 118
Английский (Индия) v3_en_indic 1 15
Испанский v3_es 1 3
Калмыцкий v3_xal 1 2
Немецкий v3_de 1 5
Русский v3_1_ru 1 5
Татарский v3_tt 1 1
Узбекский v3_uz 1 1
Украинский v3_ua 1 1
Французский v3_fr 1 6
Языки народов Индии v3_indic 10 17 Язык модели Название модели Число языков Число голосов
Английский v3_en 1 118
Английский (Индия) v3_en_indic 1 15
Испанский v3_es 1 3
Калмыцкий v3_xal 1 2
Немецкий v3_de 1 5
Русский v3_1_ru 1 5
Татарский v3_tt 1 1
Узбекский v3_uz 1 1
Украинский v3_ua 1 1
Французский v3_fr 1 6
Языки народов Индии v3_indic 10 17 Язык модели Название модели Число языков Число голосов Язык модели Название модели Число языков Число голосов Язык модели Название модели Число языков Число голосов Английский v3_en 1 118
Английский (Индия) v3_en_indic 1 15
Испанский v3_es 1 3
Калмыцкий v3_xal 1 2
Немецкий v3_de 1 5
Русский v3_1_ru 1 5
Татарский v3_tt 1 1
Узбекский v3_uz 1 1
Украинский v3_ua 1 1
Французский v3_fr 1 6
Языки народов Индии v3_indic 10 17 Английский v3_en 1 118 Английский v3_en v3_en 1 118 Английский (Индия) v3_en_indic 1 15 Английский (Индия) v3_en_indic v3_en_indic 1 15 Испанский v3_es 1 3 Испанский v3_es v3_es 1 3 Калмыцкий v3_xal 1 2 Калмыцкий v3_xal v3_xal 1 2 Немецкий v3_de 1 5 Немецкий v3_de v3_de 1 5 Русский v3_1_ru 1 5 Русский v3_1_ru v3_1_ru 1 5 Татарский v3_tt 1 1 Татарский v3_tt v3_tt 1 1 Узбекский v3_uz 1 1 Узбекский v3_uz v3_uz 1 1 Украинский v3_ua 1 1 Украинский v3_ua v3_ua 1 1 Французский v3_fr 1 6 Французский v3_fr v3_fr 1 6 Языки народов Индии v3_indic 10 17 Языки народов Индии v3_indic v3_indic 10 17  Для всех моделей с более чем одним спикером доступен "случайный" спикер.  Чтобы не делать статью гигантской, просто приведу примеры звучания для каждого языка под спойлером. Попробовать модели как обычно вы можете:  В нашем публичном репозитории по ссылке. Вам нужны модели для синтеза v3;
Или можно прямо в колабе; В нашем публичном репозитории по ссылке. Вам нужны модели для синтеза v3; ссылке v3 Или можно прямо в колабе; колабе  Примеры звучания моделей на каждом языке Примеры звучания моделей на каждом языке                                                         Улучшение модели простановки ударений     Но если без шуток, то задача простановки ударений оказалась сильно сложнее, чем предполагалось, но мы смогли добиться в ней впечатляющего прогресса. Если коротко, то нам удалось:  Собрать словарь ударений размером примерно в 4 миллиона слов с высоким покрытием разных корпусов;
Натренировать максимально сжатую модель, выдающую точность 100% (это не ошибка) на таком словаре общим размером менее 2.6 мегабайт (!);
Инициировать итерационный процесс улучшения и проверки словаря;
Добиться нетривиальной точности на омографах (но в текущий релиз эти модели пока не вошли) в районе 80%; Собрать словарь ударений размером примерно в 4 миллиона слов с высоким покрытием разных корпусов; Натренировать максимально сжатую модель, выдающую точность 100% (это не ошибка) на таком словаре общим размером менее 2.6 мегабайт (!); Инициировать итерационный процесс улучшения и проверки словаря; Добиться нетривиальной точности на омографах (но в текущий релиз эти модели пока не вошли) в районе 80%;  Сложность такой задачи покоится на 3 китах:  Сложность сбора и валидации большого и качественного словаря с ударениями;
Сложность "упаковки" и сжатия быстрой модели, которая со 100% точностью расставляет ударения на заданном словаре;
Сложность обработки большого количества краевых Сложность сбора и валидации большого и качественного словаря с ударениями; Сложность "упаковки" и сжатия быстрой модели, которая со 100% точностью расставляет ударения на заданном словаре; Сложность обработки большого количества краевых  Про каждый из этих пунктов мы отдельно расскажем.  Словарь  Нам удалось собрать словарь размером примерно в 4 миллиона слов. Эти 4 миллиона слов примерно разбиваются на следующие категории:  Примерно 100,000 частотных слов (5,000 и более вхождений), P95;
Примерно 1,000,000 слов средней частоты (100 и более вхождений), P50;
Примерно 3,000,000 "редких" слов; Примерно 100,000 частотных слов (5,000 и более вхождений), P95; P95 Примерно 1,000,000 слов средней частоты (100 и более вхождений), P50; P50 Примерно 3,000,000 "редких" слов;  Из этих 4 миллионов слов примерно 100 тысяч имели "спорное" ударение и были "кандидатами" в омографы. Из этих 100 тысяч у нас получилось выделить следующие категории:  50,000 сложных слов с 2 ударениями — мы ими пока просто пренебрегли (и оставили только основное ударение);
15,000 частотных слов — "кандидатов" в омографы;
35,000 слов — "длинный хвост"; 50,000 сложных слов с 2 ударениями — мы ими пока просто пренебрегли (и оставили только основное ударение); 15,000 частотных слов — "кандидатов" в омографы; 35,000 слов — "длинный хвост";  Из 15,000 самых популярных "кандидатов" для части слов (примерно 5,000 штук) мы смогли найти наиболее популярную форму с помощью морфологических парсеров и принять ее за "эталонную". Для остальных — мы просто случайно выбрали одну из форм. Это одна из проблем словаря.  Другая проблема состоит в том, что в словаре много мусора или очень редких форм и часть слов из топовых 100,000 слов имеет просто неверное ударение.  Тут небольшая ремарка, на момент отправки статью в публикацию, мы успели проверить 20,000 самых популярных слов из словаря. Процесс автоматизированный и с многократной проверкой, но естественно не идеальный. Мы добились того, что наша модель выдает 100% точность на нашем словаре, но в голове нужно держать этот ряд оговорок: 100% точность на нашем словаре  Часть ударений просто неверная;
Для известных нам "настоящих" омографов стоит по умолчанию более популярная форма;
Для части слов ударение было поставлено случайно из имеющихся опций;
Процесс проверки топ 100,000 самых популярных слов все еще идет (проверено 20,000 слов); Часть ударений просто неверная; Для известных нам "настоящих" омографов стоит по умолчанию более популярная форма; Для части слов ударение было поставлено случайно из имеющихся опций; Процесс проверки топ 100,000 самых популярных слов все еще идет (проверено 20,000 слов);  Чтобы дать примерную оценку качества нашего словаря приведем статистику покрытия на популярных интернет корпусах:  Домен Текстов Словарь … P95 Покрытие текстов, % … словаря, % … P95, %
Финансы 39,357,993 289,182 11,531 90.9 76.05 95.37
Common Crawl 300,021,148 536,319 17,236 90.07 61.7 95.99
Книги 100,013,036 903,862 29,268 91.09 61.71 95.27
Новости 25,403,505 839,365 14,559 82.53 32.09 92.49
Субтитры 44,641,621 299,061 11,764 92.82 73.14 92.97
Поэзия, литература 100,014,088 824,830 28,031 92.56 66.38 97.65
Википедия 29 401,392 768,451 21,916 85.93 54.78 96
Общая статистика 638,852,783 1,382,006 73,556 90.69 51.57 93.28 Домен Текстов Словарь … P95 Покрытие текстов, % … словаря, % … P95, %
Финансы 39,357,993 289,182 11,531 90.9 76.05 95.37
Common Crawl 300,021,148 536,319 17,236 90.07 61.7 95.99
Книги 100,013,036 903,862 29,268 91.09 61.71 95.27
Новости 25,403,505 839,365 14,559 82.53 32.09 92.49
Субтитры 44,641,621 299,061 11,764 92.82 73.14 92.97
Поэзия, литература 100,014,088 824,830 28,031 92.56 66.38 97.65
Википедия 29 401,392 768,451 21,916 85.93 54.78 96
Общая статистика 638,852,783 1,382,006 73,556 90.69 51.57 93.28 Домен Текстов Словарь … P95 Покрытие текстов, % … словаря, % … P95, %
Финансы 39,357,993 289,182 11,531 90.9 76.05 95.37
Common Crawl 300,021,148 536,319 17,236 90.07 61.7 95.99
Книги 100,013,036 903,862 29,268 91.09 61.71 95.27
Новости 25,403,505 839,365 14,559 82.53 32.09 92.49
Субтитры 44,641,621 299,061 11,764 92.82 73.14 92.97
Поэзия, литература 100,014,088 824,830 28,031 92.56 66.38 97.65
Википедия 29 401,392 768,451 21,916 85.93 54.78 96
Общая статистика 638,852,783 1,382,006 73,556 90.69 51.57 93.28 Домен Текстов Словарь … P95 Покрытие текстов, % … словаря, % … P95, % Домен Текстов Словарь … P95 Покрытие текстов, % … словаря, % … P95, % Домен Текстов Словарь … P95 Покрытие текстов, % … словаря, % … P95, % Финансы 39,357,993 289,182 11,531 90.9 76.05 95.37
Common Crawl 300,021,148 536,319 17,236 90.07 61.7 95.99
Книги 100,013,036 903,862 29,268 91.09 61.71 95.27
Новости 25,403,505 839,365 14,559 82.53 32.09 92.49
Субтитры 44,641,621 299,061 11,764 92.82 73.14 92.97
Поэзия, литература 100,014,088 824,830 28,031 92.56 66.38 97.65
Википедия 29 401,392 768,451 21,916 85.93 54.78 96
Общая статистика 638,852,783 1,382,006 73,556 90.69 51.57 93.28 Финансы 39,357,993 289,182 11,531 90.9 76.05 95.37 Финансы 39,357,993 289,182 11,531 90.9 76.05 95.37 Common Crawl 300,021,148 536,319 17,236 90.07 61.7 95.99 Common Crawl 300,021,148 536,319 17,236 90.07 61.7 95.99 Книги 100,013,036 903,862 29,268 91.09 61.71 95.27 Книги 100,013,036 903,862 29,268 91.09 61.71 95.27 Новости 25,403,505 839,365 14,559 82.53 32.09 92.49 Новости 25,403,505 839,365 14,559 82.53 32.09 92.49 Субтитры 44,641,621 299,061 11,764 92.82 73.14 92.97 Субтитры 44,641,621 299,061 11,764 92.82 73.14 92.97 Поэзия, литература 100,014,088 824,830 28,031 92.56 66.38 97.65 Поэзия, литература 100,014,088 824,830 28,031 92.56 66.38 97.65 Википедия 29 401,392 768,451 21,916 85.93 54.78 96 Википедия 29 401,392 768,451 21,916 85.93 54.78 96 Общая статистика 638,852,783 1,382,006 73,556 90.69 51.57 93.28 Общая статистика 638,852,783 1,382,006 73,556 90.69 51.57 93.28  Словарь корпуса включает в себя только слова, встречающиеся более 10 раз (иначе общий словарь всех корпусов вырастет до 40 миллионов "слов").  Также для удобства пользования мы выкладываем наш словарь омографов и словарь из слов "кандидатов" в омографы, на которых мы случайно проставили ударение. словарь омографов "кандидатов" в омографы  Также опережая очевидный вопрос, почему покрытие P95 не составляет 100%, мы посмотрели каких слов не хватает. В основном там:  Имена собственные;
Артефакты процессинга текста и склеенные слова (например, "такойчто" или "неизвестнокогда");
Cлова вроде "хм-м", "ааа";
И довольно редко встречаются недостающие формы существующих слов; Имена собственные; Артефакты процессинга текста и склеенные слова (например, "такойчто" или "неизвестнокогда"); Cлова вроде "хм-м", "ааа"; И довольно редко встречаются недостающие формы существующих слов;  Со всеми вышеописанными оговорками, наше решение имеет точность в 100% на нашем словаре и занимает примерно 0.2 миллисекунды на 1 слово. Со всеми вышеописанными оговорками, наше решение имеет точность в 100% на нашем словаре и занимает примерно 0.2 миллисекунды на 1 слово.  Сравнение с публичными инструментами  Ради интереса, мы также сравнили метрики на нашем словаре с другими публично доступными решениями для простановки ударений:  Инструмент Точность на всём словаре, % … на словаре P95, % … на словаре P50, %
espeak 89.58 95.86 81.37
russtress 89.47 91.98 85.63
russian_accentuation 70.3 83.86 58.86 Инструмент Точность на всём словаре, % … на словаре P95, % … на словаре P50, %
espeak 89.58 95.86 81.37
russtress 89.47 91.98 85.63
russian_accentuation 70.3 83.86 58.86 Инструмент Точность на всём словаре, % … на словаре P95, % … на словаре P50, %
espeak 89.58 95.86 81.37
russtress 89.47 91.98 85.63
russian_accentuation 70.3 83.86 58.86 Инструмент Точность на всём словаре, % … на словаре P95, % … на словаре P50, % Инструмент Точность на всём словаре, % … на словаре P95, % … на словаре P50, % Инструмент Точность на всём словаре, % … на словаре P95, % … на словаре P50, % espeak 89.58 95.86 81.37
russtress 89.47 91.98 85.63
russian_accentuation 70.3 83.86 58.86 espeak 89.58 95.86 81.37 espeak espeak 89.58 95.86 81.37 russtress 89.47 91.98 85.63 russtress russtress 89.47 91.98 85.63 russian_accentuation 70.3 83.86 58.86 russian_accentuation russian_accentuation 70.3 83.86 58.86  Сжатие модели  Словарь на 4 миллиона слов весит примерно 100 мегабайт. Наша модель весит примерно 2.6 мегабайта.  Сжатие Размер, MB Сжатие, раз
Словарь 98 1.0
Словарь + gzip 23 4.3
Наша модель 2.6 37.7 Сжатие Размер, MB Сжатие, раз
Словарь 98 1.0
Словарь + gzip 23 4.3
Наша модель 2.6 37.7 Сжатие Размер, MB Сжатие, раз
Словарь 98 1.0
Словарь + gzip 23 4.3
Наша модель 2.6 37.7 Сжатие Размер, MB Сжатие, раз Сжатие Размер, MB Сжатие, раз Сжатие Размер, MB Сжатие, раз Словарь 98 1.0
Словарь + gzip 23 4.3
Наша модель 2.6 37.7 Словарь 98 1.0 Словарь 98 1.0 Словарь + gzip 23 4.3 Словарь + gzip 23 4.3 Наша модель 2.6 37.7 Наша модель 2.6 37.7  То есть у нас получилось с учетом всех вспомогательных файлов и весов модели добиться сжатия словаря примерно в 40 раз. Мое личное мнение — это отличный результат.  Причем если словарь допустим увеличить до 10 миллионов слов, размер модели должен вырасти в сильно меньшей пропорции.  Краевые случаи  Для полноты картины опишем явно известные нам, решенные и еще не решенные краевые случаи.  Решенные краевые случаи: Решенные краевые случаи:  Такие слова как как-то, кое-кто, где-нибудь, итд;
Возможность сохранения авторской пунктуации;
Возможность использования проставленного пользователем ударения и проставленной буквы ё;
Разного рода "сложные" слова через дефис (например квадратно-гнездовой); Такие слова как как-то, кое-кто, где-нибудь, итд; как-то кое-кто где-нибудь Возможность сохранения авторской пунктуации; Возможность использования проставленного пользователем ударения и проставленной буквы ё; ё Разного рода "сложные" слова через дефис (например квадратно-гнездовой); квадратно-гнездовой  Частично и ещё не решенные краевые случаи: Частично и ещё не решенные краевые случаи:  Ручная чистка и проверка 100,000 самых популярных слов в словаре;
Омографы, настоящие и "кандидаты" в омографы;
Настоящие слова с 2 ударениями (например заднеприводный); Ручная чистка и проверка 100,000 самых популярных слов в словаре; Омографы, настоящие и "кандидаты" в омографы; Настоящие слова с 2 ударениями (например заднеприводный); заднеприводный  Генерализация модели  Модель так построена, что она в первую очередь хорошо умеет запоминать слова. Но ее архитектура не мешает ей иметь ограниченную генерализацию. В общем — чем длиннее слово — тем лучше генерализация.  И естественно мы пробовали подавать ей разного рода экзотические текста, и в целом по нашим наблюдениям:  В именах, особенно коротких, часто бывает рандом;
В длинных и составных словах модель чувствует себя получше;
В выдуманных и составных русских словах ударение обычно ставится правильно; В именах, особенно коротких, часто бывает рандом; В длинных и составных словах модель чувствует себя получше; В выдуманных и составных русских словах ударение обычно ставится правильно;  Несколько примеров:  гл+окая к+уздра кудлан+ула б+окра +и кудр+ячит бокренк+а

Ег+о н+е призн+али в г+ороде родн+ом +и вс+е ег+о шпын+яли +и н+очью, +и дн+ём. Н+е ст+оит огорч+аться +и н+е ст+оит роб+еть, +а л+учше +эту п+есенку вм+есте проп+еть: "К+отопес! К+отопес! Ед+инственный в м+ире мал+ыш К+отопес!

П+осле П+ервой войн+ы с Мельк+ором Вал+ар воздв+игли в Ард+е дв+а Вел+иких Свет+ильника +и созд+али п+ервое корол+евство н+а +острове Алмарен.
+Этому д+олгому м+иру приш+ёл кон+ец, когд+а Мельк+ор т+айно верн+улся в +Арду +и низв+ерг Свет+ильники. Вал+ар в Ам+ане основ+али втор+ое корол+евство Валин+ор.
Йав+анна в+ырастила дв+а Др+ева Св+ета, кот+орые освещ+али Валин+ор, н+о оставл+яли Средиз+емье в+о тьм+е Мельк+ора. В б+олее п+оздних эп+охах +эти дер+евья дал+и плод+ы, кот+орые ст+али С+олнцем +и Лун+ой.

с+аша +аня паш+а м+аша зуб+арджат аннаб+ель +анна-мар+ия ангел+ина лар+иса нат+аша д+аша игн+ат иннок+ентий дил+яра караб+ас-бар+абас бурат+ино пуш+инчик ман+я юр+а +юрий +юрасик          Дальнейшие планы  Мы не планируем останавливаться на достигнутом и собираемся продолжать развивать наш синтез:  Ускорить его еще в несколько раз;
Прикрутить квантизацию и ONNX для какой-то кастрированной версии синтеза, тем самым возможно ускорив его еще в 2-4 раза;
Проверить все 100,000 слов на предмет правильности ударений;
Решить хотя бы самые частотные омографы;
Добавить возможность использовать фонемы напрямую для синтеза для произношения сложных слов и аббревиатур;
Дальше развивать фишки по управлению интонацией речи и произношением; Ускорить его еще в несколько раз; Прикрутить квантизацию и ONNX для какой-то кастрированной версии синтеза, тем самым возможно ускорив его еще в 2-4 раза; Проверить все 100,000 слов на предмет правильности ударений; Решить хотя бы самые частотные омографы; Добавить возможность использовать фонемы напрямую для синтеза для произношения сложных слов и аббревиатур; Дальше развивать фишки по управлению интонацией речи и произношением;]]></text>
</doc>
