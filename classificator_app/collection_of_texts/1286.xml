<?xml version="1.0" ?>
<doc>
	<original_author auto="true" type="list" verify="true">
		<item type="str"><![CDATA[Chanin Nantasenamat]]></item>
	</original_author>
	<label auto="true" type="str" verify="true"><![CDATA[Other]]></label>
	<author auto="true" type="list" verify="true">
		<item type="str"><![CDATA[honyaki]]></item>
	</author>
	<date auto="true" type="str" verify="true"><![CDATA[2022-06-01, 23:36]]></date>
	<link auto="true" type="str" verify="true"><![CDATA[https://habr.com/ru/company/skillfactory/blog/669126/]]></link>
	<title auto="true" type="str" verify="true"><![CDATA[Как с помощью Python создать приложение для расшифровки речи в реальном времени]]></title>
	<categories auto="true" type="list" verify="true">
		<item type="str"><![CDATA[Блог компании SkillFactory]]></item>
		<item type="str"><![CDATA[Разработка веб-сайтов]]></item>
		<item type="str"><![CDATA[Python]]></item>
		<item type="str"><![CDATA[Программирование]]></item>
		<item type="str"><![CDATA[Голосовые интерфейсы]]></item>
	</categories>
	<key_words auto="true" type="list" verify="true">
		<item type="str"><![CDATA[skillfactory]]></item>
		<item type="str"><![CDATA[речь]]></item>
		<item type="str"><![CDATA[текст]]></item>
		<item type="str"><![CDATA[речь в текст]]></item>
		<item type="str"><![CDATA[streamlit]]></item>
		<item type="str"><![CDATA[api]]></item>
		<item type="str"><![CDATA[распознавание]]></item>
		<item type="str"><![CDATA[голос]]></item>
		<item type="str"><![CDATA[интерфейс]]></item>
		<item type="str"><![CDATA[интерактивность]]></item>
	</key_words>
	<text auto="true" type="str" verify="true"><![CDATA[Пошаговое руководство с использованием AssemblyAI и Streamlit
Научить ИИ разговаривать шёпотом — непростая задача даже сегодня. Но мы покажем, насколько простыми стали распознавание и транскрипция речи, по крайней мере, на поверхности. Интересно? Тогда добро пожаловать под кат.
Материал подготовлен к старту курса по Fullstack-разработке на Python.
Введение
Приложение расшифровки речи в режиме реального времени автоматически преобразует речь в текст. Этот текст почти мгновенно отображается на экране, а использовать подобные приложения можно для самых разных целей, включая расшифровку лекций, конференций и встреч. Здесь есть ряд преимуществ:
можно сразу записывать идеи и беседы. Это очень полезная функция для людей, которые работают в быстро меняющейся среде, и для людей с большим количеством идей;
развивать навыки общения, ведь теперь вы увидите, как говорите вы сами и как говорят другие.
Такими приложениями могут пользоваться люди с нарушением слуха или те, кто учит английский. Приложение расшифровывает аудио в реальном времени, а пользователь видит текст на экране параллельно произношению слов. К тексту можно применить обработку естественного языка.
Мы научимся создавать приложение для динамического преобразования речи в текст и сделаем это с помощью API AssemblyAI (серверная часть) и Streamlit (клиентская часть).
Вот видеоверсия статьи:
Обзор приложения
Для приложения понадобятся следующие библиотеки для Python:
streamlit — веб-фреймворком воспользуемся для размещения всех виджетов ввода и вывода;
websocket — позволяет приложению взаимодействовать с API AssemblyAI;
asyncio — позволяет выполнять всевозможный речевой ввод и вывод асинхронно;
base64 — кодирует и декодирует аудиосигнал перед его отправкой в API AssemblyAI;
json — считывает речевой вывод, сгенерированный через API AssemblyAI (например, расшифрованный текст);
pyaudio — обрабатывает речевой ввод через библиотеку PortAudio;
os и pathlib — используются для перехода по различным папкам проекта и работы с файлами.
Настройка рабочей среды
Чтобы воссоздать приложение для динамической расшифровки речи на вашем компьютере, мы создадим среду conda под названием transcription:
conda create -n transcription python=3.9
Возможно, высветится запрос на установку зависимостей Python-библиотеки. Если так, нажмите клавишу Y, чтобы подтвердить действие и продолжить.
После создания среды conda активировать её можно так:
conda activate transcription
Делать это нужно каждый раз в начале написания кода, а по завершении работы с кодом из среды нужно выйти:
conda deactivate
Загрузка GitHub-репозитория
Загрузим с GitHub весь репозиторий приложения динамической расшифровки речи:
git clone https://github.com/dataprofessor/realtime-transcription
Переходим в папку realtime-transcription:
cd realtime-transcription
Можно установить обязательные библиотеки, которыми пользуется приложение:
pip install -r requirements.txt
Получение ключа от API AssemblyAI
Получить доступ к API в AssemblyAI крайне просто. Для начала зарегистрируйтесь на AssemblyAI, это бесплатно. Зайдите в учётную запись. На панели справа вы увидите API-ключ:
Как получить API-ключ в AssemblyAI
Теперь, когда вы скопировали API-ключ в память, необходимо добавить его в файл secrets.toml из папки.streamlit. Путь к файлу выглядит так: .streamlit/secrets.toml. Его содержание должно быть таким:
api_key = 'xxxxx'
Вместо xxxxx вставьте свой ключ от API. Получить этот ключ мы сможем с помощью строки кода st.secrets[‘api_key’].
Запуск приложения
Прежде чем запускать приложение, давайте рассмотрим содержимое рабочей директории (то, что открывается по команде tree в Bash):
 Содержимое папки realtime-transcription
Теперь мы готовы запустить своё приложение:
streamlit run streamlit_app.py
Этот код позволит открыть приложение в новом окне браузера:
Скриншот приложения
 Посмотрим, как работает приложение:
Работа приложения
 Объяснение кода
Ниже объясняется базовый код приложения.
Строки 1–8 — импорт обязательных библиотек веб-приложения.
Строки 10-13 — начальное состоянии сессии приложения.
Строки 15-22 — ввод для приём пользовательского ввода параметров аудио представлены виджетом text_input.
Строки 24-31 — для открытия потока аудиоданных через pyaudio используются входные параметры аудио из блока кода выше.
Строки 33-46 — определяют 3 пользовательские функции (например, start_listening, stop_listening и download_transcription), которые будут вызываться в коде (см. ниже).
Строка 49 — отображает название приложения через строку st.title.
Строки 51–62 — отображает информацию о приложении (раздел About) с помощью строки st.expander.
Строки 64–67 — создают 2 столбца строкой st.columns для размещения кнопок «Пуск» (Start) и «Стоп» (Stop). То есть они используют start_listening и stop_listening через параметр on_click виджета кнопки.
Строки 69–139 — здесь выполняется обработка речевого входа и выхода: аудиосигнал передаётся в API AssemblyAI, где расшифрованный текст выдаётся в формате JSON. Эта часть была изменена и адаптирована из блока кода, написанного Мисрой Турп и Джорджиосом Мириантусом. 
Строки 141–144 — отображают кнопку загрузки расшифровки, а затем удаляют файл.
Весь код
Заключение
Поздравляем, вы создали приложение для динамического преобразования речи на Python с помощью API AssemblyAI. Как уже говорилось, у таких приложений есть несколько вариантов использования (диктовка статьи/сочинения или письма, развитие навыков общения, преобразование речи для людей с нарушением слуха и т. д.).
Вы можете поступить как автор, то есть снова адаптировать код, уже для российских голосовых API. А мы поможем прокачать ваши навыки или с самого начала освоить профессию, актуальную в любое время:
Профессия Fullstack-разработчик на Python
Профессия Data Scientist
Выбрать другую востребованную профессию. Пошаговое руководство с использованием AssemblyAI и Streamlit ]]></text>
</doc>
