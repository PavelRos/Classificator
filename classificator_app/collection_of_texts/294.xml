<?xml version="1.0" ?>
<doc>
	<label auto="true" type="str" verify="true"><![CDATA[Develop]]></label>
	<author auto="true" type="list" verify="true">
		<item type="str"><![CDATA[dumperize]]></item>
	</author>
	<date auto="true" type="str" verify="true"><![CDATA[2022-12-09, 04:56]]></date>
	<link auto="true" type="str" verify="true"><![CDATA[https://habr.com/ru/post/704432/]]></link>
	<title auto="true" type="str" verify="true"><![CDATA[Optuna. Подбор гиперпараметров для вашей модели]]></title>
	<categories auto="true" type="list" verify="true">
		<item type="str"><![CDATA[Python]]></item>
		<item type="str"><![CDATA[Big Data]]></item>
		<item type="str"><![CDATA[Машинное обучение]]></item>
		<item type="str"><![CDATA[Искусственный интеллект]]></item>
	</categories>
	<key_words auto="true" type="list" verify="true">
		<item type="str"><![CDATA[optuna]]></item>
		<item type="str"><![CDATA[подбор гиперпараметров]]></item>
		<item type="str"><![CDATA[machinelearning]]></item>
		<item type="str"><![CDATA[data science]]></item>
	</key_words>
	<text auto="true" type="str" verify="true"><![CDATA[Гиперпараметры — это характеристики модели, которые фиксируются до начала обучения (например - глубина решающего дерева, значение силы регуляризации в линейной модели, learning rate для градиентного спуска). Гиперпараметры, в отличие от параметров задаются разработчиком модели перед ее обучением, в свою очередь параметры модели настраиваются в процессе обучения модели на данных.
Optuna — это фреймворк для для автоматизированного поиска оптимальных гиперпараметров для моделей машинного обучения. Она подбирает эти параметры методом проб и ошибок.
Ключевые особенности фреймворка:
Настраиваемое пространство поиска гиперпараметров. Разработчик может самостоятельно задать пространство для поиска гиперпараметров, используя базовый синтаксис Python (циклы, условия).
Алгоритмы SoTA для выбора гиперпараметров из пространства заданного разработчиком (samplers) и для ранней остановки бесперспективных экспериментов (pruners). В Optuna представлены различные алгоритмы семплирования и прунинга, разработчик может выбрать какой-то конкретный, оставить дефолтный, или написать свой собственный.
Легкость расспаралеливания процесса поиска гиперпараметров. Также к Optuna можно прикрутить dashboard с визуализацией обучения в реальном времени.
Установка
Рекомендуется установка через pip.
pip install optuna
Базовый пример
Этот фреймворк обычно используют как оптимизатор гиперпараметров, но никто не запрещает использовать ее для оптимизации любой функции.  В качестве базового примера использования, авторы фреймворка показывают как можно минимизировать квадратичную функцию  .
import optuna

def objective(trial):
    x = trial.suggest_float('x', -10, 10)
    return (x - 2) ** 2

study = optuna.create_study()
study.optimize(objective, n_trials=100)

study.best_params  # E.g. {'x': 2.002108042}
Определяем целевую функцию objective , в через аргументы она будет получать специальный объект trial. С его помощью можно назначать различные гипермараметры, Например, как в примере выше, мы задаем x в интервале .
Далее создаем объект обучения с помощью метода optuna.create_study.
Запускаем оптимизацию целевой функции objective на 100 итераций n_trials=100. Происходит 100 вызовов нашей функции с различными параметрам от -10 до 10. Какие именно параметры выбирает optuna будет описано ниже.
Как задать пространство поиска гиперпараметров?
Как было показано выше в целевую функцию будет передан специальный объект Trial. Так как наша целевая функция будет вызываться некоторое число раз, на каждом вызове из объекта Trial будут возвращаться новые значения параметров. Разработчику остается только задать характеристики этих параметров. Для этого есть несколько методов:
suggest_categorical(name, choice) задает категориальные параметры. Пример
suggest_float(name, low, high, *, step=None, log=False) задает параметр типа float - число с плавающей точкой. Пример
suggest_int(name, low, high, step=1, log=False) задает параметр типа int - целое число. Пример
Что еще можно настроить до начала оптимизации?
Чтобы запустить обучение нам необходимо создать объект Study. Его рекомендуется создавать либо с помощью метода create_study (пример) или load_study (пример).
В момент создания можно указать:
направление оптимизации функции directions- минимизация или максимизация
storage адрес базы данных, для сохранения результатов испытаний
study_name имя, если не указать, то будет сгенерировано автоматически. Указание собственного имени, удобно при сохранении экспериментов и их загрузке
pruner и sampler - об этом ниже
После создания объекта Study, можно приступать к оптимизации целевой функции. Сделать это можно с помощью метода optimize (пример).
Как посмотреть результаты оптимизации?
В объекте Study есть специальные поля, которые позволяют посмотреть результаты после обучения:
study.best_params лучшие параметры
study.best_value  лучшее оптимальное значение целевой функции
study.best_trial развернутые параметры лучшего испытания
Как сохранить/загрузить результаты испытаний?
Сохранить только историю в виде датафрейма
df = study.trials_dataframe()
df.to_csv('study.csv')
loaded = pd.read_csv('study.csv')
Сохранить дамп самого оптимизатора
joblib.dump(study, 'experiments.pkl')
study_loaded = joblib.load('experiments.pkl')
study_loaded.trials_dataframe()
Можно также сохранять результаты испытаний в БД, для этого в Optuna есть специальный модуль Storages, который предоставляет некоторые объекты для взаимодействия БД. Например есть объект позволяющий взаимодействовать с redis. Пример.
Что такое Sampler и Pruner?
Samplers в Optuna это набор алгоритмов для поиска гиперпараметров.
Небольшой экскурс в теорию. Существуют различные подходы к поиску оптимальных гиперпараметров, ниже примеры алгоритмов:
Grid Search - поиск по решетке. Для каждого гиперпараметра задается список возможных значений, после перебираются все возможные комбинации элементов списков, выбирается тот набор на котором значение целевой функции было минимальным/максимальным.
Random Search - случайный поиск. Для каждого гиперпараметра задается распределение, из которого выбирается его значение. Благодаря такому подходу, найти оптимальный набор гиперпараметров можно быстрее.
Байесовская оптимизация. Итерационный метод, который на каждой итерации указывает наиболее вероятную точку, в которой наша целевая функция будет оптимальна. При этом выдаваемые вероятные точки включают две компоненты: 
хорошая точка там, где согласно истории функция выдавала хорошие результаты на предыдущих вызовах (exploitation) 
хорошая точка там, где высокая неопределенность, то есть неисследованные части пространства (exploration)
Более подробно про эти алгоритмы, а также про Tree-structured Parzen Estimator (TPE), Population Based Training (PBT) можно прочитать в учебнике по машинному обучению от Яндекс, там же можно найти ссылки на полезные ресурсы по этой теме и сравнение подходов между собой.
В Optuna реализованы:
GridSampler - Grid Search
RandomSampler - Random Search
TPESampler - Tree-structured Parzen Estimator
CmaEsSampler - Алгоритм на основе CMA-ES
PartialFixedSampler - Алгоритм с частично фиксированными параметрами
NSGAIISampler - Nondominated Sorting Genetic Algorithm II
MOTPESampler - Multiobjective tree-structured parzen estimator
QMCSampler - Quasi Monte Carlo
По умолчанию устанавливается TPESampler.
Pruners в Optuna - это набор алгоритмов для прореживания экспериментов. Pruning - это механизм который позволяет обрывать эксперименты , которые с большой долей вероятности приведут к не оптимальным результатам.
Для примера рассмотрим самый простой прунер - MedianPruner. Он обрезает на каждом шаге половину бесперспективных испытаний.
На каждой эпохе (шаге) Pruner отбрасывает ровно половину испытаний, после 3х эпох, лучшим остается 7 испытание, оно будет доведено до конца, остальные будут завершены раньше.
В Optuna реализованы: 
MedianPruner - pruner использующий правило половина останавливается, половина продолжает
NopPruner - pruner который никогда не останавливает испытания.
PatientPruner - pruner обертка над любым другим pruner, позволяет не останавливать бесперспективные испытания, пока не закончится терпение у PatientPruner еще несколько эпох.
PercentilePruner - pruner, который сохраняет определенный процентиль испытаний.
SuccessiveHalvingPruner - алгоритм Asynchronous Successive Halving
HyperbandPruner - алгоритм Hyperband
ThresholdPruner - pruner, который останавливает испытание, если значение целевой функции вышло за границы - превысило верхний порог или стало ниже чем нижний порог.
Какой Sampler и Pruner стоит использовать ?
В документации согласно этому исследованию “Benchmarks with Kurobako” для не глубогкого обучения стоит использовать:
Для RandomSampler лучший pruner - это MedianPruner.
Для TPESampler лучший pruner - это Hyperband.
В документации также приведены рекомендации для глубокого обучения.
Как подружить фреймворк с популярными библиотеками?
В Optuna есть модуль integration, который содержит классы, используемые для интеграции с внешними популярными библиотеками машинного обучения. Среди них есть такие библиотеки как CatBoost, fast.ai, Keras, LightGBM, PyTorch, scikit-learn, XGBoost. С полным списком можно ознакомится тут.
А что еще есть?
Есть модуль для визуализации, в нем представлены функции для построения графика процесса оптимизации с использованием plotly и matplotlib. Функции построения графиков обычно принимают объект Study и настроечные параметры.
Здесь пример построения графика истории оптимизации.
Есть модуль importance, с помощью него есть возможность провести оценку важности гиперпараметров на основе завершенных испытаний. Гиперпараметры — это характеристики модели, которые фиксируются до начала обучения (например - глубина решающего дерева, значение силы регуляризации в линейной модели, learning rate для градиентного спуска). Гиперпараметры, в отличие от параметров задаются разработчиком модели перед ее обучением, в свою очередь параметры модели настраиваются в процессе обучения модели на данных. Optuna — это фреймворк для для автоматизированного поиска оптимальных гиперпараметров для моделей машинного обучения. Она подбирает эти параметры методом проб и ошибок. Optuna Ключевые особенности фреймворка: Ключевые особенности фреймворка: Настраиваемое пространство поиска гиперпараметров. Разработчик может самостоятельно задать пространство для поиска гиперпараметров, используя базовый синтаксис Python (циклы, условия).
Алгоритмы SoTA для выбора гиперпараметров из пространства заданного разработчиком (samplers) и для ранней остановки бесперспективных экспериментов (pruners). В Optuna представлены различные алгоритмы семплирования и прунинга, разработчик может выбрать какой-то конкретный, оставить дефолтный, или написать свой собственный.
Легкость расспаралеливания процесса поиска гиперпараметров. Также к Optuna можно прикрутить dashboard с визуализацией обучения в реальном времени. Настраиваемое пространство поиска гиперпараметров. Разработчик может самостоятельно задать пространство для поиска гиперпараметров, используя базовый синтаксис Python (циклы, условия). Настраиваемое пространство поиска гиперпараметров. Разработчик может самостоятельно задать пространство для поиска гиперпараметров, используя базовый синтаксис Python (циклы, условия). Алгоритмы SoTA для выбора гиперпараметров из пространства заданного разработчиком (samplers) и для ранней остановки бесперспективных экспериментов (pruners). В Optuna представлены различные алгоритмы семплирования и прунинга, разработчик может выбрать какой-то конкретный, оставить дефолтный, или написать свой собственный. Алгоритмы SoTA для выбора гиперпараметров из пространства заданного разработчиком (samplers) и для ранней остановки бесперспективных экспериментов (pruners). В Optuna представлены различные алгоритмы семплирования и прунинга, разработчик может выбрать какой-то конкретный, оставить дефолтный, или написать свой собственный. Легкость расспаралеливания процесса поиска гиперпараметров. Также к Optuna можно прикрутить dashboard с визуализацией обучения в реальном времени. Легкость расспаралеливания процесса поиска гиперпараметров. Также к Optuna можно прикрутить dashboard с визуализацией обучения в реальном времени. Установка Рекомендуется установка через pip. Рекомендуется pip install optuna pip install optuna Базовый пример Этот фреймворк обычно используют как оптимизатор гиперпараметров, но никто не запрещает использовать ее для оптимизации любой функции.  В качестве базового примера использования, авторы фреймворка показывают как можно минимизировать квадратичную функцию  . .  import optuna

def objective(trial):
    x = trial.suggest_float('x', -10, 10)
    return (x - 2) ** 2

study = optuna.create_study()
study.optimize(objective, n_trials=100)

study.best_params  # E.g. {'x': 2.002108042} import optuna

def objective(trial):
    x = trial.suggest_float('x', -10, 10)
    return (x - 2) ** 2

study = optuna.create_study()
study.optimize(objective, n_trials=100)

study.best_params  # E.g. {'x': 2.002108042} Определяем целевую функцию objective , в через аргументы она будет получать специальный объект trial. С его помощью можно назначать различные гипермараметры, Например, как в примере выше, мы задаем x в интервале .
Далее создаем объект обучения с помощью метода optuna.create_study.
Запускаем оптимизацию целевой функции objective на 100 итераций n_trials=100. Происходит 100 вызовов нашей функции с различными параметрам от -10 до 10. Какие именно параметры выбирает optuna будет описано ниже. Определяем целевую функцию objective , в через аргументы она будет получать специальный объект trial. С его помощью можно назначать различные гипермараметры, Например, как в примере выше, мы задаем x в интервале . Определяем целевую функцию objective , в через аргументы она будет получать специальный объект trial. С его помощью можно назначать различные гипермараметры, Например, как в примере выше, мы задаем x в интервале . objective trial x  Далее создаем объект обучения с помощью метода optuna.create_study. Далее создаем объект обучения с помощью метода optuna.create_study. optuna.create_study Запускаем оптимизацию целевой функции objective на 100 итераций n_trials=100. Происходит 100 вызовов нашей функции с различными параметрам от -10 до 10. Какие именно параметры выбирает optuna будет описано ниже. Запускаем оптимизацию целевой функции objective на 100 итераций n_trials=100. Происходит 100 вызовов нашей функции с различными параметрам от -10 до 10. Какие именно параметры выбирает optuna будет описано ниже. objective n_trials=100 ниже Как задать пространство поиска гиперпараметров? Как было показано выше в целевую функцию будет передан специальный объект Trial. Так как наша целевая функция будет вызываться некоторое число раз, на каждом вызове из объекта Trial будут возвращаться новые значения параметров. Разработчику остается только задать характеристики этих параметров. Для этого есть несколько методов: Trial Trial suggest_categorical(name, choice) задает категориальные параметры. Пример
suggest_float(name, low, high, *, step=None, log=False) задает параметр типа float - число с плавающей точкой. Пример
suggest_int(name, low, high, step=1, log=False) задает параметр типа int - целое число. Пример suggest_categorical(name, choice) задает категориальные параметры. Пример suggest_categorical(name, choice) задает категориальные параметры. Пример suggest_categorical(name, choice) Пример suggest_float(name, low, high, *, step=None, log=False) задает параметр типа float - число с плавающей точкой. Пример suggest_float(name, low, high, *, step=None, log=False) задает параметр типа float - число с плавающей точкой. Пример suggest_float(name, low, high, *, step=None, log=False) float Пример suggest_int(name, low, high, step=1, log=False) задает параметр типа int - целое число. Пример suggest_int(name, low, high, step=1, log=False) задает параметр типа int - целое число. Пример suggest_int(name, low, high, step=1, log=False) int Пример Что еще можно настроить до начала оптимизации? Чтобы запустить обучение нам необходимо создать объект Study. Его рекомендуется создавать либо с помощью метода create_study (пример) или load_study (пример). Study. create_study ( пример пример ) load_study ( пример пример ) В момент создания можно указать: направление оптимизации функции directions- минимизация или максимизация
storage адрес базы данных, для сохранения результатов испытаний
study_name имя, если не указать, то будет сгенерировано автоматически. Указание собственного имени, удобно при сохранении экспериментов и их загрузке
pruner и sampler - об этом ниже направление оптимизации функции directions- минимизация или максимизация направление оптимизации функции directions- минимизация или максимизация directions storage адрес базы данных, для сохранения результатов испытаний storage адрес базы данных, для сохранения результатов испытаний storage  study_name имя, если не указать, то будет сгенерировано автоматически. Указание собственного имени, удобно при сохранении экспериментов и их загрузке study_name имя, если не указать, то будет сгенерировано автоматически. Указание собственного имени, удобно при сохранении экспериментов и их загрузке study_name  pruner и sampler - об этом ниже pruner и sampler - об этом ниже pruner   sampler  ниже После создания объекта Study, можно приступать к оптимизации целевой функции. Сделать это можно с помощью метода optimize (пример). optimize ( пример пример ) Как посмотреть результаты оптимизации? В объекте Study есть специальные поля, которые позволяют посмотреть результаты после обучения: study.best_params лучшие параметры
study.best_value  лучшее оптимальное значение целевой функции
study.best_trial развернутые параметры лучшего испытания study.best_params лучшие параметры study.best_params лучшие параметры study.best_params study.best_value  лучшее оптимальное значение целевой функции study.best_value  лучшее оптимальное значение целевой функции study.best_value study.best_trial развернутые параметры лучшего испытания study.best_trial развернутые параметры лучшего испытания study.best_trial Как сохранить/загрузить результаты испытаний? Сохранить только историю в виде датафрейма df = study.trials_dataframe()
df.to_csv('study.csv')
loaded = pd.read_csv('study.csv') df = study.trials_dataframe()
df.to_csv('study.csv')
loaded = pd.read_csv('study.csv') Сохранить дамп самого оптимизатора joblib.dump(study, 'experiments.pkl')
study_loaded = joblib.load('experiments.pkl')
study_loaded.trials_dataframe() joblib.dump(study, 'experiments.pkl')
study_loaded = joblib.load('experiments.pkl')
study_loaded.trials_dataframe() Можно также сохранять результаты испытаний в БД, для этого в Optuna есть специальный модуль Storages, который предоставляет некоторые объекты для взаимодействия БД. Например есть объект позволяющий взаимодействовать с redis. Пример. Storages Пример  Что такое Sampler и Pruner? Samplers в Optuna это набор алгоритмов для поиска гиперпараметров. Samplers Небольшой экскурс в теорию. Существуют различные подходы к поиску оптимальных гиперпараметров, ниже примеры алгоритмов: Grid Search - поиск по решетке. Для каждого гиперпараметра задается список возможных значений, после перебираются все возможные комбинации элементов списков, выбирается тот набор на котором значение целевой функции было минимальным/максимальным.
Random Search - случайный поиск. Для каждого гиперпараметра задается распределение, из которого выбирается его значение. Благодаря такому подходу, найти оптимальный набор гиперпараметров можно быстрее.
Байесовская оптимизация. Итерационный метод, который на каждой итерации указывает наиболее вероятную точку, в которой наша целевая функция будет оптимальна. При этом выдаваемые вероятные точки включают две компоненты: 
хорошая точка там, где согласно истории функция выдавала хорошие результаты на предыдущих вызовах (exploitation) 
хорошая точка там, где высокая неопределенность, то есть неисследованные части пространства (exploration) Grid Search - поиск по решетке. Для каждого гиперпараметра задается список возможных значений, после перебираются все возможные комбинации элементов списков, выбирается тот набор на котором значение целевой функции было минимальным/максимальным. Grid Search - поиск по решетке. Для каждого гиперпараметра задается список возможных значений, после перебираются все возможные комбинации элементов списков, выбирается тот набор на котором значение целевой функции было минимальным/максимальным. Random Search - случайный поиск. Для каждого гиперпараметра задается распределение, из которого выбирается его значение. Благодаря такому подходу, найти оптимальный набор гиперпараметров можно быстрее. Random Search - случайный поиск. Для каждого гиперпараметра задается распределение, из которого выбирается его значение. Благодаря такому подходу, найти оптимальный набор гиперпараметров можно быстрее. Random Search   Байесовская оптимизация. Итерационный метод, который на каждой итерации указывает наиболее вероятную точку, в которой наша целевая функция будет оптимальна. При этом выдаваемые вероятные точки включают две компоненты: 
хорошая точка там, где согласно истории функция выдавала хорошие результаты на предыдущих вызовах (exploitation) 
хорошая точка там, где высокая неопределенность, то есть неисследованные части пространства (exploration) Байесовская оптимизация. Итерационный метод, который на каждой итерации указывает наиболее вероятную точку, в которой наша целевая функция будет оптимальна. При этом выдаваемые вероятные точки включают две компоненты:   хорошая точка там, где согласно истории функция выдавала хорошие результаты на предыдущих вызовах (exploitation) 
хорошая точка там, где высокая неопределенность, то есть неисследованные части пространства (exploration) хорошая точка там, где согласно истории функция выдавала хорошие результаты на предыдущих вызовах (exploitation)  хорошая точка там, где согласно истории функция выдавала хорошие результаты на предыдущих вызовах (exploitation)  хорошая точка там, где высокая неопределенность, то есть неисследованные части пространства (exploration) хорошая точка там, где высокая неопределенность, то есть неисследованные части пространства (exploration) Более подробно про эти алгоритмы, а также про Tree-structured Parzen Estimator (TPE), Population Based Training (PBT) можно прочитать в учебнике по машинному обучению от Яндекс, там же можно найти ссылки на полезные ресурсы по этой теме и сравнение подходов между собой. учебнике по машинному обучению от Яндекс В Optuna реализованы: GridSampler - Grid Search
RandomSampler - Random Search
TPESampler - Tree-structured Parzen Estimator
CmaEsSampler - Алгоритм на основе CMA-ES
PartialFixedSampler - Алгоритм с частично фиксированными параметрами
NSGAIISampler - Nondominated Sorting Genetic Algorithm II
MOTPESampler - Multiobjective tree-structured parzen estimator
QMCSampler - Quasi Monte Carlo GridSampler - Grid Search GridSampler - Grid Search GridSampler RandomSampler - Random Search RandomSampler - Random Search RandomSampler TPESampler - Tree-structured Parzen Estimator TPESampler - Tree-structured Parzen Estimator TPESampler CmaEsSampler - Алгоритм на основе CMA-ES CmaEsSampler - Алгоритм на основе CMA-ES CmaEsSampler PartialFixedSampler - Алгоритм с частично фиксированными параметрами PartialFixedSampler - Алгоритм с частично фиксированными параметрами PartialFixedSampler NSGAIISampler - Nondominated Sorting Genetic Algorithm II NSGAIISampler - Nondominated Sorting Genetic Algorithm II NSGAIISampler MOTPESampler - Multiobjective tree-structured parzen estimator MOTPESampler - Multiobjective tree-structured parzen estimator MOTPESampler QMCSampler - Quasi Monte Carlo QMCSampler - Quasi Monte Carlo QMCSampler По умолчанию устанавливается TPESampler. TPESampler Pruners в Optuna - это набор алгоритмов для прореживания экспериментов. Pruning - это механизм который позволяет обрывать эксперименты , которые с большой долей вероятности приведут к не оптимальным результатам. Pruners Для примера рассмотрим самый простой прунер - MedianPruner. Он обрезает на каждом шаге половину бесперспективных испытаний. MedianPruner MedianPruner .  На каждой эпохе (шаге) Pruner отбрасывает ровно половину испытаний, после 3х эпох, лучшим остается 7 испытание, оно будет доведено до конца, остальные будут завершены раньше. В Optuna реализованы:  MedianPruner - pruner использующий правило половина останавливается, половина продолжает
NopPruner - pruner который никогда не останавливает испытания.
PatientPruner - pruner обертка над любым другим pruner, позволяет не останавливать бесперспективные испытания, пока не закончится терпение у PatientPruner еще несколько эпох.
PercentilePruner - pruner, который сохраняет определенный процентиль испытаний.
SuccessiveHalvingPruner - алгоритм Asynchronous Successive Halving
HyperbandPruner - алгоритм Hyperband
ThresholdPruner - pruner, который останавливает испытание, если значение целевой функции вышло за границы - превысило верхний порог или стало ниже чем нижний порог. MedianPruner - pruner использующий правило половина останавливается, половина продолжает MedianPruner - pruner использующий правило половина останавливается, половина продолжает MedianPruner NopPruner - pruner который никогда не останавливает испытания. NopPruner - pruner который никогда не останавливает испытания. NopPruner PatientPruner - pruner обертка над любым другим pruner, позволяет не останавливать бесперспективные испытания, пока не закончится терпение у PatientPruner еще несколько эпох. PatientPruner - pruner обертка над любым другим pruner, позволяет не останавливать бесперспективные испытания, пока не закончится терпение у PatientPruner еще несколько эпох. PatientPruner пока не закончится терпение у PatientPruner PercentilePruner - pruner, который сохраняет определенный процентиль испытаний. PercentilePruner - pruner, который сохраняет определенный процентиль испытаний. PercentilePruner SuccessiveHalvingPruner - алгоритм Asynchronous Successive Halving SuccessiveHalvingPruner - алгоритм Asynchronous Successive Halving SuccessiveHalvingPruner Asynchronous Successive Halving HyperbandPruner - алгоритм Hyperband HyperbandPruner - алгоритм Hyperband HyperbandPruner Hyperband ThresholdPruner - pruner, который останавливает испытание, если значение целевой функции вышло за границы - превысило верхний порог или стало ниже чем нижний порог. ThresholdPruner - pruner, который останавливает испытание, если значение целевой функции вышло за границы - превысило верхний порог или стало ниже чем нижний порог. ThresholdPruner Какой Sampler и Pruner стоит использовать ? В документации согласно этому исследованию “Benchmarks with Kurobako” для не глубогкого обучения стоит использовать: “Benchmarks with Kurobako” Для RandomSampler лучший pruner - это MedianPruner.
Для TPESampler лучший pruner - это Hyperband. Для RandomSampler лучший pruner - это MedianPruner. Для RandomSampler лучший pruner - это MedianPruner. Для TPESampler лучший pruner - это Hyperband. Для TPESampler лучший pruner - это Hyperband. В документации также приведены рекомендации для глубокого обучения. рекомендации для глубокого обучения. Как подружить фреймворк с популярными библиотеками? В Optuna есть модуль integration, который содержит классы, используемые для интеграции с внешними популярными библиотеками машинного обучения. Среди них есть такие библиотеки как CatBoost, fast.ai, Keras, LightGBM, PyTorch, scikit-learn, XGBoost. С полным списком можно ознакомится тут. модуль integration тут А что еще есть? Есть модуль для визуализации, в нем представлены функции для построения графика процесса оптимизации с использованием plotly и matplotlib. Функции построения графиков обычно принимают объект Study и настроечные параметры.
Здесь пример построения графика истории оптимизации.
Есть модуль importance, с помощью него есть возможность провести оценку важности гиперпараметров на основе завершенных испытаний. Есть модуль для визуализации, в нем представлены функции для построения графика процесса оптимизации с использованием plotly и matplotlib. Функции построения графиков обычно принимают объект Study и настроечные параметры.
Здесь пример построения графика истории оптимизации. Есть модуль для визуализации, в нем представлены функции для построения графика процесса оптимизации с использованием plotly и matplotlib. Функции построения графиков обычно принимают объект Study и настроечные параметры. визуализации Здесь пример построения графика истории оптимизации. Здесь Есть модуль importance, с помощью него есть возможность провести оценку важности гиперпараметров на основе завершенных испытаний. Есть модуль importance, с помощью него есть возможность провести оценку важности гиперпараметров на основе завершенных испытаний. importance ]]></text>
</doc>
