<?xml version="1.0" ?>
<doc>
	<label auto="true" type="str" verify="true"><![CDATA[Develop]]></label>
	<author auto="true" type="list" verify="true">
		<item type="str"><![CDATA[mikeB21]]></item>
	</author>
	<date auto="true" type="str" verify="true"><![CDATA[2022-12-05, 10:08]]></date>
	<link auto="true" type="str" verify="true"><![CDATA[https://habr.com/ru/post/703450/]]></link>
	<title auto="true" type="str" verify="true"><![CDATA[Анализ лицевых экспрессий: от нейросетевой классификации эмоций к моделированию восприятия эксперта]]></title>
	<categories auto="true" type="list" verify="true">
		<item type="str"><![CDATA[Машинное обучение]]></item>
		<item type="str"><![CDATA[Искусственный интеллект]]></item>
	</categories>
	<key_words auto="true" type="list" verify="true">
		<item type="str"><![CDATA[эмоции ai]]></item>
		<item type="str"><![CDATA[эмоции]]></item>
		<item type="str"><![CDATA[affective computing]]></item>
		<item type="str"><![CDATA[выражение лица]]></item>
		<item type="str"><![CDATA[нейросеть]]></item>
		<item type="str"><![CDATA[искусственный интеллект]]></item>
	</key_words>
	<text auto="true" type="str" verify="true"><![CDATA[WISARD (1984): первая система, различающая улыбку и нейтральное выражение лица
В последние два десятилетия появляются коммерческие варианты компьютерных систем для автоматизированного анализа выражения эмоций, такие как FaceReader (Noldus Information Technology, Нидерланды, см. рис. 1), EmoDetect (Нейроботикс, Россия), аналогичные разработки компаний Affectiva, Microsoft, Amazon. Подобные системы востребованы для оценки персонала, контроля бдительности, нейромаркетинга, судебно-психологической экспертизы, проведения научных исследований в области affective science. Раньше такие задачи решались высоко квалифицированными экспертами в области анализа поведения. Такая работа крайне сложна и трудоемка. С лавинообразным ростом видеоконтента и явным недостатком экспертов использование компьютерных систем, способных надежно оценивать лицевые экспрессии по видеозаписи, стало весьма актуальным.
Рис.1. Фрагмент интерфейса программы FaceReader (Noldus Information Technology, Нидерланды)
В настоящее время de facto доминирующим является нейросетевой подход. Идея его применения основана на: 1) концепции базовых эмоций (см. рис. 2, 3) и 2) предположении о том, что по соответствующей выборке фотографий (пока еще редко видеозаписей), аннотированной экспертами, в ряде случаев, использованием методов краудсорсинга (как это делала компания Neurodata Lab), можно научить нейросеть распознавать эмоции (см. рис. 4).
Рис. 2. Базовые эмоции (радость, удивление, гнев, страх, печаль, отвращение, презрение).
Рис. 2. Анкета о выражениях эмоций как сочетаниях отдельных мимических движений. Результаты анкетирования были использованы Ч. Дарвином при подготовке книги "О выражении эмоций у человека и животных", которая легла в основу дискретной теории эмоции (базовых эмоций) П. Экмана.
Рис. 4. Пример отображения эмоций в программе FaceReader.
На наш взгляд, практическая реализация нейросетевого подхода имеет ряд принципиальных ограничений.
Во-первых, целый ряд ведущих психологов выражают сомнение в том, что концепция базовых эмоций (Ч. Дарвин, П. Экман, К. Изард и др.) является всеобъемлющей для описания всего спектра эмоциональных состояний человека, отражающихся на его лице.
Во-вторых, обучающая выборка, сформированная на основе фотографий, не может являться репрезентативной, поскольку выражения эмоций не являются статичными и могут описываться только в динамике как комбинация отдельных движений лица. К сожалению, обучающих выборок на основе видеоматериала хорошего качества до сих пор не создано, и, на наш взгляд, сделать это чрезвычайно сложно. Например, только для того, чтобы создать такую выборку лишь для обнаружения эмоции страха по верхней части лица на основании выделения экспертами пяти двигательных единиц FACS (Facial Action Coding System, см. ниже) с учетом их асимметрии, нам потребуется не менее 100 вариантов выражений лица одного человека, не учитывая пол, возраст, расовую, этническую принадлежность респондента и объем обучающей выборки.  Даже при грубом расчете ее минимально необходимого объема он может достигать от 500 тысяч до одного миллиона и более фрагментов видеозаписей соответствующих движений. Мы полагаем, что сделать это практически невозможно. Попытки использования баз данных с синтезированными лицами или «все взять из интернета», оказались несостоятельными. Наш опыт анализа содержания общедоступных аннотированных экспертами баз данных фото- и видеоматериалов (например: Affectiva, Cohn-Kanade, SAMM (Yap et al., 2020) или CASME II (Yan et al., 2014)) показал, что они не могут служить источником надежных данных для обучения нейросети.
В-третьих, нельзя адекватно категоризовать выражения эмоций на лице на основании фотографии как его статического изображения, так как выражение эмоции есть процесс изменения мимики во времени. Ведущие специалисты в области оценки выражений лица, П. Экман и Э. Розенберг (Rosenberg, Ekman, 2020), считают, что  анализ эмоционального выражения лица по фотографии возможен только в контексте обучения эксперта, а реальное аннотирования лицевых экспрессий должно осуществляться по видеозаписи, то есть в динамике. Это связано с тем, что эксперт должен увидеть начало и окончание каждого движения лица и на основании сочетаний отдельных двигательных единиц FACS сделать вывод о наличии той или иной эмоции. Иначе мы можем принять особенности анатомии лица или характерные для данного человека выражения лица (например, поднятые углы бровей или копирование мимической «маски» любимого киногероя) за выражение эмоции.
Цель нашей публикации состоит в том, чтобы поделиться с IT-специалистами и специалистами в области анализа поведения человека нашими соображениями и достижениями в области разработки методологии и технологии автоматического оценивания лицевых экспрессий с помощью созданного нами ПО с акцентом на его использование при решении практических задач, а также в научных исследованиях.
Как нужно и можно анализировать лицо
Разработанная нами методология и технология оценки мимической активности (МА) основана на известной системе FACS (см. рис. 5, 6), разработанной П. Экманом и его коллегами (Ekman, Friesen, Hager, 2002) и получившей  широкое распространение как способ универсального описания движений, наблюдаемых экспертом на поверхности лица.
Рис. 5. Основные AUs (action units, двигательные единицы) системы FACS (Facial Action Coding System).
Основой анализа в системе FACS является двигательная единица – AU (Action Unit), как характерное изменение поверхности лица в форме отдельного движения (например, губ, бровей, век, носогубных складок). Согласно руководству по FACS в ходе визуального анализа лица человека выделяют ограниченный набор AUs. Особо подчеркнем, что система FACS не задает теоретико-методологические рамки для оценки мимических выражений эмоций, и, тем более, выделения определенного набора базовых эмоций.
Рис. 6. AUs (action units, двигательные единицы) системы FACS (Facial Action Coding System).
В современной литературе есть известная дискуссия о том, какие эмоции отражаются в МА, какие из них базовые и сколько их (см., например: Rosenberg, Ekman, 2020, Davidson, Scherer, Goldsmith, 2003, Davis, Panksepp, 2018, Лиза Фельдман Барретт, 2018). Поэтому мы акцентируем внимание читателей на том, что FACS – это система инвариантного описания МА, инструмент, который можно использовать для выделения на лице выражения эмоций и других сложных паттернов МА вне зависимости от того, как разные авторы понимают задачу обнаружения эмоций на лице человека. Система FACS не связана с какими-либо теоретическими предположениями о природе выражения лица, она основана на очевидной и эмпирически подтвержденной связи активности отдельных лицевых мышц и мышечных с групп с соответствующими изменениями поверхности лица. Это важно, поскольку даже профессиональные психологи нередко смешивают эти две проблемы – описание МА и ее категоризацию в виде отдельных эмоциональных экспрессий. FACS – это не более чем инструмент, способ систематической фиксации в поле восприятия определенных движений поверхности лица. Например, AU2 – это поднятие внешней части брови, AU41 – опускание надпереносья, а AU20 – растяжение губ (см. номера отдельных AUs на рис. 1). Совсем другое дело – это выделять из сочетаний AUs базовые эмоции, например, как это делают П. Экман и его соавторы, например радость определяется как сочетание AUs 6+12; 2) грусть – как сочетание AUs 1+4+15 или 1+4+15 (см. рис. 7).
Рис. 7. Сочетания двигательных единиц FACS, соответствующие выражениям базовых эмоций (Ekman, Friesen, Hager, 2002).
Два подхода к автоматическому анализу лицевых экспрессий
Компьютерная система должна с приемлемой точностью и надежностью обнаруживать разные проявления МА, например, отдельные AUs,  базовые эмоции и другие паттерны МА. Выделим два основных подхода к решению этой задачи.
Так называемый селективный подход (selective approach) основан на поиске соответствия определенных выражений лица образцам в ограниченном наборе базовых эмоций или AUs. Его характерные особенности и проблемы состоят в следующем:
Используются нейросети, обученные на ограниченной и, как правило, маловариативной выборке фотографий лиц людей с выражением шести-семи базовых эмоций и отдельных AUs. Как было отмечено выше,  проблема состоит в том, для обучения нейросети нужны обучающие выборки изображений лицевых экспрессий, аннотированные опытными экспертами, а получить их крайне сложно. Тем более, создать такие выборки, где были в большом количестве представлены разные AUs, микровыражения лица (быстрые выражения лица, длительностью менее 500 миллисекунд), не говоря уже о том, что эти данные нужно собрать на разных людях. Серьезным недостатком этого подхода является то, что эксперты, аннотирующие фотографии, составляющие обучающую выборку, оценивают каждое фото на предмет выраженности в нем эмоции или какой-либо AU статически, по впечатлению, а не анализируют видеозапись, оценивая мимические проявления в динамике. На наш взгляд, это серьезная ошибка, поскольку AUs – это двигательные феномены. Нам пока не известны разработки, в которых нейросети обучались бы непосредственно на видеозаписях. По крайней мере, широко распространенные варианты программного обеспечения Face Reader или Affectiva разрабатывались с использованием большой базы аннотированных фотографий и видеофреймов с ограниченным набором интенсивно выраженных AUs.
В силу особенностей используемых компьютерных алгоритмов и ограниченности обучающих выборок быстрые движения (микро выражения) лица не определяются или определяются очень плохо.
В рамках данного подхода у 7-10 % популяции людей в силу их индивидуальных особенностей и/или неврологических проблем невозможно оценить эмоции по выражению лица, а также адекватно оценить AUs. Данное обстоятельство является критичным при использовании селективных систем при полностью автоматическом анализе мимики человека, например при анализе дистанционного интервью. Необходима предварительная экспертная оценка  МА человека на предмет возможности применения подобной систем. В частности, если в нейромаркетинге возможно исключить ряд респондентов с нетипичной мимикой, то в случае дистанционного автоматизированного интервью это невозможно.
Необходим учет расовой и этнической принадлежности лица анализируемого человека, что требует использования для обучения нейросети соответствующих выборок. В настоящее время обучающие выборки созданы для очень ограниченного числа рас (см., например, возможности ПО Noldus Face Reader, где предлагается выбор двух рас – кавказской и Юго-Восточная Азия).
При использовании системы необходима ее предварительная ручная калибровка для исключения влияния анатомической «похожести» лица на определенные эмоции.
В связи с тем,  что наличие эмоций и их сочетаний на лице в связи с особенностями этого подхода представляет собой вероятностную величину, приходится использовать разные настройки чувствительности компьютерной системы. Например, компания Affectiva при настройке своего ПО предлагает пользователям в зависимости от решаемой задачи выбор из трех уровней срабатывания алгоритма обнаружения эмоций.
Проблематичность описания и категоризации мимической активности детей до 5-7 лет в дискурсе выражений эмоций. В современной психологии детская мимика описывается только при помощи FACS и BabyFACS (Oster, 2004).
Комплексный подходе (comprehensive approach) к анализу мимической активности, в рамках которого мы работаем,  базируется на выделении и анализе сочетаний AUs во времени. Его особенности и преимущества следующие:
Непосредственное выделение AUs как основных единиц анализа  мимической активности позволяет описывать все возможные выражения лица.
Возможность оценивать быстрые движения лица (микровыражения), асимметричные выражения.
Возможность оценки индивидуальных экспрессивных особенностей МА, например, обнаружение мимических гиперкинезов, индивидуальных мимических привычек (мимических маньеризмов), сложных паттернов мимики. Еще раз подчеркнем, что эти мимические феномены оцениваются как появление соответствующих движений на поверхности лица, т.е. как отдельные AUs или их комбинация, а не как итоговое «впечатление» нейросетевого классификатора.
Независимость от расовой принадлежности человека, поскольку данный подход не ограничен особенностями обучающей выборки фото/видео изображений лиц.
Не требуется индивидуальная настройка компьютерной системы в соответствии с особенностями анализируемой выборки и решаемой задачи, поскольку в ходе анализа конкретной видеозаписи оценивается текущие изменения МА конкретного человека.
Нет возрастных ограничений по оценки базовых проявлений МА, поскольку описываются появление AUs, а не эмоции.
Особенности разработанной технологии оценки МА
При создании конкретных алгоритмов автоматизированного анализа МА мы использовали два важных методических принципа:
Прямая оценка перемещений поверхности лица для обнаружения AUs и принципиальный отказ от использования нейросетей для классификации МА как метода их косвенного оценивания.
Моделирование восприятия экспертом особенностей перемещений поверхности лица при обнаружении отдельных AUs с учетом топографии движений лицевой поверхности, характерной для реального движения, асимметрии, распределения пространственного внимания в ходе визуального наблюдения за движениями лица другого человека, характера процесса принятия решения о наличии/отсутствия AUs в соответствии с рекомендациями FACS (см. рис. 8).
Рис. 8. Базовые сегменты анализа поверхности лица, используемые ПО ЭмоРадар WR 5.0.
При создании  были разработаны авторские процедуры компьютерного зрения (CV), специфически ориентированных на анализ движений поверхности лица в отдельных его частях и характерные особенности проявления разных AUs. Необходимость создания новых процедур CV была вызвана тем, что стандартные процедуры OpenCV представляют собой универсальные способы преобразования изменений светового потока в паттерны движения и не ориентированы на анализ характерных сдвигов поверхности лица. Мы исходили из того, каким образом изменения света, попадающие в зрительную систему наблюдателя преобразуются в двигательные перцептивные инварианты (Гибсон, 1988). Фактически разработанные нами процедуры CV представляют собой инструменты поиска максимального соответствия механизмов зрительного восприятия современным способам анализа изменений светового потока, зарегистрированного видео камерой.
Эти новые процедуры по-разному оценивают изменения света в разных частях лица, разделенного нами на 14 симметричных зон (сегментов) анализа (рис. 2), а также в отдельных мини-сегментах с учетом вероятности появления AUs на местах перекрытия этих зон. Фактически были созданы компьютерные процедуры, позволяющие анализировать сокращение и растяжение поверхности лица в тех направлениях, которые соответствуют каждой из AUs. Например, очевидно, что метрика для обнаружения движений внутренних частей бровей вверх и друг к другу (AUs 1+4) – это совсем другая метрика по сравнению с горизонтальным сжатием нижних век (AU 7).
Описывая в целом алгоритм анализа МА, укажем, что фактически при выделении отдельных AUs нами был реализован принцип многослойного анализа МА:
разделение видеозаписи на отдельные кадры, выделение артефактов, оценка качества видеозаписи, построение сегментной карты лица по автоматически выделенным 68 реперным точкам, соответствующим анатомии лица;
анализ изменений распределения света от кадра кадру в разных сегментах лица, выделение значимых изменений, интерпретация этих изменений на поверхности лица в виде сдвигов кожи, складок, выпуклостей и вогнутостей; этот нижний уровень представляет собой сложный трехэтапный анализ изменений поверхности лица, результатом которого является первичное выделение значимых мимических событий на фоне общего «шума»;
сопоставление выделенных изменений друг с другом в соответствии с анатомическим строением лица и схемой FACS;
выделение начала и окончания отдельных AUs;
выделение эмоций и других сложных мимических паттернов;
расчет интегральных показателей МА, например: частота AUs в единицу времени,  асимметрия, сочетание AUs и речи;
визуализация результатов анализа на временной оси и построение таблицы результатов анализа МА;
сложная категоризация паттернов МА как характерных проявлений мимического поведения: истинные эмоции, эмблемы эмоций, придание эмоциональной модальности речевому высказыванию, индивидуальные мимические привычки, выделение значимых фрагментов речи и др.
В ходе нашей работы была создана система правил, на основании которых «сырые» данные об изменении света преобразуются в движение поверхностей, а они, в свою очередь, – в AUs. Фактически эти правила и их соотношения могут быть прообразом нового компьютерного языка для анализа МА.
Апробация разработанной технологии анализа МА
В настоящее время в рамках Лаборатории исследования поведения компании «Лицом к лицу» нами разработано ПО ЭмоРадар WR 5.0 для проведения полностью автоматизированного анализа МА по видеозаписям с разрешением не хуже HD, на которых лицо человека записано анфас (с поворотами головы влево-вправо, вверх-вниз не более, чем на 20 градусов) и занимающее по высоте не менее 500 px.
Всего с высокой точностью обнаруживаются 23 основных двигательных единиц: AU 1, 2, 5, 6, 7, 9, 10, 12, 14, 15, 17, 20, 24, 28, 41, 44, 43, 45, 70, 71, 72, 73, 74 а также семь базовых эмоций: радость, удивление, презрение, печаль, отвращение, страх, гнев.
ПО ЭмоРадар  работает под Windows и Ubuntu Linux.
ПО ЭмоРадар позволяет обрабатывать видеозаписи и просматривать на временной оси изменения МА, отображая на экране монитора разные эмоции и AUs.
Для эмпирической верификации точности и надежности работы созданного ПО мы использовали две базы данных микро- и макро выражений лица – CASME II (Yan et al., 2014) и SAMM (Yap et al., 2020).
ПО ЭмоРадар WR 5.0 используется для анализа видеозаписей в ходе судебно-психологической экспертизы в рамках сотрудничества с юристами и экспертами. Это ПО также использовалось для создания методики автоматизированного анализа кадровых интервью совместно с HR-службой одной из крупных промышленных компаний РФ на выборке более 17.000 видео интервью. ПО прошло апробацию в ходе экспериментального исследования магистрантами факультета психологии МГУ имени М.В. Ломоносова поведения человека в особых условиях профессиональной деятельности в рамках проекта «Иммерсия» Института Медико-биологических проблем РАН.
Список литературы
Гибсон, Дж. Экологический подход к зрительному восприятию. М.: Прогресс, 1988. 464 с. [Gibson J. Ecological approach to visual perception, Moscow, Progress, 1988 (In Russ)].
Лиза Фельдман Баррет. Как рождаются эмоции. Революция в понимании мозга и управлении эмоциями / Пер. с англ. Е. Поникарова. — М.: Манн, Иванов и Фербер, 2018. — 472 с.
Davidson, R. J., Scherer, K. R., & Goldsmith, H. H. (eds). Handbook of Affective Sciences. Oxford Univ. Press, 200
Ekman P., Friesen W.V., Hager J.C. (2002). Facial Action Coding System (FACS): the Manual & the Investigator's Guide. A Human Face, Salt Lake City U.
Davis, Kenneth L., and Jaak Panksepp. The Emotional Foundations of Personality: A Neurobiological and Evolutionary Approach. W.W Norton &amp; Company, 2018.
Oster, Harriet, 'The repertoire of infant facial expressions: an ontogenetic perspective', in Jacqueline Nadel, and Darwin Muir (eds), Emotional Development: Recent Research Advances (Oxford, 2004; online edn, Oxford Academic, 22 Mar. 2012), https://doi.org/10.1093/acprof:oso/9780198528845.003.0010
Rosenberg, E. L., Ekman, P. (2020). What the face reveals basic and applied studies of spontaneous expression using the facial action coding system (FACS). New York: Oxford University Press.
Yan, W., Li, X., Wang, S., Zhao, G., Liu, Y., Chen, Y., Fu, X. (2014). CASME II: An IMPROVED Spontaneous Micro-Expression database and the baseline evaluation. PLoS ONE, 9(1). doi:10.1371/journal.pone.0086041
Yap, C.H., Kendrick, C., &amp; Yap, M.H. (2020). SAMM long Videos: A spontaneous Facial micro- and Macro-Expressions Dataset. 2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020). doi:10.1109/fg47880.2020.00029
Авторы: М.С. Баев (ООО "Лицом к лицу"), А.Н. Гусев (Факультет психологии МГУ имени М.В. Ломоносова), А.Е. Кремлев (Факультет психологии МГУ имени М.В. Ломоносова). WISARD (1984): первая система, различающая улыбку и нейтральное выражение лица  WISARD (1984): первая система, различающая улыбку и нейтральное выражение лица В последние два десятилетия появляются коммерческие варианты компьютерных систем для автоматизированного анализа выражения эмоций, такие как FaceReader (Noldus Information Technology, Нидерланды, см. рис. 1), EmoDetect (Нейроботикс, Россия), аналогичные разработки компаний Affectiva, Microsoft, Amazon. Подобные системы востребованы для оценки персонала, контроля бдительности, нейромаркетинга, судебно-психологической экспертизы, проведения научных исследований в области affective science. Раньше такие задачи решались высоко квалифицированными экспертами в области анализа поведения. Такая работа крайне сложна и трудоемка. С лавинообразным ростом видеоконтента и явным недостатком экспертов использование компьютерных систем, способных надежно оценивать лицевые экспрессии по видеозаписи, стало весьма актуальным.  Рис.1. Фрагмент интерфейса программы FaceReader (Noldus Information Technology, Нидерланды) В настоящее время de facto доминирующим является нейросетевой подход. Идея его применения основана на: 1) концепции базовых эмоций (см. рис. 2, 3) и 2) предположении о том, что по соответствующей выборке фотографий (пока еще редко видеозаписей), аннотированной экспертами, в ряде случаев, использованием методов краудсорсинга (как это делала компания Neurodata Lab), можно научить нейросеть распознавать эмоции (см. рис. 4). нейросетевой подход  Рис. 2. Базовые эмоции (радость, удивление, гнев, страх, печаль, отвращение, презрение). Рис. 2. Анкета о выражениях эмоций как сочетаниях отдельных мимических движений. Результаты анкетирования были использованы Ч. Дарвином при подготовке книги "О выражении эмоций у человека и животных", которая легла в основу дискретной теории эмоции (базовых эмоций) П. Экмана.  Рис. 2. Анкета о выражениях эмоций как сочетаниях отдельных мимических движений. Результаты анкетирования были использованы Ч. Дарвином при подготовке книги "О выражении эмоций у человека и животных", которая легла в основу дискретной теории эмоции (базовых эмоций) П. Экмана. Рис. 4. Пример отображения эмоций в программе FaceReader.  Рис. 4. Пример отображения эмоций в программе FaceReader. На наш взгляд, практическая реализация нейросетевого подхода имеет ряд принципиальных ограничений. Во-первых, целый ряд ведущих психологов выражают сомнение в том, что концепция базовых эмоций (Ч. Дарвин, П. Экман, К. Изард и др.) является всеобъемлющей для описания всего спектра эмоциональных состояний человека, отражающихся на его лице. Во-вторых, обучающая выборка, сформированная на основе фотографий, не может являться репрезентативной, поскольку выражения эмоций не являются статичными и могут описываться только в динамике как комбинация отдельных движений лица. К сожалению, обучающих выборок на основе видеоматериала хорошего качества до сих пор не создано, и, на наш взгляд, сделать это чрезвычайно сложно. Например, только для того, чтобы создать такую выборку лишь для обнаружения эмоции страха по верхней части лица на основании выделения экспертами пяти двигательных единиц FACS (Facial Action Coding System, см. ниже) с учетом их асимметрии, нам потребуется не менее 100 вариантов выражений лица одного человека, не учитывая пол, возраст, расовую, этническую принадлежность респондента и объем обучающей выборки.  Даже при грубом расчете ее минимально необходимого объема он может достигать от 500 тысяч до одного миллиона и более фрагментов видеозаписей соответствующих движений. Мы полагаем, что сделать это практически невозможно. Попытки использования баз данных с синтезированными лицами или «все взять из интернета», оказались несостоятельными. Наш опыт анализа содержания общедоступных аннотированных экспертами баз данных фото- и видеоматериалов (например: Affectiva, Cohn-Kanade, SAMM (Yap et al., 2020) или CASME II (Yan et al., 2014)) показал, что они не могут служить источником надежных данных для обучения нейросети. репрезентативной FACS несостоятельными не могут В-третьих, нельзя адекватно категоризовать выражения эмоций на лице на основании фотографии как его статического изображения, так как выражение эмоции есть процесс изменения мимики во времени. Ведущие специалисты в области оценки выражений лица, П. Экман и Э. Розенберг (Rosenberg, Ekman, 2020), считают, что  анализ эмоционального выражения лица по фотографии возможен только в контексте обучения эксперта, а реальное аннотирования лицевых экспрессий должно осуществляться по видеозаписи, то есть в динамике. Это связано с тем, что эксперт должен увидеть начало и окончание каждого движения лица и на основании сочетаний отдельных двигательных единиц FACS сделать вывод о наличии той или иной эмоции. Иначе мы можем принять особенности анатомии лица или характерные для данного человека выражения лица (например, поднятые углы бровей или копирование мимической «маски» любимого киногероя) за выражение эмоции. во времени в динамике Цель нашей публикации состоит в том, чтобы поделиться с IT-специалистами и специалистами в области анализа поведения человека нашими соображениями и достижениями в области разработки методологии и технологии автоматического оценивания лицевых экспрессий с помощью созданного нами ПО с акцентом на его использование при решении практических задач, а также в научных исследованиях. Как нужно и можно анализировать лицо Разработанная нами методология и технология оценки мимической активности (МА) основана на известной системе FACS (см. рис. 5, 6), разработанной П. Экманом и его коллегами (Ekman, Friesen, Hager, 2002) и получившей  широкое распространение как способ универсального описания движений, наблюдаемых экспертом на поверхности лица. универсального Рис. 5. Основные AUs (action units, двигательные единицы) системы FACS (Facial Action Coding System).  Рис. 5. Основные AUs (action units, двигательные единицы) системы FACS (Facial Action Coding System). Основой анализа в системе FACS является двигательная единица – AU (Action Unit), как характерное изменение поверхности лица в форме отдельного движения (например, губ, бровей, век, носогубных складок). Согласно руководству по FACS в ходе визуального анализа лица человека выделяют ограниченный набор AUs. Особо подчеркнем, что система FACS не задает теоретико-методологические рамки для оценки мимических выражений эмоций, и, тем более, выделения определенного набора базовых эмоций. двигательная единица не задает  Рис. 6. AUs (action units, двигательные единицы) системы FACS (Facial Action Coding System). В современной литературе есть известная дискуссия о том, какие эмоции отражаются в МА, какие из них базовые и сколько их (см., например: Rosenberg, Ekman, 2020, Davidson, Scherer, Goldsmith, 2003, Davis, Panksepp, 2018, Лиза Фельдман Барретт, 2018). Поэтому мы акцентируем внимание читателей на том, что FACS – это система инвариантного описания МА, инструмент, который можно использовать для выделения на лице выражения эмоций и других сложных паттернов МА вне зависимости от того, как разные авторы понимают задачу обнаружения эмоций на лице человека. Система FACS не связана с какими-либо теоретическими предположениями о природе выражения лица, она основана на очевидной и эмпирически подтвержденной связи активности отдельных лицевых мышц и мышечных с групп с соответствующими изменениями поверхности лица. Это важно, поскольку даже профессиональные психологи нередко смешивают эти две проблемы – описание МА и ее категоризацию в виде отдельных эмоциональных экспрессий. FACS – это не более чем инструмент, способ систематической фиксации в поле восприятия определенных движений поверхности лица. Например, AU2 – это поднятие внешней части брови, AU41 – опускание надпереносья, а AU20 – растяжение губ (см. номера отдельных AUs на рис. 1). Совсем другое дело – это выделять из сочетаний AUs базовые эмоции, например, как это делают П. Экман и его соавторы, например радость определяется как сочетание AUs 6+12; 2) грусть – как сочетание AUs 1+4+15 или 1+4+15 (см. рис. 7). инвариантного вне зависимости не связана Рис. 7. Сочетания двигательных единиц FACS, соответствующие выражениям базовых эмоций (Ekman, Friesen, Hager, 2002).  Рис. 7. Сочетания двигательных единиц FACS, соответствующие выражениям базовых эмоций (Ekman, Friesen, Hager, 2002). Два подхода к автоматическому анализу лицевых экспрессий Компьютерная система должна с приемлемой точностью и надежностью обнаруживать разные проявления МА, например, отдельные AUs,  базовые эмоции и другие паттерны МА. Выделим два основных подхода к решению этой задачи. Так называемый селективный подход (selective approach) основан на поиске соответствия определенных выражений лица образцам в ограниченном наборе базовых эмоций или AUs. Его характерные особенности и проблемы состоят в следующем: селективный подход Используются нейросети, обученные на ограниченной и, как правило, маловариативной выборке фотографий лиц людей с выражением шести-семи базовых эмоций и отдельных AUs. Как было отмечено выше,  проблема состоит в том, для обучения нейросети нужны обучающие выборки изображений лицевых экспрессий, аннотированные опытными экспертами, а получить их крайне сложно. Тем более, создать такие выборки, где были в большом количестве представлены разные AUs, микровыражения лица (быстрые выражения лица, длительностью менее 500 миллисекунд), не говоря уже о том, что эти данные нужно собрать на разных людях. Серьезным недостатком этого подхода является то, что эксперты, аннотирующие фотографии, составляющие обучающую выборку, оценивают каждое фото на предмет выраженности в нем эмоции или какой-либо AU статически, по впечатлению, а не анализируют видеозапись, оценивая мимические проявления в динамике. На наш взгляд, это серьезная ошибка, поскольку AUs – это двигательные феномены. Нам пока не известны разработки, в которых нейросети обучались бы непосредственно на видеозаписях. По крайней мере, широко распространенные варианты программного обеспечения Face Reader или Affectiva разрабатывались с использованием большой базы аннотированных фотографий и видеофреймов с ограниченным набором интенсивно выраженных AUs.
В силу особенностей используемых компьютерных алгоритмов и ограниченности обучающих выборок быстрые движения (микро выражения) лица не определяются или определяются очень плохо.
В рамках данного подхода у 7-10 % популяции людей в силу их индивидуальных особенностей и/или неврологических проблем невозможно оценить эмоции по выражению лица, а также адекватно оценить AUs. Данное обстоятельство является критичным при использовании селективных систем при полностью автоматическом анализе мимики человека, например при анализе дистанционного интервью. Необходима предварительная экспертная оценка  МА человека на предмет возможности применения подобной систем. В частности, если в нейромаркетинге возможно исключить ряд респондентов с нетипичной мимикой, то в случае дистанционного автоматизированного интервью это невозможно.
Необходим учет расовой и этнической принадлежности лица анализируемого человека, что требует использования для обучения нейросети соответствующих выборок. В настоящее время обучающие выборки созданы для очень ограниченного числа рас (см., например, возможности ПО Noldus Face Reader, где предлагается выбор двух рас – кавказской и Юго-Восточная Азия).
При использовании системы необходима ее предварительная ручная калибровка для исключения влияния анатомической «похожести» лица на определенные эмоции.
В связи с тем,  что наличие эмоций и их сочетаний на лице в связи с особенностями этого подхода представляет собой вероятностную величину, приходится использовать разные настройки чувствительности компьютерной системы. Например, компания Affectiva при настройке своего ПО предлагает пользователям в зависимости от решаемой задачи выбор из трех уровней срабатывания алгоритма обнаружения эмоций.
Проблематичность описания и категоризации мимической активности детей до 5-7 лет в дискурсе выражений эмоций. В современной психологии детская мимика описывается только при помощи FACS и BabyFACS (Oster, 2004). Используются нейросети, обученные на ограниченной и, как правило, маловариативной выборке фотографий лиц людей с выражением шести-семи базовых эмоций и отдельных AUs. Как было отмечено выше,  проблема состоит в том, для обучения нейросети нужны обучающие выборки изображений лицевых экспрессий, аннотированные опытными экспертами, а получить их крайне сложно. Тем более, создать такие выборки, где были в большом количестве представлены разные AUs, микровыражения лица (быстрые выражения лица, длительностью менее 500 миллисекунд), не говоря уже о том, что эти данные нужно собрать на разных людях. Серьезным недостатком этого подхода является то, что эксперты, аннотирующие фотографии, составляющие обучающую выборку, оценивают каждое фото на предмет выраженности в нем эмоции или какой-либо AU статически, по впечатлению, а не анализируют видеозапись, оценивая мимические проявления в динамике. На наш взгляд, это серьезная ошибка, поскольку AUs – это двигательные феномены. Нам пока не известны разработки, в которых нейросети обучались бы непосредственно на видеозаписях. По крайней мере, широко распространенные варианты программного обеспечения Face Reader или Affectiva разрабатывались с использованием большой базы аннотированных фотографий и видеофреймов с ограниченным набором интенсивно выраженных AUs. Используются нейросети, обученные на ограниченной и, как правило, маловариативной выборке фотографий лиц людей с выражением шести-семи базовых эмоций и отдельных AUs. Как было отмечено выше,  проблема состоит в том, для обучения нейросети нужны обучающие выборки изображений лицевых экспрессий, аннотированные опытными экспертами, а получить их крайне сложно. Тем более, создать такие выборки, где были в большом количестве представлены разные AUs, микровыражения лица (быстрые выражения лица, длительностью менее 500 миллисекунд), не говоря уже о том, что эти данные нужно собрать на разных людях. Серьезным недостатком этого подхода является то, что эксперты, аннотирующие фотографии, составляющие обучающую выборку, оценивают каждое фото на предмет выраженности в нем эмоции или какой-либо AU статически, по впечатлению, а не анализируют видеозапись, оценивая мимические проявления в динамике. На наш взгляд, это серьезная ошибка, поскольку AUs – это двигательные феномены. Нам пока не известны разработки, в которых нейросети обучались бы непосредственно на видеозаписях. По крайней мере, широко распространенные варианты программного обеспечения Face Reader или Affectiva разрабатывались с использованием большой базы аннотированных фотографий и видеофреймов с ограниченным набором интенсивно выраженных AUs. статически в динамике В силу особенностей используемых компьютерных алгоритмов и ограниченности обучающих выборок быстрые движения (микро выражения) лица не определяются или определяются очень плохо. В силу особенностей используемых компьютерных алгоритмов и ограниченности обучающих выборок быстрые движения (микро выражения) лица не определяются или определяются очень плохо. В рамках данного подхода у 7-10 % популяции людей в силу их индивидуальных особенностей и/или неврологических проблем невозможно оценить эмоции по выражению лица, а также адекватно оценить AUs. Данное обстоятельство является критичным при использовании селективных систем при полностью автоматическом анализе мимики человека, например при анализе дистанционного интервью. Необходима предварительная экспертная оценка  МА человека на предмет возможности применения подобной систем. В частности, если в нейромаркетинге возможно исключить ряд респондентов с нетипичной мимикой, то в случае дистанционного автоматизированного интервью это невозможно. В рамках данного подхода у 7-10 % популяции людей в силу их индивидуальных особенностей и/или неврологических проблем невозможно оценить эмоции по выражению лица, а также адекватно оценить AUs. Данное обстоятельство является критичным при использовании селективных систем при полностью автоматическом анализе мимики человека, например при анализе дистанционного интервью. Необходима предварительная экспертная оценка  МА человека на предмет возможности применения подобной систем. В частности, если в нейромаркетинге возможно исключить ряд респондентов с нетипичной мимикой, то в случае дистанционного автоматизированного интервью это невозможно. Необходим учет расовой и этнической принадлежности лица анализируемого человека, что требует использования для обучения нейросети соответствующих выборок. В настоящее время обучающие выборки созданы для очень ограниченного числа рас (см., например, возможности ПО Noldus Face Reader, где предлагается выбор двух рас – кавказской и Юго-Восточная Азия). Необходим учет расовой и этнической принадлежности лица анализируемого человека, что требует использования для обучения нейросети соответствующих выборок. В настоящее время обучающие выборки созданы для очень ограниченного числа рас (см., например, возможности ПО Noldus Face Reader, где предлагается выбор двух рас – кавказской и Юго-Восточная Азия). При использовании системы необходима ее предварительная ручная калибровка для исключения влияния анатомической «похожести» лица на определенные эмоции. При использовании системы необходима ее предварительная ручная калибровка для исключения влияния анатомической «похожести» лица на определенные эмоции. В связи с тем,  что наличие эмоций и их сочетаний на лице в связи с особенностями этого подхода представляет собой вероятностную величину, приходится использовать разные настройки чувствительности компьютерной системы. Например, компания Affectiva при настройке своего ПО предлагает пользователям в зависимости от решаемой задачи выбор из трех уровней срабатывания алгоритма обнаружения эмоций. В связи с тем,  что наличие эмоций и их сочетаний на лице в связи с особенностями этого подхода представляет собой вероятностную величину, приходится использовать разные настройки чувствительности компьютерной системы. Например, компания Affectiva при настройке своего ПО предлагает пользователям в зависимости от решаемой задачи выбор из трех уровней срабатывания алгоритма обнаружения эмоций. Проблематичность описания и категоризации мимической активности детей до 5-7 лет в дискурсе выражений эмоций. В современной психологии детская мимика описывается только при помощи FACS и BabyFACS (Oster, 2004). Проблематичность описания и категоризации мимической активности детей до 5-7 лет в дискурсе выражений эмоций. В современной психологии детская мимика описывается только при помощи FACS и BabyFACS (Oster, 2004). Комплексный подходе (comprehensive approach) к анализу мимической активности, в рамках которого мы работаем,  базируется на выделении и анализе сочетаний AUs во времени. Его особенности и преимущества следующие: Комплексный Непосредственное выделение AUs как основных единиц анализа  мимической активности позволяет описывать все возможные выражения лица.
Возможность оценивать быстрые движения лица (микровыражения), асимметричные выражения.
Возможность оценки индивидуальных экспрессивных особенностей МА, например, обнаружение мимических гиперкинезов, индивидуальных мимических привычек (мимических маньеризмов), сложных паттернов мимики. Еще раз подчеркнем, что эти мимические феномены оцениваются как появление соответствующих движений на поверхности лица, т.е. как отдельные AUs или их комбинация, а не как итоговое «впечатление» нейросетевого классификатора.
Независимость от расовой принадлежности человека, поскольку данный подход не ограничен особенностями обучающей выборки фото/видео изображений лиц.
Не требуется индивидуальная настройка компьютерной системы в соответствии с особенностями анализируемой выборки и решаемой задачи, поскольку в ходе анализа конкретной видеозаписи оценивается текущие изменения МА конкретного человека.
Нет возрастных ограничений по оценки базовых проявлений МА, поскольку описываются появление AUs, а не эмоции. Непосредственное выделение AUs как основных единиц анализа  мимической активности позволяет описывать все возможные выражения лица. Непосредственное выделение AUs как основных единиц анализа  мимической активности позволяет описывать все возможные выражения лица. все возможные Возможность оценивать быстрые движения лица (микровыражения), асимметричные выражения. Возможность оценивать быстрые движения лица (микровыражения), асимметричные выражения. Возможность оценки индивидуальных экспрессивных особенностей МА, например, обнаружение мимических гиперкинезов, индивидуальных мимических привычек (мимических маньеризмов), сложных паттернов мимики. Еще раз подчеркнем, что эти мимические феномены оцениваются как появление соответствующих движений на поверхности лица, т.е. как отдельные AUs или их комбинация, а не как итоговое «впечатление» нейросетевого классификатора. Возможность оценки индивидуальных экспрессивных особенностей МА, например, обнаружение мимических гиперкинезов, индивидуальных мимических привычек (мимических маньеризмов), сложных паттернов мимики. Еще раз подчеркнем, что эти мимические феномены оцениваются как появление соответствующих движений на поверхности лица, т.е. как отдельные AUs или их комбинация, а не как итоговое «впечатление» нейросетевого классификатора. Независимость от расовой принадлежности человека, поскольку данный подход не ограничен особенностями обучающей выборки фото/видео изображений лиц. Независимость от расовой принадлежности человека, поскольку данный подход не ограничен особенностями обучающей выборки фото/видео изображений лиц. Не требуется индивидуальная настройка компьютерной системы в соответствии с особенностями анализируемой выборки и решаемой задачи, поскольку в ходе анализа конкретной видеозаписи оценивается текущие изменения МА конкретного человека. Не требуется индивидуальная настройка компьютерной системы в соответствии с особенностями анализируемой выборки и решаемой задачи, поскольку в ходе анализа конкретной видеозаписи оценивается текущие изменения МА конкретного человека. текущие изменения Нет возрастных ограничений по оценки базовых проявлений МА, поскольку описываются появление AUs, а не эмоции. Нет возрастных ограничений по оценки базовых проявлений МА, поскольку описываются появление AUs, а не эмоции. Особенности разработанной технологии оценки МА При создании конкретных алгоритмов автоматизированного анализа МА мы использовали два важных методических принципа: Прямая оценка перемещений поверхности лица для обнаружения AUs и принципиальный отказ от использования нейросетей для классификации МА как метода их косвенного оценивания.
Моделирование восприятия экспертом особенностей перемещений поверхности лица при обнаружении отдельных AUs с учетом топографии движений лицевой поверхности, характерной для реального движения, асимметрии, распределения пространственного внимания в ходе визуального наблюдения за движениями лица другого человека, характера процесса принятия решения о наличии/отсутствия AUs в соответствии с рекомендациями FACS (см. рис. 8). Прямая оценка перемещений поверхности лица для обнаружения AUs и принципиальный отказ от использования нейросетей для классификации МА как метода их косвенного оценивания. Прямая оценка перемещений поверхности лица для обнаружения AUs и принципиальный отказ от использования нейросетей для классификации МА как метода их косвенного оценивания. Прямая оценка косвенного Моделирование восприятия экспертом особенностей перемещений поверхности лица при обнаружении отдельных AUs с учетом топографии движений лицевой поверхности, характерной для реального движения, асимметрии, распределения пространственного внимания в ходе визуального наблюдения за движениями лица другого человека, характера процесса принятия решения о наличии/отсутствия AUs в соответствии с рекомендациями FACS (см. рис. 8). Моделирование восприятия экспертом особенностей перемещений поверхности лица при обнаружении отдельных AUs с учетом топографии движений лицевой поверхности, характерной для реального движения, асимметрии, распределения пространственного внимания в ходе визуального наблюдения за движениями лица другого человека, характера процесса принятия решения о наличии/отсутствия AUs в соответствии с рекомендациями FACS (см. рис. 8). Моделирование восприятия  Рис. 8. Базовые сегменты анализа поверхности лица, используемые ПО ЭмоРадар WR 5.0. При создании  были разработаны авторские процедуры компьютерного зрения (CV), специфически ориентированных на анализ движений поверхности лица в отдельных его частях и характерные особенности проявления разных AUs. Необходимость создания новых процедур CV была вызвана тем, что стандартные процедуры OpenCV представляют собой универсальные способы преобразования изменений светового потока в паттерны движения и не ориентированы на анализ характерных сдвигов поверхности лица. Мы исходили из того, каким образом изменения света, попадающие в зрительную систему наблюдателя преобразуются в двигательные перцептивные инварианты (Гибсон, 1988). Фактически разработанные нами процедуры CV представляют собой инструменты поиска максимального соответствия механизмов зрительного восприятия современным способам анализа изменений светового потока, зарегистрированного видео камерой. двигательные перцептивные инварианты Эти новые процедуры по-разному оценивают изменения света в разных частях лица, разделенного нами на 14 симметричных зон (сегментов) анализа (рис. 2), а также в отдельных мини-сегментах с учетом вероятности появления AUs на местах перекрытия этих зон. Фактически были созданы компьютерные процедуры, позволяющие анализировать сокращение и растяжение поверхности лица в тех направлениях, которые соответствуют каждой из AUs. Например, очевидно, что метрика для обнаружения движений внутренних частей бровей вверх и друг к другу (AUs 1+4) – это совсем другая метрика по сравнению с горизонтальным сжатием нижних век (AU 7). Описывая в целом алгоритм анализа МА, укажем, что фактически при выделении отдельных AUs нами был реализован принцип многослойного анализа МА: многослойного разделение видеозаписи на отдельные кадры, выделение артефактов, оценка качества видеозаписи, построение сегментной карты лица по автоматически выделенным 68 реперным точкам, соответствующим анатомии лица;
анализ изменений распределения света от кадра кадру в разных сегментах лица, выделение значимых изменений, интерпретация этих изменений на поверхности лица в виде сдвигов кожи, складок, выпуклостей и вогнутостей; этот нижний уровень представляет собой сложный трехэтапный анализ изменений поверхности лица, результатом которого является первичное выделение значимых мимических событий на фоне общего «шума»;
сопоставление выделенных изменений друг с другом в соответствии с анатомическим строением лица и схемой FACS;
выделение начала и окончания отдельных AUs;
выделение эмоций и других сложных мимических паттернов;
расчет интегральных показателей МА, например: частота AUs в единицу времени,  асимметрия, сочетание AUs и речи;
визуализация результатов анализа на временной оси и построение таблицы результатов анализа МА;
сложная категоризация паттернов МА как характерных проявлений мимического поведения: истинные эмоции, эмблемы эмоций, придание эмоциональной модальности речевому высказыванию, индивидуальные мимические привычки, выделение значимых фрагментов речи и др. разделение видеозаписи на отдельные кадры, выделение артефактов, оценка качества видеозаписи, построение сегментной карты лица по автоматически выделенным 68 реперным точкам, соответствующим анатомии лица; разделение видеозаписи на отдельные кадры, выделение артефактов, оценка качества видеозаписи, построение сегментной карты лица по автоматически выделенным 68 реперным точкам, соответствующим анатомии лица; анализ изменений распределения света от кадра кадру в разных сегментах лица, выделение значимых изменений, интерпретация этих изменений на поверхности лица в виде сдвигов кожи, складок, выпуклостей и вогнутостей; этот нижний уровень представляет собой сложный трехэтапный анализ изменений поверхности лица, результатом которого является первичное выделение значимых мимических событий на фоне общего «шума»; анализ изменений распределения света от кадра кадру в разных сегментах лица, выделение значимых изменений, интерпретация этих изменений на поверхности лица в виде сдвигов кожи, складок, выпуклостей и вогнутостей; этот нижний уровень представляет собой сложный трехэтапный анализ изменений поверхности лица, результатом которого является первичное выделение значимых мимических событий на фоне общего «шума»; сопоставление выделенных изменений друг с другом в соответствии с анатомическим строением лица и схемой FACS; сопоставление выделенных изменений друг с другом в соответствии с анатомическим строением лица и схемой FACS; выделение начала и окончания отдельных AUs; выделение начала и окончания отдельных AUs; выделение эмоций и других сложных мимических паттернов; выделение эмоций и других сложных мимических паттернов; расчет интегральных показателей МА, например: частота AUs в единицу времени,  асимметрия, сочетание AUs и речи; расчет интегральных показателей МА, например: частота AUs в единицу времени,  асимметрия, сочетание AUs и речи; визуализация результатов анализа на временной оси и построение таблицы результатов анализа МА; визуализация результатов анализа на временной оси и построение таблицы результатов анализа МА; сложная категоризация паттернов МА как характерных проявлений мимического поведения: истинные эмоции, эмблемы эмоций, придание эмоциональной модальности речевому высказыванию, индивидуальные мимические привычки, выделение значимых фрагментов речи и др. сложная категоризация паттернов МА как характерных проявлений мимического поведения: истинные эмоции, эмблемы эмоций, придание эмоциональной модальности речевому высказыванию, индивидуальные мимические привычки, выделение значимых фрагментов речи и др. В ходе нашей работы была создана система правил, на основании которых «сырые» данные об изменении света преобразуются в движение поверхностей, а они, в свою очередь, – в AUs. Фактически эти правила и их соотношения могут быть прообразом нового компьютерного языка для анализа МА. система правил Апробация разработанной технологии анализа МА В настоящее время в рамках Лаборатории исследования поведения компании «Лицом к лицу» нами разработано ПО ЭмоРадар WR 5.0 для проведения полностью автоматизированного анализа МА по видеозаписям с разрешением не хуже HD, на которых лицо человека записано анфас (с поворотами головы влево-вправо, вверх-вниз не более, чем на 20 градусов) и занимающее по высоте не менее 500 px.  Всего с высокой точностью обнаруживаются 23 основных двигательных единиц: AU 1, 2, 5, 6, 7, 9, 10, 12, 14, 15, 17, 20, 24, 28, 41, 44, 43, 45, 70, 71, 72, 73, 74 а также семь базовых эмоций: радость, удивление, презрение, печаль, отвращение, страх, гнев.  ПО ЭмоРадар  работает под Windows и Ubuntu Linux. ЭмоРадар ПО ЭмоРадар позволяет обрабатывать видеозаписи и просматривать на временной оси изменения МА, отображая на экране монитора разные эмоции и AUs.  Для эмпирической верификации точности и надежности работы созданного ПО мы использовали две базы данных микро- и макро выражений лица – CASME II (Yan et al., 2014) и SAMM (Yap et al., 2020). ПО ЭмоРадар WR 5.0 используется для анализа видеозаписей в ходе судебно-психологической экспертизы в рамках сотрудничества с юристами и экспертами. Это ПО также использовалось для создания методики автоматизированного анализа кадровых интервью совместно с HR-службой одной из крупных промышленных компаний РФ на выборке более 17.000 видео интервью. ПО прошло апробацию в ходе экспериментального исследования магистрантами факультета психологии МГУ имени М.В. Ломоносова поведения человека в особых условиях профессиональной деятельности в рамках проекта «Иммерсия» Института Медико-биологических проблем РАН. Список литературы Гибсон, Дж. Экологический подход к зрительному восприятию. М.: Прогресс, 1988. 464 с. [Gibson J. Ecological approach to visual perception, Moscow, Progress, 1988 (In Russ)].
Лиза Фельдман Баррет. Как рождаются эмоции. Революция в понимании мозга и управлении эмоциями / Пер. с англ. Е. Поникарова. — М.: Манн, Иванов и Фербер, 2018. — 472 с.
Davidson, R. J., Scherer, K. R., & Goldsmith, H. H. (eds). Handbook of Affective Sciences. Oxford Univ. Press, 200
Ekman P., Friesen W.V., Hager J.C. (2002). Facial Action Coding System (FACS): the Manual & the Investigator's Guide. A Human Face, Salt Lake City U.
Davis, Kenneth L., and Jaak Panksepp. The Emotional Foundations of Personality: A Neurobiological and Evolutionary Approach. W.W Norton &amp; Company, 2018.
Oster, Harriet, 'The repertoire of infant facial expressions: an ontogenetic perspective', in Jacqueline Nadel, and Darwin Muir (eds), Emotional Development: Recent Research Advances (Oxford, 2004; online edn, Oxford Academic, 22 Mar. 2012), https://doi.org/10.1093/acprof:oso/9780198528845.003.0010
Rosenberg, E. L., Ekman, P. (2020). What the face reveals basic and applied studies of spontaneous expression using the facial action coding system (FACS). New York: Oxford University Press.
Yan, W., Li, X., Wang, S., Zhao, G., Liu, Y., Chen, Y., Fu, X. (2014). CASME II: An IMPROVED Spontaneous Micro-Expression database and the baseline evaluation. PLoS ONE, 9(1). doi:10.1371/journal.pone.0086041
Yap, C.H., Kendrick, C., &amp; Yap, M.H. (2020). SAMM long Videos: A spontaneous Facial micro- and Macro-Expressions Dataset. 2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020). doi:10.1109/fg47880.2020.00029 Гибсон, Дж. Экологический подход к зрительному восприятию. М.: Прогресс, 1988. 464 с. [Gibson J. Ecological approach to visual perception, Moscow, Progress, 1988 (In Russ)]. Гибсон, Дж. Экологический подход к зрительному восприятию. М.: Прогресс, 1988. 464 с. [Gibson J. Ecological approach to visual perception, Moscow, Progress, 1988 (In Russ)]. Лиза Фельдман Баррет. Как рождаются эмоции. Революция в понимании мозга и управлении эмоциями / Пер. с англ. Е. Поникарова. — М.: Манн, Иванов и Фербер, 2018. — 472 с. Лиза Фельдман Баррет. Как рождаются эмоции. Революция в понимании мозга и управлении эмоциями / Пер. с англ. Е. Поникарова. — М.: Манн, Иванов и Фербер, 2018. — 472 с. Davidson, R. J., Scherer, K. R., & Goldsmith, H. H. (eds). Handbook of Affective Sciences. Oxford Univ. Press, 200 Davidson, R. J., Scherer, K. R., & Goldsmith, H. H. (eds). Handbook of Affective Sciences. Oxford Univ. Press, 200 Ekman P., Friesen W.V., Hager J.C. (2002). Facial Action Coding System (FACS): the Manual & the Investigator's Guide. A Human Face, Salt Lake City U. Ekman P., Friesen W.V., Hager J.C. (2002). Facial Action Coding System (FACS): the Manual & the Investigator's Guide. A Human Face, Salt Lake City U. Davis, Kenneth L., and Jaak Panksepp. The Emotional Foundations of Personality: A Neurobiological and Evolutionary Approach. W.W Norton &amp; Company, 2018. Davis, Kenneth L., and Jaak Panksepp. The Emotional Foundations of Personality: A Neurobiological and Evolutionary Approach. W.W Norton &amp; Company, 2018. Oster, Harriet, 'The repertoire of infant facial expressions: an ontogenetic perspective', in Jacqueline Nadel, and Darwin Muir (eds), Emotional Development: Recent Research Advances (Oxford, 2004; online edn, Oxford Academic, 22 Mar. 2012), https://doi.org/10.1093/acprof:oso/9780198528845.003.0010 Oster, Harriet, 'The repertoire of infant facial expressions: an ontogenetic perspective', in Jacqueline Nadel, and Darwin Muir (eds), Emotional Development: Recent Research Advances (Oxford, 2004; online edn, Oxford Academic, 22 Mar. 2012), https://doi.org/10.1093/acprof:oso/9780198528845.003.0010 https://doi.org/10.1093/acprof:oso/9780198528845.003.0010 Rosenberg, E. L., Ekman, P. (2020). What the face reveals basic and applied studies of spontaneous expression using the facial action coding system (FACS). New York: Oxford University Press. Rosenberg, E. L., Ekman, P. (2020). What the face reveals basic and applied studies of spontaneous expression using the facial action coding system (FACS). New York: Oxford University Press. Yan, W., Li, X., Wang, S., Zhao, G., Liu, Y., Chen, Y., Fu, X. (2014). CASME II: An IMPROVED Spontaneous Micro-Expression database and the baseline evaluation. PLoS ONE, 9(1). doi:10.1371/journal.pone.0086041 Yan, W., Li, X., Wang, S., Zhao, G., Liu, Y., Chen, Y., Fu, X. (2014). CASME II: An IMPROVED Spontaneous Micro-Expression database and the baseline evaluation. PLoS ONE, 9(1). doi:10.1371/journal.pone.0086041 Yap, C.H., Kendrick, C., &amp; Yap, M.H. (2020). SAMM long Videos: A spontaneous Facial micro- and Macro-Expressions Dataset. 2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020). doi:10.1109/fg47880.2020.00029 Yap, C.H., Kendrick, C., &amp; Yap, M.H. (2020). SAMM long Videos: A spontaneous Facial micro- and Macro-Expressions Dataset. 2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020). doi:10.1109/fg47880.2020.00029 Авторы: М.С. Баев (ООО "Лицом к лицу"), А.Н. Гусев (Факультет психологии МГУ имени М.В. Ломоносова), А.Е. Кремлев (Факультет психологии МГУ имени М.В. Ломоносова). М.С. Баев (ООО "Лицом к лицу"), А.Н. Гусев (Факультет психологии МГУ имени М.В. Ломоносова), А.Е. Кремлев (Факультет психологии МГУ имени М.В. Ломоносова). ]]></text>
</doc>
