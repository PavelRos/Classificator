<?xml version="1.0" ?>
<doc>
	<label auto="true" type="str" verify="true"><![CDATA[Develop]]></label>
	<author auto="true" type="list" verify="true">
		<item type="str"><![CDATA[viktar1]]></item>
	</author>
	<date auto="true" type="str" verify="true"><![CDATA[2022-11-30, 02:33]]></date>
	<link auto="true" type="str" verify="true"><![CDATA[https://habr.com/ru/post/702434/]]></link>
	<title auto="true" type="str" verify="true"><![CDATA[Fast-dreambooth. Имба для тонкой настройки StableDiffusion]]></title>
	<categories auto="true" type="list" verify="true">
		<item type="str"><![CDATA[Машинное обучение]]></item>
	</categories>
	<key_words auto="true" type="list" verify="true">
		<item type="str"><![CDATA[DreamBooth]]></item>
		<item type="str"><![CDATA[гайд]]></item>
		<item type="str"><![CDATA[stablediffusion]]></item>
	</key_words>
	<text auto="true" type="str" verify="true"><![CDATA[Всем привет! Для всех кто ищет отправную точку для погружения в мир генеративных нейросетей в этой статье я расскажу как научить StableDiffusion генерировать изображения в вашем стиле. Или даже с вашим лицом.
Подготовка изображений.
StableDiffusion может обучаться на ваших изображениях и первое что вам нужно это подготовить качественные изображения. Я попробовал собрать изображения бельгийского оперного певца Werner Van Mechelen
Werner Van Mechelen
После этого необходимо обрезать изображения до квадрата 512х512 это можно сделать с помощью этого сервиса. Загружаете туда изображения выбираете область кропа и сохраняете как зип файл себе на компьютер.
Birme
Затем нужно переименовать изображения следующим образом. Одинаковое имя + (n) по этому имени вы будете делать запрос к нейросети для генерации вашего изображения. Так что выбирайте то что не занято, что бы не запутать StableDiffusion я использую токен sks.
Именование изображений
Инициализация collab
копируем себе эту версию dreamBooth https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb#scrollTo=O3KHGKqyeJp9
И запускаем эти две ячейки:
Дальше нужно выбрать модель и предоставить токен для скачивания модели. Выбираем тут модель версии 1.5. Можете попытать счастье с версией 2, но у меня не запускалось обучение через этот колаб на второй версии модели, вероятно дело в том, что она появилась буквально несколько дней назад и это ещё не стабильная версия. также вторая версия сложнее в обучения, так что я рекомендую использовать v1.5
Если нет аккаунта на Hugging Face то создайте его и выпустите себе токен для того что бы колаб смог скачать модель StableDiffusion https://huggingface.co/settings/tokens
Дальше создаем сессию, на гуглдиске будет создана папка Fast-Dreambooth/Sessions/werner-van-mechelen так же выбираем опцию Contains_faces так как я обучал на фотографиях мужчины, то выбираю Male.
Теперь запускаем ячейку с загрузкой картинок и перетаскиваем туда картинки. После того как картинки будут загружены ячейка будет выполнена.
Теперь нужно запустить обучения и выбрать некоторые параметры
Training_Steps Умножаем количество картинок на 200 и вводим это число. Это будет количество тренировочных шагов.
Resolution 512
fp16 половинная точность, если эта опция включена то задействуется меньше памяти
Enable_text_encoder_training нужно оставить включенным, так обучения текстового энкодера повышает качество результатов.
Train_text_encoder_for выбираем процент сколько шагов будет тренироваться текстовый энкодер. Чем выше процент, тем более точно сеть будет повторять входные изображения. Но за счёт этого снижается способность к "стилизации". Чем ниже процент тем проще будет стилизовать ваше изображение.
Save_Checkpoint_Every_n_Steps Не рекомендую включать эту галку, так как это может занять много места на гугл диске.
Ждем пока завершится обучение и запускаем получившеюся модель
В результате блокнот даст ссылку на следующий интерфейс:
Я смотрю примеры запросов на этом сайте OpenArt тут можно найти какие изображения генерирует сеть по разным запросам и попробовать найти то что вам понравится. Далеко не все изображения удачные, можно поиграться с запросами и просто попробовать выполнить один запрос несколько раз, так как каждый раз вы будете получать разные изображения.
Вот несколько результатов:
Заключение
Этот блокнот предоставляет очень простой интерфейс для обучения сети и вдобавок сеть версии 1.5 обучается очень легко. Процесс обучения для 20 изображений занимает примерно 2-3 часа. По моим наблюдениям легче всего обучить её на лицах и генерировать разные арты персонажа. Всем привет! Для всех кто ищет отправную точку для погружения в мир генеративных нейросетей в этой статье я расскажу как научить StableDiffusion генерировать изображения в вашем стиле. Или даже с вашим лицом. Подготовка изображений. StableDiffusion может обучаться на ваших изображениях и первое что вам нужно это подготовить качественные изображения. Я попробовал собрать изображения бельгийского оперного певца Werner Van Mechelen  Werner Van Mechelen После этого необходимо обрезать изображения до квадрата 512х512 это можно сделать с помощью этого сервиса. Загружаете туда изображения выбираете область кропа и сохраняете как зип файл себе на компьютер. этого сервиса этого сервиса  Birme Затем нужно переименовать изображения следующим образом. Одинаковое имя + (n) по этому имени вы будете делать запрос к нейросети для генерации вашего изображения. Так что выбирайте то что не занято, что бы не запутать StableDiffusion я использую токен sks.  Именование изображений Инициализация collab копируем себе эту версию dreamBooth https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb#scrollTo=O3KHGKqyeJp9]]></text>
</doc>
