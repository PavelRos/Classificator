<?xml version="1.0" ?>
<doc>
	<label auto="true" type="str" verify="true"><![CDATA[Develop]]></label>
	<author auto="true" type="list" verify="true">
		<item type="str"><![CDATA[Lev_Perla]]></item>
	</author>
	<date auto="true" type="str" verify="true"><![CDATA[2022-11-26, 22:27]]></date>
	<link auto="true" type="str" verify="true"><![CDATA[https://habr.com/ru/post/701798/]]></link>
	<title auto="true" type="str" verify="true"><![CDATA[Как лучше обучать RNN для прогнозирования временных рядов?]]></title>
	<categories auto="true" type="list" verify="true">
		<item type="str"><![CDATA[Python]]></item>
		<item type="str"><![CDATA[Машинное обучение]]></item>
		<item type="str"><![CDATA[Искусственный интеллект]]></item>
		<item type="str"><![CDATA[Финансы в IT]]></item>
	</categories>
	<key_words auto="true" type="list" verify="true">
		<item type="str"><![CDATA[time series forecasting]]></item>
		<item type="str"><![CDATA[rnn]]></item>
		<item type="str"><![CDATA[lstm]]></item>
		<item type="str"><![CDATA[gru]]></item>
		<item type="str"><![CDATA[deep learning]]></item>
	</key_words>
	<text auto="true" type="str" verify="true"><![CDATA[Привет, Хабр!
Два последних года я в рамках магистерской диссертации разбирался с тем, как лучше использовать рекуррентные нейронные сети для прогнозирования временных рядов, и теперь хочу поделиться моим опытом с сообществом.
Я разделил свой рассказ на несколько блоков:
Что такое RNN
Рекуррентные нейроны
Методы обработки временных рядов
Стратегии прогнозирования
Добавление факторов в RNN
Глобальные модели RNN
По ходу статьи я буду приводить выводы, которые основывал на научной литературе и экспериментах, проведенных в рамках моего исследования. Подробно описывать эксперименты в данной статье было бы слишком громоздко, поэтому приведу лишь основные параметры и схемы потока данных каждого из них:
Параметры экспериментов
Желающие ознакомиться с полным текстом магистерской работы и кодом экспериментов могут найти их в этом репозитории.
Что такое RNN?
RNN (Recurrent neural network) – вид нейронной сети, который хорошо подходит для задач обработки последовательностей данных, начиная от обработки естественного языка до прогнозирования временных рядов.
RNN можно использовать для прогнозирования временных рядов из различных сфер жизни. Согласно выводам мета-исследования статей по финансовому прогнозированию, RNN являются наиболее популярными моделями среди исследователей в этой сфере.
Рекуррентные нейроны
Наиболее популярными нейронами RNN являются RNN Элмана, блок долговременной краткосрочной памяти LSTM и блок GRU. Про начинку и принципы работы этих нейронов на Хабре уже написано много статей, поэтому углубляться в это не буду.
Блоки LSTM и GRU были разработаны специально для того, чтобы решить проблемы взрывного и исчезающего градиентов, которые были свойственны простому рекуррентному блоку RNN Элмана.
Согласно исследованию, LSTM показывает наилучшую производительность в задачах прогнозирования временных рядов. На втором месте идет блок GRU и замыкает список RNN Элмана.
Методы обработки временных рядов
В этом разделе разберу основные методы обработки временных рядов и расскажу, как они влияют на качество прогноза RNN моделей.
Метод скользящего окна
При использовании архитектуры Stacked RNN основным шагом обработки временного ряда является метод скользящего окна, который представляет из себя следующую логику:
Метод скользящего окна
Сначала временной ряд длиной L нарезается на части длины inputsize и outputsize. В общей сложности существует (L – outputsize – inputsize) таĸих частей. Здесь outputsize относится ĸ длине выходного окна, в то время как inputsize представляет длину входного окна, используемого в каждом фрагменте обучающей выборки. Обучающий набор данных генерируется путем повторения описанного выше процесса, смещая окно на одно значение вперед до тех пор, пока последняя точка входного окна не будет расположена в L – outputsize.
outputsize определяется, исходя из горизонта прогнозирования и стратегии построения прогноза.
С выбором значения inputsize все обстоит сложнее, так как нужно находить баланс между количеством наблюдений и объемом информации в одном наблюдении. В статье исследователи предложили эмпирическую формулу:
Получается, что длина входного вектора должна быть больше длины выходного вектора и одновременно захватывать весь период сезонности временного ряда.
Согласно результатам исследования, увеличение входного окна позволяет Stacked архитектуре захватить больше внутренних закономерностей временного ряда вне зависимости от того, была ли удалена сезонность или нет. Поэтому, если количество наблюдений вам позволяет, лучше брать inputsize как можно большим.
Заполнение пропущенных значений
RNN не могут работать с пропусками во входных данных, поэтому их необходимо заполнять. Для этого можно использовать разные методы интерполяции временных рядов, описание которых выходит за рамки моей статьи.
Удаление сезонности
На данный момент в литературе нет единого однозначного мнения насчет того, насколько точно рекуррентные нейронные сети способны моделировать сезонные колебания.
Как мы уже говорили, чтобы RNN смогла правильно смоделировать сезонность, необходимо выбрать значение inputsize скользящего окна больше, чем период сезонности ряда. Для коротких рядов это сделать невозможно, так как это приведет к критичному снижению обучающей выборки, поэтому для них лучше пользоваться методами удаления сезонности перед обучением RNN.
В проведенном мной эксперименте на финансовых временных рядах, в которых сезонность часто выражена неявно, модели RNN, обученные на рядах c удаленной сезонностью, показывали качество хуже, чем на рядах без обработки.
При этом простой временной ряд Series G с удалением мультипликативной сезонности модель RNN предсказывает заметно точнее:
Я сделал вывод, что, если во временном ряде нет явной сезонной составляющей, лучше давать нейронной сети самостоятельно выделить эту закономерность.
Масштабирование (нормализация)
Функции активации, используемые в блоках RNN, такие как сигмоида и гиперболический тангенс, имеют области насыщения, в которых выходные данные остаются постоянными.
Поэтому нужно масштабировать временные ряды (привести значения к диапазону [0, 1]) для того, чтобы выход рекуррентных нейронов не попадал в зону насыщения.
Мой первый эксперимент подтвердил увеличение точности прогнозирования RNN после нормализации временных рядов. Модели RNN, обученные на нормированных данных, в среднем имели значение метрики MAPE на 2.33% меньше, чем на ненормированных.
Стабилизация дисперсии ряда
Самыми популярными методами стабилизации дисперсии во временном ряду являются логарифмирование и преобразование Бокса-Кокса.
Исследователи отмечают, что логарифмическое преобразование является сильно нелинейным, и из-за этого модель может неверно воспринять закономерности временного ряда. Поэтому в прогнозировании временных рядов популярнее более консервативный метод Бокса-Кокса. Однако его эффективность сильно зависит от подбора параметра 𝜆.
По результатам моего эксперимента применение логарифмирования позволяет в среднем снизить среднюю процентную ошибку MAPE на 2.1%, а метода Бокса-Кокса на 1.38%.
Переход ĸ разностям
Метод взятия первой разности зачастую позволяет привести временной ряд к стационарной форме. В этом случае модели требуется научиться прогнозировать прирост целевого временного ряда, что позволяет снизить влияние возрастающего тренда, присущего большинству финансовых временных рядов.
Мой первый эксперимент также подтвердил увеличение точности прогнозирования RNN после взятия первой разности. При этом, для этого даже не требовалась нормализация рядов, так как значения приростов не попадали в области насыщения функций внутри рекуррентных блоков. В среднем применение этого метода предобработки позволяло уменьшить MAPE на 3.52%.
Выводы по методам обработки:
Значение inputsize для метода скользящего окна лучше выбирать как можно большим.
Необходимо заполнять пропущенные значения перед обучением RNN.
Для временных рядов с явной сезонностью можно воспользоваться методами удаления сезонности перед обучением RNN. Однако, если сезонность скрытая, лучше подавать временной ряд в нейронную сеть без удаления сезонности.
При использовании моделей RNN в большинстве случаев необходимо масштабировать временные ряды.
Для финансовых временных рядов лучше использовать метод взятия первой разности, как один из шагов обработки ряда.
Стратегии прогнозирования
Стратегиям построения прогноза в большинстве случаев уделяется не так много внимания, поэтому кратко опишу их матчасть.
Согласно статье, существует 5 стратегий построения прогноза:
Recursive
Прогнозирование происходит циклическим добавлением полученного прогноза во вход модели на следующем шаге.
Recursive стратегия
Главный недостаток этой стратегии состоит в том, что происходит накопление ошибки с каждым новым значением прогнозного горизонта. Поэтому она подходит только для прогнозов на короткий период. 
Direct
Для построения прогноза строится H моделей, каждая из которых совершает прогноз на
i-ое значение из прогнозного горизонта, где i∈(1,...,H). Предположим, для прогноза температуры на улице на два дня вперед обучались бы две модели RNN: первая - прогнозировать на завтра, а вторая на послезавтра.
Direct стратегия
У данной стратегии есть закономерный недостаток – требуется сравнительно большее количество времени для обучения.
Multi-Input Multi-Output
При использовании стратегии MIMO выход нейронной сети является вектор длиной прогнозного горизонта.
MiMo стратегия
Эта стратегия позволяет избежать предположения об условной независимости прогнозных значений, сделанного Direct стратегией, а также накопления ошибок, от которых страдает рекурсивная стратегия.
Однако при использовании этой стратегии имеется недостаток фиксации горизонта прогнозирования. При возникновении необходимости прогнозировать на большее количество периодов вперед модель придется переобучать заново. Несмотря на это стратегия MIMO является наиболее популярной среди исследователей и аналитиков данных.
Direct Multi-Output
DirMo стратегия
Данная стратегия является улучшением моделей Direct и MIMO, где прогноз на горизонт H разбивается на блоки, и каждый блок прогнозируется с помощью MIMO стратегии.
Задача прогнозирования на горизонт H разбивается на n multi-out задач, где n=H / s для размера выхода s ∈ (1,...,H). Параметр s можно изменять для получения оптимального значения.
DirRec strategy
DirRec стратегия
В данной стратегии производится прогноз для каждого значения из прогнозного горизонта с помощью отдельной модели (как в Direct стратегии), при этом на каждом шаге увеличивается набор входных данных путем добавления прогноза предыдущего шага (как в рекурсивной стратегии).
Выводы по стратегиям
Стратегии с множественным выходом (MIMO и DIRMO) являются лучшими. Они превосходят по точности стратегии с единственным выходом, такие как Direct, Recursive и DirRec. При этом стратегии MIMO и DIRMO обеспечивают сопоставимую производительность.
Для DIRMO выбор параметра s имеет решающее значение, поскольку он оказывает большое влияние на производительность.
Среди стратегий с единственным выходом стратегия Recursive почти всегда имеет меньший размер и более высокую точность, чем стратегия Direct.
DirRec в целом является худшей стратегией и дает особенно низкую точность, когда не выполняется предварительное удаление сезонности из временного ряда. Более того она является наиболее затратной по необходимым ресурсам и времени обучения.
Данные тенденции сохраняются для финансовых временных рядов.
Добавление факторов в RNN
Модели RNN, которые используют помимо лагов целевого временного ряда дополнительные ряды-факторы, называют многомерными RNN моделями.
Основная прелесть многомерных RNN моделей заключается в том, что теперь одним наблюдением у нас является не вектор, а матрица размера inputsize * (n_features + 1). Простыми словами, чтобы спрогнозировать несколько значений вперед мы будем использовать лаги целевого показателя и одновременно лаги каждого из факторов. Это позволяет учесть больше информации для прогноза.
Нужно отметить, что временные ряды-факторы тоже необходимо нормализовать.
Третий эксперимент подтвердил увеличение качества прогноза при добавлении факторов в модель RNN. Нужно отметить, что при этом проводился отбор значимых факторов с помощью метода permutation feature importance.
Глобальные модели RNN
В современных задачах прогнозирования часто требуется составлять прогнозы для групп временных рядов, которые могут иметь схожие закономерности, в отличие от прогнозирования только одного временного ряда.
Например, вашей компании нужно найти прогноз спроса на кофе в трех кофейнях в разных городах. Очевидно, что продажи кофе в кофейнях не влияют друг на друга, но могут изменяться схожим образом. Поэтому вместо того, чтобы строить отдельную модель для каждой кофейни, можно обучить одну глобальную для всех трех временных рядов. На моей практике с помощью использования данного подхода удалось улучшить качество прогнозной системы на несколько процентов.
Для обучения глобальной модели каждый из временных рядов обрабатывается методом скользящего окна и объединяется с остальными в единую базу для обучения единой RNN модели.
В отличие от подхода многомерных моделей, применение глобальных моделей к набору временных рядов не указывает на какую-либо взаимозависимость между ними в отношении прогноза.
Хочется отметить, что в 2018 году на международном соревновании по прогнозированию временных рядов M4 победила модель, которая комбинировала метод экспоненциального сглаживания и глобальную рекуррентную нейронную сеть.
Достоинства глобальных моделей:
Сложность и размер глобальной модели не меняются от количества временных рядов в датасете.
Потенциальное увеличение качества прогноза за счет увеличения обучающей выборки.
Недостатки глобальных моделей:
Если ряды в обучающей выборке имеют различную структуру, глобальная модель имеет склонность к переобучению.
Глобальные модели чувствительны к сезонным колебаниям внутри рядов.
Подводим итоги
Блоки LSTM в среднем показывают наилучшую производительность среди рекуррентных блоков. Если критичен размер модели, то можно использовать блоки GRU.
Размер входного вектора нужно выбирать, ориентируясь на три момента: длина прогнозного горизонта, период сезонности, количество данных.
Я рекомендую всегда проводить масштабирование временных рядов перед обучением, RNN модели чувствительны к ненормализованным данным из-за нелинейных функций в структуре их нейронов.
Для финансовых временных рядов, которым свойственен возрастающий тренд, я рекомендую использовать метод взятия первой разности. Проведение данной процедуры позволяет модели RNN уделять большее внимание волатильности, а не тренду целевого временного ряда.
Для временных рядов с ярко выраженной сезонностью можно использовать методы удаления сезонности перед обучением RNN. Однако для временных рядов, в которых сезонность выражена плохо, я рекомендую давать возможность рекуррентной нейронной сети самостоятельно выделять сезонную составляющую на этапе обучения модели.
В качестве стратегии прогнозирования я рекомендую использовать MIMO, которая является оптимальной с точки зрения сложности модели и получаемой точности прогнозов.
Использование объясняющих факторов в комбинации с лагами целевого временного ряда действительно позволяет увеличить качество прогноза, однако требует более детального внимания к конфигурации модели рекуррентной нейронной сети и набору факторов.
Глобальные RNN модели из-за высокой чувствительности к особенностям индивидуальных временных рядов нужно использовать в рамках групп рядов с одинаковой сезонностью и паттернами изменения.
Рассмотренные методы, стратегии и модификации моделей можно протестировать самостоятельно с помощью написанной мной библиотеки ts-rnn для Python на базе Keras, которую можно найти в моем github.
***
Буду рад пообщаться и ответить на вопросы в комментариях. Привет, Хабр! Два последних года я в рамках магистерской диссертации разбирался с тем, как лучше использовать рекуррентные нейронные сети для прогнозирования временных рядов, и теперь хочу поделиться моим опытом с сообществом. Я разделил свой рассказ на несколько блоков: Что такое RNN
Рекуррентные нейроны
Методы обработки временных рядов
Стратегии прогнозирования
Добавление факторов в RNN
Глобальные модели RNN Что такое RNN Что такое RNN Рекуррентные нейроны Рекуррентные нейроны Методы обработки временных рядов Методы обработки временных рядов Стратегии прогнозирования Стратегии прогнозирования Добавление факторов в RNN Добавление факторов в RNN Глобальные модели RNN Глобальные модели RNN По ходу статьи я буду приводить выводы, которые основывал на научной литературе и экспериментах, проведенных в рамках моего исследования. Подробно описывать эксперименты в данной статье было бы слишком громоздко, поэтому приведу лишь основные параметры и схемы потока данных каждого из них: Параметры экспериментов Параметры экспериментов                                   Желающие ознакомиться с полным текстом магистерской работы и кодом экспериментов могут найти их в этом репозитории. репозитории Что такое RNN? RNN (Recurrent neural network) – вид нейронной сети, который хорошо подходит для задач обработки последовательностей данных, начиная от обработки естественного языка до прогнозирования временных рядов. RNN (Recurrent neural network) RNN можно использовать для прогнозирования временных рядов из различных сфер жизни. Согласно выводам мета-исследования статей по финансовому прогнозированию, RNN являются наиболее популярными моделями среди исследователей в этой сфере. мета-исследования Рекуррентные нейроны Наиболее популярными нейронами RNN являются RNN Элмана, блок долговременной краткосрочной памяти LSTM и блок GRU. Про начинку и принципы работы этих нейронов на Хабре уже написано много статей, поэтому углубляться в это не буду. Блоки LSTM и GRU были разработаны специально для того, чтобы решить проблемы взрывного и исчезающего градиентов, которые были свойственны простому рекуррентному блоку RNN Элмана. Согласно исследованию, LSTM показывает наилучшую производительность в задачах прогнозирования временных рядов. На втором месте идет блок GRU и замыкает список RNN Элмана. исследованию Методы обработки временных рядов В этом разделе разберу основные методы обработки временных рядов и расскажу, как они влияют на качество прогноза RNN моделей. Метод скользящего окна Метод скользящего окна При использовании архитектуры Stacked RNN основным шагом обработки временного ряда является метод скользящего окна, который представляет из себя следующую логику:  Метод скользящего окна Сначала временной ряд длиной L нарезается на части длины inputsize и outputsize. В общей сложности существует (L – outputsize – inputsize) таĸих частей. Здесь outputsize относится ĸ длине выходного окна, в то время как inputsize представляет длину входного окна, используемого в каждом фрагменте обучающей выборки. Обучающий набор данных генерируется путем повторения описанного выше процесса, смещая окно на одно значение вперед до тех пор, пока последняя точка входного окна не будет расположена в L – outputsize. outputsize определяется, исходя из горизонта прогнозирования и стратегии построения прогноза. outputsize С выбором значения inputsize все обстоит сложнее, так как нужно находить баланс между количеством наблюдений и объемом информации в одном наблюдении. В статье исследователи предложили эмпирическую формулу: inputsize статье  Получается, что длина входного вектора должна быть больше длины выходного вектора и одновременно захватывать весь период сезонности временного ряда. Согласно результатам исследования, увеличение входного окна позволяет Stacked архитектуре захватить больше внутренних закономерностей временного ряда вне зависимости от того, была ли удалена сезонность или нет. Поэтому, если количество наблюдений вам позволяет, лучше брать inputsize как можно большим. исследования Заполнение пропущенных значений Заполнение пропущенных значений RNN не могут работать с пропусками во входных данных, поэтому их необходимо заполнять. Для этого можно использовать разные методы интерполяции временных рядов, описание которых выходит за рамки моей статьи. Удаление сезонности Удаление сезонности На данный момент в литературе нет единого однозначного мнения насчет того, насколько точно рекуррентные нейронные сети способны моделировать сезонные колебания. Как мы уже говорили, чтобы RNN смогла правильно смоделировать сезонность, необходимо выбрать значение inputsize скользящего окна больше, чем период сезонности ряда. Для коротких рядов это сделать невозможно, так как это приведет к критичному снижению обучающей выборки, поэтому для них лучше пользоваться методами удаления сезонности перед обучением RNN. В проведенном мной эксперименте на финансовых временных рядах, в которых сезонность часто выражена неявно, модели RNN, обученные на рядах c удаленной сезонностью, показывали качество хуже, чем на рядах без обработки. При этом простой временной ряд Series G с удалением мультипликативной сезонности модель RNN предсказывает заметно точнее:   Я сделал вывод, что, если во временном ряде нет явной сезонной составляющей, лучше давать нейронной сети самостоятельно выделить эту закономерность. Масштабирование (нормализация) Масштабирование (нормализация) Функции активации, используемые в блоках RNN, такие как сигмоида и гиперболический тангенс, имеют области насыщения, в которых выходные данные остаются постоянными.   Поэтому нужно масштабировать временные ряды (привести значения к диапазону [0, 1]) для того, чтобы выход рекуррентных нейронов не попадал в зону насыщения. Мой первый эксперимент подтвердил увеличение точности прогнозирования RNN после нормализации временных рядов. Модели RNN, обученные на нормированных данных, в среднем имели значение метрики MAPE на 2.33% меньше, чем на ненормированных. Стабилизация дисперсии ряда Стабилизация дисперсии ряда Самыми популярными методами стабилизации дисперсии во временном ряду являются логарифмирование и преобразование Бокса-Кокса.   Исследователи отмечают, что логарифмическое преобразование является сильно нелинейным, и из-за этого модель может неверно воспринять закономерности временного ряда. Поэтому в прогнозировании временных рядов популярнее более консервативный метод Бокса-Кокса. Однако его эффективность сильно зависит от подбора параметра 𝜆. По результатам моего эксперимента применение логарифмирования позволяет в среднем снизить среднюю процентную ошибку MAPE на 2.1%, а метода Бокса-Кокса на 1.38%. Переход ĸ разностям Переход ĸ разностям  Метод взятия первой разности зачастую позволяет привести временной ряд к стационарной форме. В этом случае модели требуется научиться прогнозировать прирост целевого временного ряда, что позволяет снизить влияние возрастающего тренда, присущего большинству финансовых временных рядов. Мой первый эксперимент также подтвердил увеличение точности прогнозирования RNN после взятия первой разности. При этом, для этого даже не требовалась нормализация рядов, так как значения приростов не попадали в области насыщения функций внутри рекуррентных блоков. В среднем применение этого метода предобработки позволяло уменьшить MAPE на 3.52%. Выводы по методам обработки: Выводы по методам обработки: Значение inputsize для метода скользящего окна лучше выбирать как можно большим.
Необходимо заполнять пропущенные значения перед обучением RNN.
Для временных рядов с явной сезонностью можно воспользоваться методами удаления сезонности перед обучением RNN. Однако, если сезонность скрытая, лучше подавать временной ряд в нейронную сеть без удаления сезонности.
При использовании моделей RNN в большинстве случаев необходимо масштабировать временные ряды.
Для финансовых временных рядов лучше использовать метод взятия первой разности, как один из шагов обработки ряда. Значение inputsize для метода скользящего окна лучше выбирать как можно большим. Значение inputsize для метода скользящего окна лучше выбирать как можно большим. Необходимо заполнять пропущенные значения перед обучением RNN. Необходимо заполнять пропущенные значения перед обучением RNN. Для временных рядов с явной сезонностью можно воспользоваться методами удаления сезонности перед обучением RNN. Однако, если сезонность скрытая, лучше подавать временной ряд в нейронную сеть без удаления сезонности. Для временных рядов с явной сезонностью можно воспользоваться методами удаления сезонности перед обучением RNN. Однако, если сезонность скрытая, лучше подавать временной ряд в нейронную сеть без удаления сезонности. При использовании моделей RNN в большинстве случаев необходимо масштабировать временные ряды. При использовании моделей RNN в большинстве случаев необходимо масштабировать временные ряды. Для финансовых временных рядов лучше использовать метод взятия первой разности, как один из шагов обработки ряда. Для финансовых временных рядов лучше использовать метод взятия первой разности, как один из шагов обработки ряда. Стратегии прогнозирования Стратегиям построения прогноза в большинстве случаев уделяется не так много внимания, поэтому кратко опишу их матчасть. Согласно статье, существует 5 стратегий построения прогноза: статье Recursive Recursive Прогнозирование происходит циклическим добавлением полученного прогноза во вход модели на следующем шаге.  Recursive стратегия Главный недостаток этой стратегии состоит в том, что происходит накопление ошибки с каждым новым значением прогнозного горизонта. Поэтому она подходит только для прогнозов на короткий период.    Direct Direct Для построения прогноза строится H моделей, каждая из которых совершает прогноз на
i-ое значение из прогнозного горизонта, где i∈(1,...,H). Предположим, для прогноза температуры на улице на два дня вперед обучались бы две модели RNN: первая - прогнозировать на завтра, а вторая на послезавтра.   Direct стратегия У данной стратегии есть закономерный недостаток – требуется сравнительно большее количество времени для обучения. Multi-Input Multi-Output Multi-Input Multi-Output При использовании стратегии MIMO выход нейронной сети является вектор длиной прогнозного горизонта.  MiMo стратегия Эта стратегия позволяет избежать предположения об условной независимости прогнозных значений, сделанного Direct стратегией, а также накопления ошибок, от которых страдает рекурсивная стратегия. Однако при использовании этой стратегии имеется недостаток фиксации горизонта прогнозирования. При возникновении необходимости прогнозировать на большее количество периодов вперед модель придется переобучать заново. Несмотря на это стратегия MIMO является наиболее популярной среди исследователей и аналитиков данных. Direct Multi-Output Direct Multi-Output  DirMo стратегия Данная стратегия является улучшением моделей Direct и MIMO, где прогноз на горизонт H разбивается на блоки, и каждый блок прогнозируется с помощью MIMO стратегии. Задача прогнозирования на горизонт H разбивается на n multi-out задач, где n=H / s для размера выхода s ∈ (1,...,H). Параметр s можно изменять для получения оптимального значения. DirRec strategy DirRec strategy  DirRec стратегия В данной стратегии производится прогноз для каждого значения из прогнозного горизонта с помощью отдельной модели (как в Direct стратегии), при этом на каждом шаге увеличивается набор входных данных путем добавления прогноза предыдущего шага (как в рекурсивной стратегии). Выводы по стратегиям Выводы по стратегиям Стратегии с множественным выходом (MIMO и DIRMO) являются лучшими. Они превосходят по точности стратегии с единственным выходом, такие как Direct, Recursive и DirRec. При этом стратегии MIMO и DIRMO обеспечивают сопоставимую производительность.
Для DIRMO выбор параметра s имеет решающее значение, поскольку он оказывает большое влияние на производительность.
Среди стратегий с единственным выходом стратегия Recursive почти всегда имеет меньший размер и более высокую точность, чем стратегия Direct.
DirRec в целом является худшей стратегией и дает особенно низкую точность, когда не выполняется предварительное удаление сезонности из временного ряда. Более того она является наиболее затратной по необходимым ресурсам и времени обучения.
Данные тенденции сохраняются для финансовых временных рядов. Стратегии с множественным выходом (MIMO и DIRMO) являются лучшими. Они превосходят по точности стратегии с единственным выходом, такие как Direct, Recursive и DirRec. При этом стратегии MIMO и DIRMO обеспечивают сопоставимую производительность. Стратегии с множественным выходом (MIMO и DIRMO) являются лучшими. Они превосходят по точности стратегии с единственным выходом, такие как Direct, Recursive и DirRec. При этом стратегии MIMO и DIRMO обеспечивают сопоставимую производительность. Для DIRMO выбор параметра s имеет решающее значение, поскольку он оказывает большое влияние на производительность. Для DIRMO выбор параметра s имеет решающее значение, поскольку он оказывает большое влияние на производительность. Среди стратегий с единственным выходом стратегия Recursive почти всегда имеет меньший размер и более высокую точность, чем стратегия Direct. Среди стратегий с единственным выходом стратегия Recursive почти всегда имеет меньший размер и более высокую точность, чем стратегия Direct. DirRec в целом является худшей стратегией и дает особенно низкую точность, когда не выполняется предварительное удаление сезонности из временного ряда. Более того она является наиболее затратной по необходимым ресурсам и времени обучения. DirRec в целом является худшей стратегией и дает особенно низкую точность, когда не выполняется предварительное удаление сезонности из временного ряда. Более того она является наиболее затратной по необходимым ресурсам и времени обучения. Данные тенденции сохраняются для финансовых временных рядов. Данные тенденции сохраняются для финансовых временных рядов. Добавление факторов в RNN Модели RNN, которые используют помимо лагов целевого временного ряда дополнительные ряды-факторы, называют многомерными RNN моделями.   Основная прелесть многомерных RNN моделей заключается в том, что теперь одним наблюдением у нас является не вектор, а матрица размера inputsize * (n_features + 1). Простыми словами, чтобы спрогнозировать несколько значений вперед мы будем использовать лаги целевого показателя и одновременно лаги каждого из факторов. Это позволяет учесть больше информации для прогноза. Нужно отметить, что временные ряды-факторы тоже необходимо нормализовать. Третий эксперимент подтвердил увеличение качества прогноза при добавлении факторов в модель RNN. Нужно отметить, что при этом проводился отбор значимых факторов с помощью метода permutation feature importance. Глобальные модели RNN В современных задачах прогнозирования часто требуется составлять прогнозы для групп временных рядов, которые могут иметь схожие закономерности, в отличие от прогнозирования только одного временного ряда. Например, вашей компании нужно найти прогноз спроса на кофе в трех кофейнях в разных городах. Очевидно, что продажи кофе в кофейнях не влияют друг на друга, но могут изменяться схожим образом. Поэтому вместо того, чтобы строить отдельную модель для каждой кофейни, можно обучить одну глобальную для всех трех временных рядов. На моей практике с помощью использования данного подхода удалось улучшить качество прогнозной системы на несколько процентов. Для обучения глобальной модели каждый из временных рядов обрабатывается методом скользящего окна и объединяется с остальными в единую базу для обучения единой RNN модели. В отличие от подхода многомерных моделей, применение глобальных моделей к набору временных рядов не указывает на какую-либо взаимозависимость между ними в отношении прогноза. Хочется отметить, что в 2018 году на международном соревновании по прогнозированию временных рядов M4 победила модель, которая комбинировала метод экспоненциального сглаживания и глобальную рекуррентную нейронную сеть. модель Достоинства глобальных моделей: Достоинства глобальных моделей Сложность и размер глобальной модели не меняются от количества временных рядов в датасете.
Потенциальное увеличение качества прогноза за счет увеличения обучающей выборки. Сложность и размер глобальной модели не меняются от количества временных рядов в датасете. Сложность и размер глобальной модели не меняются от количества временных рядов в датасете. Потенциальное увеличение качества прогноза за счет увеличения обучающей выборки. Потенциальное увеличение качества прогноза за счет увеличения обучающей выборки. Недостатки глобальных моделей: Недостатки глобальных моделей Если ряды в обучающей выборке имеют различную структуру, глобальная модель имеет склонность к переобучению.
Глобальные модели чувствительны к сезонным колебаниям внутри рядов. Если ряды в обучающей выборке имеют различную структуру, глобальная модель имеет склонность к переобучению. Если ряды в обучающей выборке имеют различную структуру, глобальная модель имеет склонность к переобучению. Глобальные модели чувствительны к сезонным колебаниям внутри рядов. Глобальные модели чувствительны к сезонным колебаниям внутри рядов. Подводим итоги Блоки LSTM в среднем показывают наилучшую производительность среди рекуррентных блоков. Если критичен размер модели, то можно использовать блоки GRU.
Размер входного вектора нужно выбирать, ориентируясь на три момента: длина прогнозного горизонта, период сезонности, количество данных.
Я рекомендую всегда проводить масштабирование временных рядов перед обучением, RNN модели чувствительны к ненормализованным данным из-за нелинейных функций в структуре их нейронов.
Для финансовых временных рядов, которым свойственен возрастающий тренд, я рекомендую использовать метод взятия первой разности. Проведение данной процедуры позволяет модели RNN уделять большее внимание волатильности, а не тренду целевого временного ряда.
Для временных рядов с ярко выраженной сезонностью можно использовать методы удаления сезонности перед обучением RNN. Однако для временных рядов, в которых сезонность выражена плохо, я рекомендую давать возможность рекуррентной нейронной сети самостоятельно выделять сезонную составляющую на этапе обучения модели.
В качестве стратегии прогнозирования я рекомендую использовать MIMO, которая является оптимальной с точки зрения сложности модели и получаемой точности прогнозов.
Использование объясняющих факторов в комбинации с лагами целевого временного ряда действительно позволяет увеличить качество прогноза, однако требует более детального внимания к конфигурации модели рекуррентной нейронной сети и набору факторов.
Глобальные RNN модели из-за высокой чувствительности к особенностям индивидуальных временных рядов нужно использовать в рамках групп рядов с одинаковой сезонностью и паттернами изменения. Блоки LSTM в среднем показывают наилучшую производительность среди рекуррентных блоков. Если критичен размер модели, то можно использовать блоки GRU. Блоки LSTM в среднем показывают наилучшую производительность среди рекуррентных блоков. Если критичен размер модели, то можно использовать блоки GRU. Блоки LSTM Размер входного вектора нужно выбирать, ориентируясь на три момента: длина прогнозного горизонта, период сезонности, количество данных. Размер входного вектора нужно выбирать, ориентируясь на три момента: длина прогнозного горизонта, период сезонности, количество данных. Размер входного вектора Я рекомендую всегда проводить масштабирование временных рядов перед обучением, RNN модели чувствительны к ненормализованным данным из-за нелинейных функций в структуре их нейронов. Я рекомендую всегда проводить масштабирование временных рядов перед обучением, RNN модели чувствительны к ненормализованным данным из-за нелинейных функций в структуре их нейронов. всегда проводить масштабирование Для финансовых временных рядов, которым свойственен возрастающий тренд, я рекомендую использовать метод взятия первой разности. Проведение данной процедуры позволяет модели RNN уделять большее внимание волатильности, а не тренду целевого временного ряда. Для финансовых временных рядов, которым свойственен возрастающий тренд, я рекомендую использовать метод взятия первой разности. Проведение данной процедуры позволяет модели RNN уделять большее внимание волатильности, а не тренду целевого временного ряда. Для финансовых временных рядов метод взятия первой разности Для временных рядов с ярко выраженной сезонностью можно использовать методы удаления сезонности перед обучением RNN. Однако для временных рядов, в которых сезонность выражена плохо, я рекомендую давать возможность рекуррентной нейронной сети самостоятельно выделять сезонную составляющую на этапе обучения модели. Для временных рядов с ярко выраженной сезонностью можно использовать методы удаления сезонности перед обучением RNN. Однако для временных рядов, в которых сезонность выражена плохо, я рекомендую давать возможность рекуррентной нейронной сети самостоятельно выделять сезонную составляющую на этапе обучения модели. давать возможность рекуррентной нейронной сети самостоятельно выделять сезонную составляющую В качестве стратегии прогнозирования я рекомендую использовать MIMO, которая является оптимальной с точки зрения сложности модели и получаемой точности прогнозов. В качестве стратегии прогнозирования я рекомендую использовать MIMO, которая является оптимальной с точки зрения сложности модели и получаемой точности прогнозов. MIMO Использование объясняющих факторов в комбинации с лагами целевого временного ряда действительно позволяет увеличить качество прогноза, однако требует более детального внимания к конфигурации модели рекуррентной нейронной сети и набору факторов. Использование объясняющих факторов в комбинации с лагами целевого временного ряда действительно позволяет увеличить качество прогноза, однако требует более детального внимания к конфигурации модели рекуррентной нейронной сети и набору факторов. Использование объясняющих факторов позволяет увеличить качество прогноза Глобальные RNN модели из-за высокой чувствительности к особенностям индивидуальных временных рядов нужно использовать в рамках групп рядов с одинаковой сезонностью и паттернами изменения. Глобальные RNN модели из-за высокой чувствительности к особенностям индивидуальных временных рядов нужно использовать в рамках групп рядов с одинаковой сезонностью и паттернами изменения. Глобальные RNN модели Рассмотренные методы, стратегии и модификации моделей можно протестировать самостоятельно с помощью написанной мной библиотеки ts-rnn для Python на базе Keras, которую можно найти в моем github. github *** Буду рад пообщаться и ответить на вопросы в комментариях. ]]></text>
</doc>
