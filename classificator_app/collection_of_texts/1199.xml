<?xml version="1.0" ?>
<doc>
	<label auto="true" type="str" verify="true"><![CDATA[Other]]></label>
	<author auto="true" type="list" verify="true">
		<item type="str"><![CDATA[snakers4]]></item>
	</author>
	<date auto="true" type="str" verify="true"><![CDATA[2022-06-29, 11:38]]></date>
	<link auto="true" type="str" verify="true"><![CDATA[https://habr.com/ru/post/673996/]]></link>
	<title auto="true" type="str" verify="true"><![CDATA[Может ли синтез речи обмануть систему биометрической идентификации?]]></title>
	<categories auto="true" type="list" verify="true">
		<item type="str"><![CDATA[Информационная безопасность]]></item>
		<item type="str"><![CDATA[Машинное обучение]]></item>
		<item type="str"><![CDATA[Голосовые интерфейсы]]></item>
	</categories>
	<key_words auto="true" type="list" verify="true">
		<item type="str"><![CDATA[синтез речи]]></item>
		<item type="str"><![CDATA[биометрия]]></item>
		<item type="str"><![CDATA[биометрическая идентификация]]></item>
		<item type="str"><![CDATA[служба поддержки]]></item>
	</key_words>
	<text auto="true" type="str" verify="true"><![CDATA[Александр, вас беспокоят из службы поддержки ЗверьБанка!
Под одной из наших недавних статей на Хабре я упомянул исследование, подробно рассматривающее вопрос "обмана" коммерческих систем биометрической идентификации с помощью открытых инструментов по клонированию голоса. Завязалась дискуссия на тему "стоит ли бояться, что ваш голос украдут".
Естественно, исследование четкого однозначного ответа не дает, но скорее говорит, что на пути злоумышленников в первую очередь встает несовершенство систем клонирования голоса, количество и качество записей полученных мошенниками, акценты и прочие несовершенства мира. Проценты "обмана" при наличии ряда таких затруднений там не впечатляющие.
Так уж получилось, что один из наших заказчиков, заказывал у нас голос для синтеза … как раз с целью сделать пен-тест коммерческой системы биометрической идентификации. Не могу назвать (и даже не знаю) вендора этой системы, но заказчик - это довольно крупная и известная фирма (они попросили не упоминать какие-либо названия).
Короткий ответ на вопрос из заголовка - да, причем весьма успешно. Длинный ответ - скорее всего вам этого бояться не следует. Постараюсь объяснить почему. Поехали.
Качество аудио и версия синтеза речи
Голос делался на старой версии нашего синтеза речи, которая еще имела ряд ярких детских "болячек".
Также важно сказать, что:
Записано было около пары часов в относительно хороший микрофон (сейчас достаточно даже 15 минут речи);
Обладатель голоса - не диктор, просто условно случайный сотрудник с яркими артефактами дикции (системный администратор);
Микрофон был хорошим, но на фоне немного гудел кондиционер;
Результаты
Описанная выше система голосовой биометрической идентификации выдает скор менее 1.1, если она считает, что в двух аудио-файлах говорит один и тот же человек, и скор более 1.1, если считает, что люди - разные (эти пороги были выставлены заказчиком или вендором системы).
100 реальных аудио человека сравниваются со 100 разными сгенерированными примерами (включая пример с таким же текстом), созданными на основе текстов этих же 100 реальных аудио.
На картинке ниже вы можете увидеть сравнение 100 реальных аудио со 100 сгенерированными аудио и скоры системы (помечено цветом). Зеленым цветом (скор менее 1) помечено, что система "считает" эту пару записей одним человеком. Красным - это "разные" люди (скор более 1.1). Желтый - это пограничные значения (скор между 1 и 1.1).
Если взять среднее значение по точке отсечения 1.1 (порог установлен заказчиком), то получается, что в среднем НЕ УДАЛОСЬ обмануть систему где-то в 10% случаев. То есть в 90% случаев систему обмануть УДАЛОСЬ.
По общей "матрице" также видно, что "плохие" (или "хорошие", тут как смотреть) примеры сгруппированы. По отзывам заказчика, основные ошибки относились скорее к недостаткам именно старой системы синтеза:
Нестабильная работа;
Нестабильность на более длинных аудио и на совсем коротких аудио;
Система не принимала более 140 символов на вход;
Эти артефакты были поправлены с переходом на новый синтез речи и в текущей версии синтеза в рамках одного предложения определить синтез ли это уже практически невозможно (но эксперимент мы ещё не повторяли).
Вывод
Кажется, что нужно начинать паниковать, ведь люди заморочились, заказали модель, провели пен-тест какой-то супер-коммерческой системы и оказалось, что в 90% случаев её можно обмануть! Ужас! Но на самом деле конечно никакого повода для паники нет.
Мы записывали аудио на качественный микрофон в относительной тишине. Мы приложили максимум усилий для обработки и чистки аудио и вложили некоторое количество вычислительных ресурсов (нетривиальное, но и не десятки тысяч GPU-дней).
Абсолютно очевидно, что для массового обмана наш подход не подходит, равно как и системы клонирования голоса в текущем состоянии (хотя интересный прогресс конечно есть).
Даже если мошенники будут так же подкованы (или будут таргетировать супер "важную" цель с помощью некоторых неадекватно дорогих и непрактичных публичных инструментов) - на их пути встанет низкое качество голосовых семплов, которые они скорее всего смогут получить "левыми" способами. А понижение качества качества аудио и его количества резко понижает качество результата. Плюс многие "халявные" инструменты заточены только на английский язык по очевидным причинам. А исследование в начале статьи явно указывает на смену акцента / диалекта как основную причину резкого понижения вероятности успеха "атаки".
Плюс нужно держать в уме, что полноценный синтез всегда звучит лучше, чем клонирование голоса. Ну и конечно шутливый вывод: если голосовая фраза - единственный ключ (а не часть составного) у вашего вендора услуг - бегите в любом случае. Никто в здравом уме и так не рассматривает голос как основной ключ (в отличие от смешных поползновений некоторых успешно и активно обнуляющихся банков собирать ваши селфи).  Александр, вас беспокоят из службы поддержки ЗверьБанка! Под одной из наших недавних статей на Хабре я упомянул исследование, подробно рассматривающее вопрос "обмана" коммерческих систем биометрической идентификации с помощью открытых инструментов по клонированию голоса. Завязалась дискуссия на тему "стоит ли бояться, что ваш голос украдут". статей исследование Естественно, исследование четкого однозначного ответа не дает, но скорее говорит, что на пути злоумышленников в первую очередь встает несовершенство систем клонирования голоса, количество и качество записей полученных мошенниками, акценты и прочие несовершенства мира. Проценты "обмана" при наличии ряда таких затруднений там не впечатляющие. Так уж получилось, что один из наших заказчиков, заказывал у нас голос для синтеза … как раз с целью сделать пен-тест коммерческой системы биометрической идентификации. Не могу назвать (и даже не знаю) вендора этой системы, но заказчик - это довольно крупная и известная фирма (они попросили не упоминать какие-либо названия). Короткий ответ на вопрос из заголовка - да, причем весьма успешно. Длинный ответ - скорее всего вам этого бояться не следует. Постараюсь объяснить почему. Поехали. Качество аудио и версия синтеза речи Голос делался на старой версии нашего синтеза речи, которая еще имела ряд ярких детских "болячек". старой версии Также важно сказать, что: Записано было около пары часов в относительно хороший микрофон (сейчас достаточно даже 15 минут речи);
Обладатель голоса - не диктор, просто условно случайный сотрудник с яркими артефактами дикции (системный администратор);
Микрофон был хорошим, но на фоне немного гудел кондиционер; Записано было около пары часов в относительно хороший микрофон (сейчас достаточно даже 15 минут речи); Записано было около пары часов в относительно хороший микрофон (сейчас достаточно даже 15 минут речи); Обладатель голоса - не диктор, просто условно случайный сотрудник с яркими артефактами дикции (системный администратор); Обладатель голоса - не диктор, просто условно случайный сотрудник с яркими артефактами дикции (системный администратор); Микрофон был хорошим, но на фоне немного гудел кондиционер; Микрофон был хорошим, но на фоне немного гудел кондиционер; Результаты Описанная выше система голосовой биометрической идентификации выдает скор менее 1.1, если она считает, что в двух аудио-файлах говорит один и тот же человек, и скор более 1.1, если считает, что люди - разные (эти пороги были выставлены заказчиком или вендором системы). 100 реальных аудио человека сравниваются со 100 разными сгенерированными примерами (включая пример с таким же текстом), созданными на основе текстов этих же 100 реальных аудио. На картинке ниже вы можете увидеть сравнение 100 реальных аудио со 100 сгенерированными аудио и скоры системы (помечено цветом). Зеленым цветом (скор менее 1) помечено, что система "считает" эту пару записей одним человеком. Красным - это "разные" люди (скор более 1.1). Желтый - это пограничные значения (скор между 1 и 1.1).   Если взять среднее значение по точке отсечения 1.1 (порог установлен заказчиком), то получается, что в среднем НЕ УДАЛОСЬ обмануть систему где-то в 10% случаев. То есть в 90% случаев систему обмануть УДАЛОСЬ. По общей "матрице" также видно, что "плохие" (или "хорошие", тут как смотреть) примеры сгруппированы. По отзывам заказчика, основные ошибки относились скорее к недостаткам именно старой системы синтеза: Нестабильная работа;
Нестабильность на более длинных аудио и на совсем коротких аудио;
Система не принимала более 140 символов на вход; Нестабильная работа; Нестабильная работа; Нестабильность на более длинных аудио и на совсем коротких аудио; Нестабильность на более длинных аудио и на совсем коротких аудио; Система не принимала более 140 символов на вход; Система не принимала более 140 символов на вход; Эти артефакты были поправлены с переходом на новый синтез речи и в текущей версии синтеза в рамках одного предложения определить синтез ли это уже практически невозможно (но эксперимент мы ещё не повторяли). новый синтез речи Вывод Кажется, что нужно начинать паниковать, ведь люди заморочились, заказали модель, провели пен-тест какой-то супер-коммерческой системы и оказалось, что в 90% случаев её можно обмануть! Ужас! Но на самом деле конечно никакого повода для паники нет. Мы записывали аудио на качественный микрофон в относительной тишине. Мы приложили максимум усилий для обработки и чистки аудио и вложили некоторое количество вычислительных ресурсов (нетривиальное, но и не десятки тысяч GPU-дней). Абсолютно очевидно, что для массового обмана наш подход не подходит, равно как и системы клонирования голоса в текущем состоянии (хотя интересный прогресс конечно есть). Даже если мошенники будут так же подкованы (или будут таргетировать супер "важную" цель с помощью некоторых неадекватно дорогих и непрактичных публичных инструментов) - на их пути встанет низкое качество голосовых семплов, которые они скорее всего смогут получить "левыми" способами. А понижение качества качества аудио и его количества резко понижает качество результата. Плюс многие "халявные" инструменты заточены только на английский язык по очевидным причинам. А исследование в начале статьи явно указывает на смену акцента / диалекта как основную причину резкого понижения вероятности успеха "атаки". Плюс нужно держать в уме, что полноценный синтез всегда звучит лучше, чем клонирование голоса. Ну и конечно шутливый вывод: если голосовая фраза - единственный ключ (а не часть составного) у вашего вендора услуг - бегите в любом случае. Никто в здравом уме и так не рассматривает голос как основной ключ (в отличие от смешных поползновений некоторых успешно и активно обнуляющихся банков собирать ваши селфи). ]]></text>
</doc>
