<?xml version="1.0" ?>
<doc>
	<label auto="true" type="str" verify="true"><![CDATA[Develop]]></label>
	<author auto="true" type="list" verify="true">
		<item type="str"><![CDATA[nlpist]]></item>
	</author>
	<date auto="true" type="str" verify="true"><![CDATA[2022-12-03, 22:53]]></date>
	<link auto="true" type="str" verify="true"><![CDATA[https://habr.com/ru/post/703334/]]></link>
	<title auto="true" type="str" verify="true"><![CDATA[Обучение Russian SuperGLUE моделей с помощью библиотеки DeepPavlov]]></title>
	<categories auto="true" type="list" verify="true">
		<item type="str"><![CDATA[Open source]]></item>
		<item type="str"><![CDATA[Python]]></item>
		<item type="str"><![CDATA[Машинное обучение]]></item>
		<item type="str"><![CDATA[Искусственный интеллект]]></item>
		<item type="str"><![CDATA[Natural Language Processing]]></item>
	</categories>
	<key_words auto="true" type="list" verify="true">
		<item type="str"><![CDATA[nlp (natural language processing)]]></item>
		<item type="str"><![CDATA[ai]]></item>
		<item type="str"><![CDATA[deeppavlov]]></item>
		<item type="str"><![CDATA[python]]></item>
		<item type="str"><![CDATA[pytorch]]></item>
		<item type="str"><![CDATA[обработка текстов]]></item>
		<item type="str"><![CDATA[bert]]></item>
		<item type="str"><![CDATA[deep learning]]></item>
		<item type="str"><![CDATA[transfer learning]]></item>
		<item type="str"><![CDATA[нейронные сети]]></item>
	</key_words>
	<text auto="true" type="str" verify="true"><![CDATA[Соревнования GLUE и SuperGLUE
В последние годы соревнования GLUE и SuperGLUE на английском языке стали стандартным бенчмарком для определения возможностей универсальных языковых моделей, таких как BERT, RoBERTa в решении широкого круга задач обработки естественного языка, в том числе задач с недостаточной обучающей выборкой. Соревнования GLUE/SuperGLUE представляют собой наборы задач NLP на основе ранее представленных датасетов. Академическое сообщество NLP довольно быстро расправилось с GLUE, отчасти вследствие того, что задачи были довольно однотипные, они сводились либо к парной текстовой классификации, либо к классификации единственной последовательности. Ответом на это был новый набор задач SuperGLUE, в состав которого вошли вопросно-ответные задачи, задачи кореференции и задачи семантического следования. На данный момент модели, обученные на базе ERNIE и DeBERT, превзошли качество разметки человеком.
Соревнование Russian SuperGLUE
Соревнования GLUE/SuperGLUE исключительно про английский язык, а что с русским? В 2020 нашими коллегами из команды AGI NLP Сбербанка, лаборатории Noah’s Ark Huawei и факультета компьютерных наук ВШЭ был представлен Russian SuperGLUE — набор задач на понимание текста по аналогии с его английской версией SuperGLUE. Создание набора задач для русского языка позволило сравнивать качество предобученных универсальных языковых моделей русского языка. В отличие от SuperGLUE некоторые датасеты русского языка были собраны и размечены специально для Russian SuperGLUE. Таким образом, задачи Russian SuperGLUE отражают особенности русского языка, например, более свободный порядок слов, чем в английском. Подробнее про Russian SuperGLUE в можно узнать в статье неподражаемой @Rybolos.
На данный момент лидерборд Russian SuperGLUE содержит более двадцати сабмитов на основе разных универсальных языковых моделей. Среди них сабмит на дообученном русcком BERT. Однако на момент написании статьи ни одна из моделей так и не превзошла качество разметки человеком. Значит, соревнование до сих пор остается актуальным.
Сравнение моделей jiant и DeepPavlov для задач Russian SuperGLUE
Исторически в качестве тестового стенда для задач SuperGLUE использовалась библиотека jiant, разработанная в группе машинного обучения Нью-Йоркского университета. В библиотеку интегрированы задачи GLUE, SuperGLUE и EXTREME. Библиотека поддерживает многозадачное обучение, методы переноса знаний. Однако неожиданно для всех в 2021 году разработчики библиотеки сообщили, что они более не собираются поддерживать jiant.
Мы в DeepPavlov не могли оставить сообщество без поддержки этих моделей и в новом релизе подготовили для вас наши базовые решения для задач соревнования Russian SuperGLUE, которые по усредненным метрикам качества превосходят аналогичные базовые решения jiant. Все модели реализованы на PyTorch с использованием пакета transformers🤗, таким образом вы можете использовать любую подходящую модель из нашего хаба или из хаба наших друзей из Sber AI. Ниже в таблице приведено сравнение базовых моделей jiant и DeepPavlov, дообученных на DeepPavlov/rubert-base-cased, а также ссылки на конфигурационные файлы Russian SuperGLUE моделей в библиотеке DeepPavlov.
Задача
Метрика
jiant(rubert)
DeepPavlov(rubert)
Lidirus
Matthews Corr
0.191
0.251
RCB
Avg. F1 / Accuracy
0.367 / 0.463 
0.336 / 0.486
PARus
Accuracy
0.574 
0.588
MuSeRC
F1a / EM
0.711 / 0.324
0.689 / 0.298
TERRa
Accuracy
0.642 
0.65
RUSSE
Accuracy
0.726 
0.641
RWSD
Accuracy
0.669 
0.669
DaNetQA
Accuracy
0.639
0.647
RuCoS
F1 / EM
0.32 / 0.314 
0.77 / 0.768
Использование моделей Russian SuperGLUE в библиотеке DeepPavlov
Для установки библиотеки DeepPavlov необходимо запустить:
pip install deeppavlov==1.0.1
По традиции все модели в нашей библиотеки описаны с помощью конфигурационных файлов разбитых на пять основных секций: dataset_reader, dataset_iterator, chainer, train, и metadata. 
Секция dataset_reader определяет набор данных модели. Секция chainer устанавливает порядок запуска компонентов модели (препроцессор, классификатор, построцессор и другие). metadata описывает переменные, которые использует модель, например, ссылка на предобученную модель и другие. Секция train описывает параметры обучения, такие как: batch_size, epochs и другие.
Изучив, из чего состоит конфигурационный файл, перейдем непосредственно к командам обучения и инференса. Для примера все команды приведены для задачи TERRa. Textual Entailment Recognition for Russian (TERRa) — это модель семантического следования, которая на основании двух текстовых последовательностей определяет следует ли одна из другой или нет, ниже приведена пара последовательностей, для которой не соблюдается условие семантического следования:
"premise": "На большей части региона пройдет небольшой снег, а морозы вновь начнут усиливаться."
"hypothesis": "Повсюду пройдет снег."
"label": "not_entailment"
Для того, чтобы проверить качество работы предобученной модели на валидационной выборке необходимо запустить:
python -m deeppavlov evaluate russian_superglue_terra_rubert -d -i
где флаг -d указывает на то, что предобученную модель необходимо сначала скачать, а флаг -i инициирует установку дополнительных зависимостей для запуска модели.
Для того, чтобы подготовить файл для сабмита на лидерборд, необходимо запустить:
python -m deeppavlov.utils.benchmarks.superglue russian_superglue_terra_rubert [-d] [-o <output_file_name.jsonl>]
Если вы тестируете свою универсальный языковую модель, то сначала необходимо объявить путь к модель в переменной конфигурационного файла BASE_MODEL, определить желаемые гиперпараметры и дообучить модель, запустив:
python -m deeppavlov train russian_superglue_terra_rubert [-i]
Обратите внимание, что обученная модель будет сохранена в папку, на которую указывает переменная MODEL_PATH конфигурационного файла. Для того, чтобы поработать с моделью в интерактивном режиме необходимо запустить:
python -m deeppavlov interact russian_superglue_terra_rubert [-d] [-i]
Кроме того, библиотека DeepPavlov позволяет поднять REST API сервер с предобученной моделью:
python -m deeppavlov riseapi russian_superglue_terra_rubert [-d] [-i]
Далее я расскажу про то как улучшить качество моделей Russian SuperGLUE, используя методы переноса знаний.
Применение методов переноса знаний к задачам SuperGLUE/Russian SuperGLUE
Задачи Russian SuperGLUE — это отличный тест для ваших предобученных универсальных языковых моделей и библиотека DeepPavlov позволяет вам легко дообучить ваши модели и протестировать, загрузив размеченные файлы на лидерборд.
Наличие разнообразных задач на нескольких языках открывает для нас перспективы применения методов переноса. Перенос знаний — это механизм, позволяющий использовать знания полученные при обучении некоторой исходной задачи для улучшения качества некоторой целевой задачи.
Один из способов применения переноса знаний к задачам SuperGLUE/Russian SuperGLUE — это использование многозадачного обучения, который подробно описывают авторы MT-DNN. Этот способ подразумевает, что все задачи обучаются с использованием единой модели на основе кодировщика Трансформера. При этом для каждой задачи формируется отдельный финальный слой. Такой подход позволил не только сэкономить вычислительные ресурсы, используя единую модель, но и еще превзойти отдельно обученные модели на основе того же кодировщика.
Задачи Russian SuperGLUE сильно отличаются друг от друга по размеру обучающих выборок, например, TERRа — 2.616 обучающих пар, при этом RCB — всего 438. Очевидно, что если предварительно предобучить модель на задаче TERRа, а потом дообучить на RCB, то мы улучшим качество последней. Такой метод переноса знаний называется последовательный перенос, когда целевая задача использует знания, полученные при обучении исходной задачи. При этом исходная и целевая задачи должны быть "схожи".
Предобучение многоязычных моделей таких как M-BERT, XLM-RoBERTa и других вернули интерес к межъязыковому переносу, когда многоязычная модель предварительно обучается на выборке одного языка, затем дообучается на выборке целевого языка. Межъязыковой перенос допускает, что может отсутствовать обучающая выборка целевой задачи, что, однако, негативно повлияет на качество последней. Наличие идентичных задач SuperGLUE на разных языках позволяет нам задействовать межъязыковой перенос знаний для улучшения качества задач Russian SuperGLUE.
А что, если "я занимаюсь NLP в коммерческой компании и мне нет никакого интереса до набора задач Russian SuperGLUE для оценки качества языковых моделей?" Справедливое утверждение, Russian SuperGLUE не покрывает все возможные задачи, которые встают перед NLP-инженером, однако многие практические задачи можно с легкостью свести к одной из задач Russian SuperGLUE и получить качество на уровне лучших текущих решений. Например, задача текстовой классификации на основании ограниченной обучающей выборки (few-shot text classification), популярный запрос к библиотеке DeepPavlov, элементарно сводится к задаче семантического следования (TERRa, RCB).
Итак, надеюсь, я вас убедил, что задачи Russian SuperGLUE полезны не только для академического сообщества, но также для IT-гигантов и небольших компаний, которые привлекают NLP-технологии для решения своих бизнес-задач.
Я надеюсь статья была для вас полезна. Подробности про использование моделей Russian SuperGLUE можно найти в справке библиотеки DeepPavlov. Кроме моделей Russian SuperGLUE библиотека DeepPavlov содержит большое количество других NLP моделей, которые могут быть использованы как самостоятельно, так и в качестве компонентов для разработки диалоговых ассистентов. Некоторые модели DeepPavlov доступны в нашем демо. Вопросы по библиотеке DeepPavlov можно оставлять на нашем форуме. Буду рад обратной связи, а еще напишите в комментариях каких моделей вам не хватает в библиотеке DeepPavlov.
Полезные ссылки:
Cтатья Люди ломаются на логике, роботы — на всем понемногу. Экзамены по русскому для NLP-моделей от @Rybolos
Научная статья RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark
Конфигурационные файлы моделей Russian SuperGLUE в библиотеке DeepPavlov
Документация по моделям Russian SuperGLUE в библиотеке DeepPavlov
Введение в библиотеку DeepPavlov   Соревнования GLUE и SuperGLUE В последние годы соревнования GLUE и SuperGLUE на английском языке стали стандартным бенчмарком для определения возможностей универсальных языковых моделей, таких как BERT, RoBERTa в решении широкого круга задач обработки естественного языка, в том числе задач с недостаточной обучающей выборкой. Соревнования GLUE/SuperGLUE представляют собой наборы задач NLP на основе ранее представленных датасетов. Академическое сообщество NLP довольно быстро расправилось с GLUE, отчасти вследствие того, что задачи были довольно однотипные, они сводились либо к парной текстовой классификации, либо к классификации единственной последовательности. Ответом на это был новый набор задач SuperGLUE, в состав которого вошли вопросно-ответные задачи, задачи кореференции и задачи семантического следования. На данный момент модели, обученные на базе ERNIE и DeBERT, превзошли качество разметки человеком. GLUE GLUE SuperGLUE SuperGLUE Соревнование Russian SuperGLUE Соревнования GLUE/SuperGLUE исключительно про английский язык, а что с русским? В 2020 нашими коллегами из команды AGI NLP Сбербанка, лаборатории Noah’s Ark Huawei и факультета компьютерных наук ВШЭ был представлен Russian SuperGLUE — набор задач на понимание текста по аналогии с его английской версией SuperGLUE. Создание набора задач для русского языка позволило сравнивать качество предобученных универсальных языковых моделей русского языка. В отличие от SuperGLUE некоторые датасеты русского языка были собраны и размечены специально для Russian SuperGLUE. Таким образом, задачи Russian SuperGLUE отражают особенности русского языка, например, более свободный порядок слов, чем в английском. Подробнее про Russian SuperGLUE в можно узнать в статье неподражаемой @Rybolos. Russian SuperGLUE Russian SuperGLUE статье статье @Rybolos На данный момент лидерборд Russian SuperGLUE содержит более двадцати сабмитов на основе разных универсальных языковых моделей. Среди них сабмит на дообученном русcком BERT. Однако на момент написании статьи ни одна из моделей так и не превзошла качество разметки человеком. Значит, соревнование до сих пор остается актуальным. русcком BERT русcком BERT Сравнение моделей jiant и DeepPavlov для задач Russian SuperGLUE Исторически в качестве тестового стенда для задач SuperGLUE использовалась библиотека jiant, разработанная в группе машинного обучения Нью-Йоркского университета. В библиотеку интегрированы задачи GLUE, SuperGLUE и EXTREME. Библиотека поддерживает многозадачное обучение, методы переноса знаний. Однако неожиданно для всех в 2021 году разработчики библиотеки сообщили, что они более не собираются поддерживать jiant. jiant jiant Мы в DeepPavlov не могли оставить сообщество без поддержки этих моделей и в новом релизе подготовили для вас наши базовые решения для задач соревнования Russian SuperGLUE, которые по усредненным метрикам качества превосходят аналогичные базовые решения jiant. Все модели реализованы на PyTorch с использованием пакета transformers🤗, таким образом вы можете использовать любую подходящую модель из нашего хаба или из хаба наших друзей из Sber AI. Ниже в таблице приведено сравнение базовых моделей jiant и DeepPavlov, дообученных на DeepPavlov/rubert-base-cased, а также ссылки на конфигурационные файлы Russian SuperGLUE моделей в библиотеке DeepPavlov. новом релизе новом релизе Russian SuperGLUE Russian SuperGLUE нашего нашего хаба хаба DeepPavlov/rubert-base-cased DeepPavlov/rubert-base-cased ссылки Задача
Метрика
jiant(rubert)
DeepPavlov(rubert)
Lidirus
Matthews Corr
0.191
0.251
RCB
Avg. F1 / Accuracy
0.367 / 0.463 
0.336 / 0.486
PARus
Accuracy
0.574 
0.588
MuSeRC
F1a / EM
0.711 / 0.324
0.689 / 0.298
TERRa
Accuracy
0.642 
0.65
RUSSE
Accuracy
0.726 
0.641
RWSD
Accuracy
0.669 
0.669
DaNetQA
Accuracy
0.639
0.647
RuCoS
F1 / EM
0.32 / 0.314 
0.77 / 0.768 Задача
Метрика
jiant(rubert)
DeepPavlov(rubert)
Lidirus
Matthews Corr
0.191
0.251
RCB
Avg. F1 / Accuracy
0.367 / 0.463 
0.336 / 0.486
PARus
Accuracy
0.574 
0.588
MuSeRC
F1a / EM
0.711 / 0.324
0.689 / 0.298
TERRa
Accuracy
0.642 
0.65
RUSSE
Accuracy
0.726 
0.641
RWSD
Accuracy
0.669 
0.669
DaNetQA
Accuracy
0.639
0.647
RuCoS
F1 / EM
0.32 / 0.314 
0.77 / 0.768 Задача
Метрика
jiant(rubert)
DeepPavlov(rubert)
Lidirus
Matthews Corr
0.191
0.251
RCB
Avg. F1 / Accuracy
0.367 / 0.463 
0.336 / 0.486
PARus
Accuracy
0.574 
0.588
MuSeRC
F1a / EM
0.711 / 0.324
0.689 / 0.298
TERRa
Accuracy
0.642 
0.65
RUSSE
Accuracy
0.726 
0.641
RWSD
Accuracy
0.669 
0.669
DaNetQA
Accuracy
0.639
0.647
RuCoS
F1 / EM
0.32 / 0.314 
0.77 / 0.768 Задача
Метрика
jiant(rubert)
DeepPavlov(rubert)
Lidirus
Matthews Corr
0.191
0.251
RCB
Avg. F1 / Accuracy
0.367 / 0.463 
0.336 / 0.486
PARus
Accuracy
0.574 
0.588
MuSeRC
F1a / EM
0.711 / 0.324
0.689 / 0.298
TERRa
Accuracy
0.642 
0.65
RUSSE
Accuracy
0.726 
0.641
RWSD
Accuracy
0.669 
0.669
DaNetQA
Accuracy
0.639
0.647
RuCoS
F1 / EM
0.32 / 0.314 
0.77 / 0.768 Задача
Метрика
jiant(rubert)
DeepPavlov(rubert) Задача Задача Задача Метрика Метрика Метрика jiant(rubert) jiant(rubert) jiant(rubert) DeepPavlov(rubert) DeepPavlov(rubert) DeepPavlov(rubert) Lidirus
Matthews Corr
0.191
0.251 Lidirus Lidirus Lidirus Matthews Corr Matthews Corr Matthews Corr 0.191 0.191 0.251 0.251 0.251 RCB
Avg. F1 / Accuracy
0.367 / 0.463 
0.336 / 0.486 RCB RCB RCB Avg. F1 / Accuracy Avg. F1 / Accuracy Avg. F1 / Accuracy 0.367 / 0.463  0.367 / 0.463  0.367 0.336 / 0.486 0.336 / 0.486 0.486 PARus
Accuracy
0.574 
0.588 PARus PARus PARus Accuracy Accuracy Accuracy 0.574  0.574  0.588 0.588 0.588 MuSeRC
F1a / EM
0.711 / 0.324
0.689 / 0.298 MuSeRC MuSeRC MuSeRC F1a / EM F1a / EM F1a / EM 0.711 / 0.324 0.711 / 0.324 0.711 / 0.324 0.689 / 0.298 0.689 / 0.298 TERRa
Accuracy
0.642 
0.65 TERRa TERRa TERRa Accuracy Accuracy Accuracy 0.642  0.642  0.65 0.65 0.65 RUSSE
Accuracy
0.726 
0.641 RUSSE RUSSE RUSSE Accuracy Accuracy Accuracy 0.726  0.726  0.726  0.641 0.641 RWSD
Accuracy
0.669 
0.669 RWSD RWSD RWSD Accuracy Accuracy Accuracy 0.669  0.669  0.669 0.669 DaNetQA
Accuracy
0.639
0.647 DaNetQA DaNetQA DaNetQA Accuracy Accuracy 0.639 0.639 0.647 0.647 0.647 RuCoS
F1 / EM
0.32 / 0.314 
0.77 / 0.768 RuCoS RuCoS RuCoS F1 / EM F1 / EM F1 / EM 0.32 / 0.314  0.32 / 0.314  0.77 / 0.768 0.77 / 0.768 0.77 / 0.768 Использование моделей Russian SuperGLUE в библиотеке DeepPavlov Для установки библиотеки DeepPavlov необходимо запустить: pip install deeppavlov==1.0.1 pip install deeppavlov==1.0.1 По традиции все модели в нашей библиотеки описаны с помощью конфигурационных файлов разбитых на пять основных секций: dataset_reader, dataset_iterator, chainer, train, и metadata.  dataset_reader dataset_iterator chainer train metadata . Секция dataset_reader определяет набор данных модели. Секция chainer устанавливает порядок запуска компонентов модели (препроцессор, классификатор, построцессор и другие). metadata описывает переменные, которые использует модель, например, ссылка на предобученную модель и другие. Секция train описывает параметры обучения, такие как: batch_size, epochs и другие. dataset_reader chainer metadata train batch_size epochs Изучив, из чего состоит конфигурационный файл, перейдем непосредственно к командам обучения и инференса. Для примера все команды приведены для задачи TERRa. Textual Entailment Recognition for Russian (TERRa) — это модель семантического следования, которая на основании двух текстовых последовательностей определяет следует ли одна из другой или нет, ниже приведена пара последовательностей, для которой не соблюдается условие семантического следования: TERRa TERRa "premise": "На большей части региона пройдет небольшой снег, а морозы вновь начнут усиливаться."
"hypothesis": "Повсюду пройдет снег."
"label": "not_entailment" "premise": "На большей части региона пройдет небольшой снег, а морозы вновь начнут усиливаться." premise "На большей части региона пройдет небольшой снег, а морозы вновь начнут усиливаться." "hypothesis": "Повсюду пройдет снег." hypothesis "Повсюду пройдет снег." "label": "not_entailment" label "not_entailment" Для того, чтобы проверить качество работы предобученной модели на валидационной выборке необходимо запустить: python -m deeppavlov evaluate russian_superglue_terra_rubert -d -i python -m deeppavlov evaluate russian_superglue_terra_rubert -d -i где флаг -d указывает на то, что предобученную модель необходимо сначала скачать, а флаг -i инициирует установку дополнительных зависимостей для запуска модели. -d -i Для того, чтобы подготовить файл для сабмита на лидерборд, необходимо запустить: python -m deeppavlov.utils.benchmarks.superglue russian_superglue_terra_rubert [-d] [-o <output_file_name.jsonl>] python -m deeppavlov.utils.benchmarks.superglue russian_superglue_terra_rubert [-d] [-o <output_file_name.jsonl>] Если вы тестируете свою универсальный языковую модель, то сначала необходимо объявить путь к модель в переменной конфигурационного файла BASE_MODEL, определить желаемые гиперпараметры и дообучить модель, запустив: BASE_MODEL , python -m deeppavlov train russian_superglue_terra_rubert [-i] python -m deeppavlov train russian_superglue_terra_rubert [-i] Обратите внимание, что обученная модель будет сохранена в папку, на которую указывает переменная MODEL_PATH конфигурационного файла. Для того, чтобы поработать с моделью в интерактивном режиме необходимо запустить: MODEL_PATH python -m deeppavlov interact russian_superglue_terra_rubert [-d] [-i] python -m deeppavlov interact russian_superglue_terra_rubert [-d] [-i] Кроме того, библиотека DeepPavlov позволяет поднять REST API сервер с предобученной моделью: python -m deeppavlov riseapi russian_superglue_terra_rubert [-d] [-i] python -m deeppavlov riseapi russian_superglue_terra_rubert [-d] [-i] Далее я расскажу про то как улучшить качество моделей Russian SuperGLUE, используя методы переноса знаний. Применение методов переноса знаний к задачам SuperGLUE/Russian SuperGLUE Задачи Russian SuperGLUE — это отличный тест для ваших предобученных универсальных языковых моделей и библиотека DeepPavlov позволяет вам легко дообучить ваши модели и протестировать, загрузив размеченные файлы на лидерборд. лидерборд Наличие разнообразных задач на нескольких языках открывает для нас перспективы применения методов переноса. Перенос знаний — это механизм, позволяющий использовать знания полученные при обучении некоторой исходной задачи для улучшения качества некоторой целевой задачи. Один из способов применения переноса знаний к задачам SuperGLUE/Russian SuperGLUE — это использование многозадачного обучения, который подробно описывают авторы MT-DNN. Этот способ подразумевает, что все задачи обучаются с использованием единой модели на основе кодировщика Трансформера. При этом для каждой задачи формируется отдельный финальный слой. Такой подход позволил не только сэкономить вычислительные ресурсы, используя единую модель, но и еще превзойти отдельно обученные модели на основе того же кодировщика. многозадачного обучения описывают Задачи Russian SuperGLUE сильно отличаются друг от друга по размеру обучающих выборок, например, TERRа — 2.616 обучающих пар, при этом RCB — всего 438. Очевидно, что если предварительно предобучить модель на задаче TERRа, а потом дообучить на RCB, то мы улучшим качество последней. Такой метод переноса знаний называется последовательный перенос, когда целевая задача использует знания, полученные при обучении исходной задачи. При этом исходная и целевая задачи должны быть "схожи". последовательный перенос Предобучение многоязычных моделей таких как M-BERT, XLM-RoBERTa и других вернули интерес к межъязыковому переносу, когда многоязычная модель предварительно обучается на выборке одного языка, затем дообучается на выборке целевого языка. Межъязыковой перенос допускает, что может отсутствовать обучающая выборка целевой задачи, что, однако, негативно повлияет на качество последней. Наличие идентичных задач SuperGLUE на разных языках позволяет нам задействовать межъязыковой перенос знаний для улучшения качества задач Russian SuperGLUE. Межъязыковой перенос А что, если "я занимаюсь NLP в коммерческой компании и мне нет никакого интереса до набора задач Russian SuperGLUE для оценки качества языковых моделей?" Справедливое утверждение, Russian SuperGLUE не покрывает все возможные задачи, которые встают перед NLP-инженером, однако многие практические задачи можно с легкостью свести к одной из задач Russian SuperGLUE и получить качество на уровне лучших текущих решений. Например, задача текстовой классификации на основании ограниченной обучающей выборки (few-shot text classification), популярный запрос к библиотеке DeepPavlov, элементарно сводится к задаче семантического следования (TERRa, RCB). "я занимаюсь NLP в коммерческой компании и мне нет никакого интереса до набора задач Russian SuperGLUE для оценки качества языковых моделей?" Итак, надеюсь, я вас убедил, что задачи Russian SuperGLUE полезны не только для академического сообщества, но также для IT-гигантов и небольших компаний, которые привлекают NLP-технологии для решения своих бизнес-задач. Я надеюсь статья была для вас полезна. Подробности про использование моделей Russian SuperGLUE можно найти в справке библиотеки DeepPavlov. Кроме моделей Russian SuperGLUE библиотека DeepPavlov содержит большое количество других NLP моделей, которые могут быть использованы как самостоятельно, так и в качестве компонентов для разработки диалоговых ассистентов. Некоторые модели DeepPavlov доступны в нашем демо. Вопросы по библиотеке DeepPavlov можно оставлять на нашем форуме. Буду рад обратной связи, а еще напишите в комментариях каких моделей вам не хватает в библиотеке DeepPavlov. справке справке диалоговых ассистентов демо демо форуме форуме Буду рад обратной связи, а еще напишите в комментариях каких моделей вам не хватает в библиотеке DeepPavlov. Полезные ссылки: Cтатья Люди ломаются на логике, роботы — на всем понемногу. Экзамены по русскому для NLP-моделей от @Rybolos
Научная статья RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark
Конфигурационные файлы моделей Russian SuperGLUE в библиотеке DeepPavlov
Документация по моделям Russian SuperGLUE в библиотеке DeepPavlov
Введение в библиотеку DeepPavlov Cтатья Люди ломаются на логике, роботы — на всем понемногу. Экзамены по русскому для NLP-моделей от @Rybolos Cтатья Люди ломаются на логике, роботы — на всем понемногу. Экзамены по русскому для NLP-моделей от @Rybolos Люди ломаются на логике, роботы — на всем понемногу. Экзамены по русскому для NLP-моделей @Rybolos Научная статья RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark Научная статья RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark Конфигурационные файлы моделей Russian SuperGLUE в библиотеке DeepPavlov Конфигурационные файлы моделей Russian SuperGLUE в библиотеке DeepPavlov Конфигурационные файлы Документация по моделям Russian SuperGLUE в библиотеке DeepPavlov Документация по моделям Russian SuperGLUE в библиотеке DeepPavlov Документация Введение в библиотеку DeepPavlov Введение в библиотеку DeepPavlov Введение ]]></text>
</doc>
