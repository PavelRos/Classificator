<?xml version="1.0" ?>
<doc>
	<original_author auto="true" type="list" verify="true">
		<item type="str"><![CDATA[Elaine Atwell]]></item>
	</original_author>
	<label auto="true" type="str" verify="true"><![CDATA[Develop]]></label>
	<author auto="true" type="list" verify="true">
		<item type="str"><![CDATA[itglobalcom]]></item>
	</author>
	<date auto="true" type="str" verify="true"><![CDATA[2022-12-07, 11:04]]></date>
	<link auto="true" type="str" verify="true"><![CDATA[https://habr.com/ru/company/itglobalcom/blog/703962/]]></link>
	<title auto="true" type="str" verify="true"><![CDATA[GitHub Copilot: он не стоит таких рисков]]></title>
	<categories auto="true" type="list" verify="true">
		<item type="str"><![CDATA[Блог компании ITGLOBAL.COM]]></item>
		<item type="str"><![CDATA[GitHub]]></item>
	</categories>
	<key_words auto="true" type="list" verify="true">
		<item type="str"><![CDATA[ии]]></item>
		<item type="str"><![CDATA[copilot]]></item>
	</key_words>
	<text auto="true" type="str" verify="true"><![CDATA[3 ноября программист и правовед Мэтью Баттерик совместно с юридической фирмой Джозефа Савери подал коллективный иск против GitHub, Microsoft (его материнской компании) и OpenAI.
Иск, поданный «от имени группы предполагаемых миллионов пользователей GitHub», направлен против GitHub Copilot, инструмента на основе искусственного интеллекта, выполняющего функцию продвинутого автокомплита для программистов. Разработчики, установившие Copilot в качестве дополнения к IDE, вводят подсказки на естественном языке, а Copilot выдает предложения по написанию кода на десятках языков программирования.
Генеральный директор GitHub Томас Дохмке ранее заявлял, будто Copilot способен избавить программистов от 40% рабочей нагрузки, предлагая им шаблонные фрагменты кода — в теории это позволит избежать долгих часов изысканий, проб и ошибок.
Но Бутерик и другие критики Copilot утверждают, что многие предложения Copilot вовсе не являются «шаблонными»; в них безошибочно угадываются следы оригинальных авторов, поскольку Copilot был «обучен» на хранилищах публичного и открытого кода GitHub.
Этот иск, как и масштабные дебаты вокруг Copilot, поднимает массу сложных вопросов: технологических, юридических, этических и даже экзистенциальных.
Например:
Что для ИИ означает «учиться»?
Являются ли инструменты ИИ, такие как Copilot, началом новой эры инноваций или они просто-напросто ликвидируют человеческий труд и творческий подход?
Является ли код в большей степени подобием искусства или же математики? И зависит ли от ответа на этот вопрос то, как с ним следует обращаться с точки зрения закона?
Эти вопросы бесконечно провоцируют споры, и в этой статье мы слегка затронем каждый из них.
Однако существует еще более насущный вопрос, на который техническим директорам следует ответить прямо сейчас: стоит ли мне позволять использование Copilot внутри своей компании? 
Как вы могли догадаться по заголовку этой статьи, мы настроены против корпоративного использования Copilot — по крайней мере, пока над ним нависло столько нерешенных юридических вопросов.
В этой статье мы рассмотрим аргументы как за, так и против Copilot, а также расскажем, как вы сможете проверить, не используют ли его в вашей организации прямо у вас за спиной.
Как обычно, мы напоминаем, что все сказанное ниже не должно рассматриваться как юридическая консультация, и перед принятием правовых решений необходимо проконсультироваться с профессиональным юристом.
Юридические риски Copilot
Бутерик подробно рассказал о своем видении экзистенциальной угрозы Copilot для сообщества open source, но его иск сводится к гораздо более прозаичному вопросу нарушения авторских прав. Бутерик и его коллеги утверждают, что предложения по коду Copilot берет из программ с открытым исходным кодом, и, не указывая ссылки на оригинал, он нарушает условия open source лицензий.
Очевидно, что организации, использующие Copilot, подвержены такому же риску.
Краткое руководство по лицензиям на ПО с открытым исходным кодом
Лицензии на программное обеспечение с открытым исходным кодом не монолитны, поэтому разные лицензии накладывают разные ограничения на то, как сторонние разработчики могут использовать исходный код. «Разрешительные» лицензии, такие как MIT и Apache Licenses, позволяют разработчикам изменять и распространять код так, как они считают нужным. С другой стороны, лицензии с copyleft, такие как GPL, требуют, чтобы при любом повторном использовании соблюдались условия оригинальной лицензии.
Существуют и другие важные различия между лицензиями на ПО с открытым исходным кодом, но для наших целей важнее всего то, что их объединяет: все они требуют от разработчиков указывать авторство, включая оригинальное уведомление об авторских правах. Это гарантирует (среди прочего), что программное обеспечение не содержит несовместимых лицензий. Как объясняет Бутерик, нельзя создавать программное обеспечение с лицензией MIT, используя код с лицензией GPL, потому что нельзя передавать другим людям права, которых у вас самого никогда не было.
Copilot отнимает у кода лицензию, поэтому разработчики, использующие его, рискуют случайно нарушить чьи-то авторские права. Это подвергает компании риску судебных исков, особенно со стороны групп по защите ПО с открытым исходным кодом, таких как Software Freedom Conservancy (SFC).
Конкуренты Copilot
К вашему сведению, Copilot — это не единственный инструмент, который дописывает код за вас. Однако из-за своего подхода к лицензиям он особенно опасен. Tabnine, например, обучается только на ПО с разрешительными лицензиями.
Конкуренты Copilot к тому же заслужили репутацию тех, кто и правда придерживается правила «шаблонных» рекомендаций. Они, похоже, не разделяют амбициозных планов Copilot написать почти половину кода за разработчика, поэтому менее склонны предлагать сложную логику, которую можно отследить вплоть до источника, защищенного авторским правом. Тем не менее, все «друзья программиста», работающие на основе ИИ, несут в себе определенный риск, и мы не собираемся с пеной у рта доказывать вам, что Copilot якобы опаснее других подобных программ.
Нарушает ли Copilot закон об авторском праве?
На этот вопрос нет простого ответа, потому что аналогов делу Copilot не существует. Тем не менее, от ряда аргументов нелегко отмахнуться.
Ряд защитников Copilot утверждают, что предложения программы настолько очевидны и универсальны, что на самом деле они не являются объектом авторского права. Но на собственном сайте GitHub говорится, что «примерно в 1% случаев предложение может содержать фрагменты кода длиной более ~150 символов, напрямую совпадающие с данными из обучающего набора».
В коллективной жалобе утверждается, что даже код короче 150 символов всё ещё может представлять из себя нарушение авторских прав и «если даже прибегнуть к собственной метрике GitHub и самым консервативным критериям, Copilot нарушил DMCA по меньшей мере десятки тысяч раз».
Волна возмущения разработчиков, обнаруживших свои наработки в Copilot, еще не успела набрать обороты, но первые жалобы уже посыпались. В печально известной ветке Твиттера профессор Тим Дэвис возражал против того, что Copilot выдает значительные фрагменты его кода, защищенного авторским правом.
@github copilot, с заблокированным «публичным кодом», выдает огромные куски моего кода, защищенного авторским правом, без указания авторства, без лицензии LGPL. Например, простая подсказка «sparse matrix transpose, cs» выдает мой cstranspose в CSparse. Слева — мой код, справа — github. Непорядок. pic.twitter.com/sqpOThi8nf
— Тим Дэвис (@DocSparse) 16 октября 2022 г.
В иске Бутерика и его коллег перечислены и другие примеры, включая код, имеющий значительное сходство с образцами из книг Mastering JS и Think JavaScript. В жалобе также отмечается, что, генерируя часто используемый код, Copilot воспроизводит и типичные ошибки, поэтому его предложения часто бывают глючными и неэффективными. Как утверждают истцы, это доказывает, что Copilot ничего не создает в каком-либо значимом смысле — он просто копирует код, с которым чаще всего сталкивался в обучении.
Пока что позиция защиты корпорации Microsoft, похоже, держится на идее «добросовестного использования». Добросовестное использование освобождает создателей от претензий по авторскому праву при условии, что их работа в достаточной степени преобразует исходник. Например, музыкант, пародирующий песню другого исполнителя, удовлетворяет определению добросовестного использования. Но пока еще не ясно, применимо ли такое понятие к Copilot.
Кто-то указывает на судебный прецедент Google против Oracle, в котором Верховный суд постановил, что Google имела право использовать Java API для создания ОС Android. Но API в основе своей созданы для облегчения коммуникации между программами, что является гораздо более узким случаем использования, чем широта кода, о которой идет речь.
Другое дело, которое может пролить свет на законность Copilot, вообще не касается технологий. Дело Andy Warhol Foundation против Голдсмит касается серии портретов покойного художника, которые были основаны на работах фотографа Линн Голдсмит. SCOTUS недавно заслушал аргументы по этому делу, но что бы суд в итоге ни решил, его сравнение с Copilot останется неполноценным, поскольку код не является ни в полной мере искусством, ни в полной мере наукой. Одни функции полностью «математичны», в то время как другие можно считать триумфом творческого мышления; не существует единого правила, которое было бы применимо сразу ко всем ситуациям.
Майкл Вайнберг написал в своем блоге статью, в которой проанализировал аргументы за и против Copilot. Он пришел к выводу, что даже если доводы о добросовестном использовании провалятся, GitHub сможет сослаться на свои условия предоставления услуг, чтобы оправдать изъятие кода из любого репозитория. Однако он также отмечает, что это может быть крайняя мера защиты, поскольку она может вызвать негативную реакцию со стороны пользователей GitHub.
Прочие недостатки Copilot
Технические директора могли бы согласиться на риск нарушить чужое авторское право, если бы Copilot со всех прочих сторон оказался идеальным продуктом. Но пока вы еще не перешли этот Рубикон, мы предлагаем вам рассмотреть еще два фактора, которые помогут принять осознанное решение.
Безопасность
Эксперты сообщают, что Copilot часто предлагает код с дырами в безопасности. В ходе одного исследования специалисты составили при помощи Copilot 1 689 программ, из которых 40% были уязвимы для атак. Конечно, исследование проводилось, когда инструмент ещё находился в бета-версии, но даже сейчас GitHub открыто говорит о том, что не несёт никакой ответственности за качество кода.
Вдобавок ко всему, одна из малообсуждаемых проблем безопасности заключается в том, что Copilot представляет собой кейлоггер. В отличие от Tabnine, который разработчик может запустить локально, Copilot функционирует только в облаке. Справедливости ради отметим, что Copilot все же позволяет пользователям отключить телеметрию, настроив отказ на вкладке «настройки».
В настоящее время GitHub Copilot не включает телеметрию по умолчанию. Тем не менее, если вы не знаете, включали ли вы её раньше не лишним будет перепроверить галочку.
Тем не менее, есть причины сомневаться в том, что процесс отказа от телеметрии работает так, как обещано. И вот почему: пользователи также могут запретить Copilot выдавать предложения, совпадающие с публичным кодом. Однако Тим Дэвис, на чью запись в Твиттере мы уже ссылались, сообщил, что он предпринял оба этих шага, и ему по-прежнему возвращается его собственный код.
Когда я зарегистрировался, я отключил опцию «Разрешить Github использовать мой код...». Также обратите внимание, что «предложения, совпадающие с публичным кодом» «заблокированы». Тот же результат... @github выдает мой LGPL-код дословно, без указания лицензии и авторских прав. pic.twitter.com/viKbqym2eq
— Тим Дэвис (@DocSparse) 16 октября 2022 г.
Полезность
Согласно собственной странице FAQ GitHub, «пользователи принимают в среднем 26% дополнений, предложенных GitHub Copilot». Оценка Бутерика была более прямолинейной: «Copilot, по сути, ставит перед вами миссию исправить домашнее задание 12-летнего ребёнка, снова и снова».
По мнению некоторых разработчиков, этот инструмент оказался полезен с точки зрения уменьшения «гуглежа».
Майкл Вайнберг выразился весьма точно: «Copilot — это инструмент, которым можно заменить и Google, и StackOverflow. Это, безусловно, полезно, но пока не настолько, чтобы компании добились значимых изменений в своем бюджете на разработку.
Одним из важных — хотя и трудно поддающихся количественной оценке — факторов является то, что обеспечение надлежащего контроля за кодом, генерируемым Copilot может свести на нет любой прирост производительности, который он обеспечивает. Наш генеральный директор привел этот фактор как наиболее значимый при принятии решения о запрете Copilot.
Как рецензент, я не могу знать, какой код написал нанятый мной сотрудник, а какой — AI-бот. Знание того, кто написал код, абсолютно точно определяет объем проверок, которые я должен произвести. Например, инженер, который изо дня в день доказывает, что он может создавать качественный код, проверяется менее тщательно, чем младший инженер, которого мы только что наняли.
Не зная, кто на самом деле написал 25% кода, представленного в PR, я лишаю себя возможности использовать высокоуровневую эвристику и вынужден рассматривать каждую строчку, предполагая, что её мог написать ИИ. Так как ИИ «в целом корректен, но затем внезапно и необъяснимо допускает катастрофическую ошибку», я считаю, что код, написанный им, заслуживает самого пристального внимания.
Справедливости ради стоит отметить, что GitHub, похоже, прислушивается к этим опасениям. В ноябрьском сообщении в своём блоге они объявили, что в будущих релизах Copilot любое предложение кода будет сопровождаться списком сопоставимого кода и позволит разработчикам упорядочить этот список в соответствии с лицензией (среди прочих факторов):
Используя эту информацию, разработчик может найти вдохновение в чужой кодовой базе, обнаружить документацию и почти наверняка обрести уверенность в том, что этот фрагмент подходит для использования в его проекте. Он может установить зависимость, указать авторство там, где это необходимо, или, возможно, даже выбрать другую стратегию реализации.
Это шаг в правильном направлении, но даже в этом случае дать разработчикам возможность указывать авторство — это не то же самое, что включить его автоматически. Нужно посмотреть, как эта функция будет выглядеть в реальности (где-то в 2023 году), прежде чем мы поймем, насколько успешно она справляется с претензиями критиков.
Что делать с Copilot в вашей организации
Для многих компаний риск распространения кода под GPL достаточен, чтобы отказаться от Copilot. На самом деле, перед тем как подать иск, Баттерик сам написал, что «не беспокоится о его влиянии на открытый исходный код», потому что разработчики программного обеспечения неизбежно запретят его использование.
Как говорит наш генеральный директор, «будучи человеком, который раньше работал над сделками M&A, я нередко снижал цену на 20-30% или даже полностью уходил от сделки, если чувствовал, что существует неоправданный риск нарушения авторского права». Учитывая это, запрет на использование Copilot — это пока что самый безопасный, хотя и самый консервативный выход.
Если вы все-таки позволите сотрудникам использовать Copilot, мы советуем вам принять следующие меры предосторожности:
Отключить телеметрию
Блокировать предложения публичного кода
Тщательно тестировать весь код Copilot
Прогонять проекты через инструменты проверки лицензий, которые анализируют код на предмет плагиата
GitHub Copilot — это освоение неизведанных территорий
Можно было бы написать целую книгу (или комментарий на Reddit длиной в тысячу страниц) обо всех вопросах, которые поднимает Copilot. Помимо всего прочего, он вызвал ожесточенные дебаты между евангелистами ИИ и пуристами open-source.
Дэвид Хайнемайер Ханссон, создатель Ruby on Rails, утверждает, что неприятие Copilot противоречит самому духу open source. Copilot — это «именно тот вид совместного новаторского прорыва, который я с удовольствием наблюдаю, когда любой выложенный мною в мир открытый код становится полезным», — пишет он. «Разве не для этого изначально мы публикуем наш код? Чтобы дать другим возможность делать ремиксы, повторно использовать его и создавать что-то новое?»
Несмотря на то, что Ханссон действительно мотивирован этим чувством экспансивной щедрости, нельзя считать, что он говорит от имени всего сообщества разработчиков ПО с открытым исходным кодом. Программист, написавший приложение для поиска потерявшихся домашних животных, может иметь законные возражения против того, чтобы его код использовался в системе наведения ракет.
С другой стороны, юридическая победа над GitHub, Microsoft и OpenAI может иметь непредвиденные побочные эффекты, которые распространятся на всю область генеративного ИИ.
Как бы мы к этому ни относились, кажется, что появление чего-то похожего на Copilot просто неизбежно. В лучшем случае это будет программа, которая не станет разводить код и людей, пишущих его, в разные стороны в попытке стать чем-то вроде автопилота.   3 ноября программист и правовед Мэтью Баттерик совместно с юридической фирмой Джозефа Савери подал коллективный иск против GitHub, Microsoft (его материнской компании) и OpenAI. Иск, поданный «от имени группы предполагаемых миллионов пользователей GitHub», направлен против GitHub Copilot, инструмента на основе искусственного интеллекта, выполняющего функцию продвинутого автокомплита для программистов. Разработчики, установившие Copilot в качестве дополнения к IDE, вводят подсказки на естественном языке, а Copilot выдает предложения по написанию кода на десятках языков программирования. Иск Иск Генеральный директор GitHub Томас Дохмке ранее заявлял, будто Copilot способен избавить программистов от 40% рабочей нагрузки, предлагая им шаблонные фрагменты кода — в теории это позволит избежать долгих часов изысканий, проб и ошибок. заявлял заявлял Но Бутерик и другие критики Copilot утверждают, что многие предложения Copilot вовсе не являются «шаблонными»; в них безошибочно угадываются следы оригинальных авторов, поскольку Copilot был «обучен» на хранилищах публичного и открытого кода GitHub. Этот иск, как и масштабные дебаты вокруг Copilot, поднимает массу сложных вопросов: технологических, юридических, этических и даже экзистенциальных. Например: Что для ИИ означает «учиться»?
Являются ли инструменты ИИ, такие как Copilot, началом новой эры инноваций или они просто-напросто ликвидируют человеческий труд и творческий подход?
Является ли код в большей степени подобием искусства или же математики? И зависит ли от ответа на этот вопрос то, как с ним следует обращаться с точки зрения закона? Что для ИИ означает «учиться»? Что для ИИ означает «учиться»? Являются ли инструменты ИИ, такие как Copilot, началом новой эры инноваций или они просто-напросто ликвидируют человеческий труд и творческий подход? Являются ли инструменты ИИ, такие как Copilot, началом новой эры инноваций или они просто-напросто ликвидируют человеческий труд и творческий подход? Является ли код в большей степени подобием искусства или же математики? И зависит ли от ответа на этот вопрос то, как с ним следует обращаться с точки зрения закона? Является ли код в большей степени подобием искусства или же математики? И зависит ли от ответа на этот вопрос то, как с ним следует обращаться с точки зрения закона? Эти вопросы бесконечно провоцируют споры, и в этой статье мы слегка затронем каждый из них. Однако существует еще более насущный вопрос, на который техническим директорам следует ответить прямо сейчас: стоит ли мне позволять использование Copilot внутри своей компании?  Как вы могли догадаться по заголовку этой статьи, мы настроены против корпоративного использования Copilot — по крайней мере, пока над ним нависло столько нерешенных юридических вопросов. В этой статье мы рассмотрим аргументы как за, так и против Copilot, а также расскажем, как вы сможете проверить, не используют ли его в вашей организации прямо у вас за спиной. Как обычно, мы напоминаем, что все сказанное ниже не должно рассматриваться как юридическая консультация, и перед принятием правовых решений необходимо проконсультироваться с профессиональным юристом. Юридические риски Copilot Бутерик подробно рассказал о своем видении экзистенциальной угрозы Copilot для сообщества open source, но его иск сводится к гораздо более прозаичному вопросу нарушения авторских прав. Бутерик и его коллеги утверждают, что предложения по коду Copilot берет из программ с открытым исходным кодом, и, не указывая ссылки на оригинал, он нарушает условия open source лицензий. Очевидно, что организации, использующие Copilot, подвержены такому же риску. Краткое руководство по лицензиям на ПО с открытым исходным кодом Лицензии на программное обеспечение с открытым исходным кодом не монолитны, поэтому разные лицензии накладывают разные ограничения на то, как сторонние разработчики могут использовать исходный код. «Разрешительные» лицензии, такие как MIT и Apache Licenses, позволяют разработчикам изменять и распространять код так, как они считают нужным. С другой стороны, лицензии с copyleft, такие как GPL, требуют, чтобы при любом повторном использовании соблюдались условия оригинальной лицензии. разные лицензии накладывают разные ограничения разные лицензии накладывают разные ограничения Существуют и другие важные различия между лицензиями на ПО с открытым исходным кодом, но для наших целей важнее всего то, что их объединяет: все они требуют от разработчиков указывать авторство, включая оригинальное уведомление об авторских правах. Это гарантирует (среди прочего), что программное обеспечение не содержит несовместимых лицензий. Как объясняет Бутерик, нельзя создавать программное обеспечение с лицензией MIT, используя код с лицензией GPL, потому что нельзя передавать другим людям права, которых у вас самого никогда не было. объясняет объясняет Copilot отнимает у кода лицензию, поэтому разработчики, использующие его, рискуют случайно нарушить чьи-то авторские права. Это подвергает компании риску судебных исков, особенно со стороны групп по защите ПО с открытым исходным кодом, таких как Software Freedom Conservancy (SFC). подвергает подвергает Software Freedom Conservancy (SFC) Software Freedom Conservancy (SFC) Конкуренты Copilot К вашему сведению, Copilot — это не единственный инструмент, который дописывает код за вас. Однако из-за своего подхода к лицензиям он особенно опасен. Tabnine, например, обучается только на ПО с разрешительными лицензиями. Tabnine Tabnine Конкуренты Copilot к тому же заслужили репутацию тех, кто и правда придерживается правила «шаблонных» рекомендаций. Они, похоже, не разделяют амбициозных планов Copilot написать почти половину кода за разработчика, поэтому менее склонны предлагать сложную логику, которую можно отследить вплоть до источника, защищенного авторским правом. Тем не менее, все «друзья программиста», работающие на основе ИИ, несут в себе определенный риск, и мы не собираемся с пеной у рта доказывать вам, что Copilot якобы опаснее других подобных программ. Нарушает ли Copilot закон об авторском праве? На этот вопрос нет простого ответа, потому что аналогов делу Copilot не существует. Тем не менее, от ряда аргументов нелегко отмахнуться. Ряд защитников Copilot утверждают, что предложения программы настолько очевидны и универсальны, что на самом деле они не являются объектом авторского права. Но на собственном сайте GitHub говорится, что «примерно в 1% случаев предложение может содержать фрагменты кода длиной более ~150 символов, напрямую совпадающие с данными из обучающего набора».]]></text>
</doc>
